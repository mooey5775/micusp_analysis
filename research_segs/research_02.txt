Using data collected straight from test subjects can be extremely helpful in formulating theories about second language acquisition. My goals in this research is to analyse the speech of a student of German. I plan to do more in depth into certain aspects of his language skills as well as determine his overall level of speaking fluency as based on the definition given on page 14 of our MELAB booklet.
My subject, who wishes to be called Max, is a 24-year-old program manager for an international company whose first language is English. He began learning the German language by himself at the age of 20 through reading and listening to cassette tapes. During the next two semesters of college after a summer of this self-teaching, he enrolled in a total of 18 credit hours of German and advanced rapidly in his language skills. Max was exposed to a variety of teaching methods at that time.
Feeling that he was then ready to gain some practical experience in a country where the language was spoken, he enrolled in an exchange program and spent a year in Munich studying at the university there and taking specially-designed classes through his program. He was in an immersion-style setting involving classes only taught in German but with students who all spoke the same first language and could therefore help each other with difficult aspects of grammar and pronunciation.
Today, Max no longer uses his German skills often and admits that they may have grown a bit rusty, although he does still speak with a perfect German accent. He still enjoys speaking the language and had a high personal motivation to learn it in the first place because language learning is a favorite pasttime of his.
I have rented an audio cassette player from LS&A Media to record the verbal interraction between myself and Max. Other resources include parts of the readings discussed throughout the semester, as well as the MELAB booklet and handouts given out in class. I will also make use of the transcript of my recorded interview with Max for my analysis of his language skills.
One of the most important parts of the German language that does not exist in English is the presence of grammatical gender. As is the case with many other languages, nouns in German have had a gender arbitrarily assigned to them. This is one of the hardest aspects of German to learn because the monolingual English speaker has no experience with such things; and the English speaker with some contact with other languages will often also have difficulties because the genders of nouns may differ be different in German (i.e. el puente in Spanish, and die Brücke in German). I have chosen to take a more in-depth look into Max's use of indefinite articles since they came up more frequently than the definite articles and are similar in form and equally difficult to master. To make my data more easily intelligible, here is a chart of the indefinite articles of German:
For my analysis, I have taken several random samples from the pages of the transcript of my interview to look at the accuracy rate in Max's speech. These examples are representative of a general trend that I have found in his grammar. While Max does seem to have a basic grasp of the indefinite article, the more complicated and less-used forms still seem to allude him. Nominative tenses are correct most of the time, while accusative is correct some of the time, and dative and genitive are often incorrect. This leads me to believe that Max has memorized the basic (nominative) genders of the nouns but does not know how to decline them well. A glance at the definite and possessive articles in the transcript confirms this.
Verb placement is often difficult for second language learners because they must learn a new set of rules. In German, the verbs often occur in two different places in the sentence, with the modal verb before or after the subject (depending on whether it follows another item or not) or even at the end of a sentence (if the sentence begins with certain specific prepositions). To make this easier, all verbs will be in bold.
This data shows that while Max does see that there is a possibility in German for a more varied verb placement, he does not know how and where to impliment it. All the sentences in the example were chosen because they should have the standard SVOV order. Some of them do and some don't, reflecting Max's evident confusion with this aspect of the grammar.
Another aspect of the verbs in German is that the past perfect can be conjugated using either to have or to be. For example, he has come in English would be er ist gekommen (he is come) in German. Verbs using the to be form usually pertain to motion or movement from one place or position to another.
Here we see that Max is having problems distinguishing the to be verbs from the to have verbs. This probably is taken from his first language because English does not allow for to be verbs. Max rarely uses the to be form, even with the German verbs that call for it.
Using page 14 of the MELAB booklet given out in class, I would rank Max as a good speaker, but with a 3-, meaning that he is much closer to being a marginal/fair speaker than an excellent speaker. I chose this ranking because Max understood everything I asked him and could produce utterances easily and without accent. The reason he is not an excellent speaker is that he seems to have not yet grasped many of the aspects of the difficult grammar of German. He also sometimes had trouble finding the right word and often resorted to code-switching during our interview. I would suggest a more in-depth study of articles and sentence structure for Max, as well as more time spent in Germany. Being exposed directly to the language would help his German advance, and I am convinced that in time he would speak almost perfect German.

Over the past 20 years or so, hedging has become an increasingly well-researched aspect of academic writing. As with any identifiable aspect of academic writing, much of the research on hedging attempts to define it, theoretically and functionally. Because of the negative treatment hedging has received in the past, many studies (e.g. Skelton 1988a and 1988b; Myers 1996; Channell 1990; Banks 1998; Hyland 1994 and 1998) aim to validate the presence and legitimacy of hedges in academic writing. Other research (e.g. Hyland 1994 and 1998) has offered advice on how best to teach hedging in an EAP context. Research has been undertaken on the pragmatics of hedging and its link to politeness, its social implications, and how it affects the negotiation of meaning between writer and reader (e.g. R. Lakoff 1972; Myers 1996; Salager-Meyer 1994). Several contrastive rhetoric studies have looked at hedging in different cultures (eg Martìn-Martìn & Burgess 2004) and the possible linguistic transfer that may result from attempts to hedge in the L2 (e.g. Clyne 1991; Hinkel 1997). Some attention has been paid to the strength and presence of hedging and the variations thereof in certain genres (such as the IMRD pattern for research papers) (Salager-Meyer 1994; Martìn-Martìn & Burgess 2004; Banks 1994b). However, one issue that has not received as much attention in the literature as it perhaps warrants is that of multiple hedging (using more than one hedge in a given statement, such as in "this may suggest..." or "this could perhaps be..."). The fact that multiple hedging does indeed occur is evident from a look at almost any piece of academic writing, and it has not been entirely ignored in the research. Many studies mention it in passing; however, few devote any significant amount of space or time to its study. What this lack of focused attention leaves unclear is just how often multiple hedging occurs, whether or not it is considered acceptable (and if so how many hedges must be used before multiple hedging becomes overhedging), and what, if any, factors, such as level of education, native vs. non-native speaker status, etc, may affect the strength or amount of a given writer's use of hedges. In this paper, I will look specifically at multiple hedging as a phenomenon of academic writing. I will start by providing an extensive review of the literature on hedging, focusing first on how hedging has been defined, and gathering from these different definitions a working definition to apply to my own research; and focusing secondly on how the notions of overhedging and underhedging have been addressed in the literature, in order to see if multiple hedging has received any sort of value judgment by the academic community. After this literature review, I will turn to my own research: a look at multiple hedging in the Hyland Corpus of academic text (which attempts to answer the question of how often multiple hedging occurs) and a survey which attempts to assess the evaluation of hedging expressions of various levels of strength by different academic groups (this survey attempts to address the acceptability of multiple hedging and the factors that may affect the strength of a writer's hedging expressions). I conclude by summarizing the results of my research and exploring how these results may be useful to the academic community.
George Lakoff introduced the term hedging in 1972 as a way to refer to "words whose job it is to make things more or less fuzzy." Lakoff's introduction of the term did not spark much research, however, and in 1988 the subject was still "scarcely touched on in ELT" (Skelton, 1988b, p. 98). But since then, hedges have been written about relatively frequently in the literature, with a significant amount of attention paid to both hedges in speech and hedges in writing. Unsurprisingly, given the slippery nature of pragmalinguistic phenomena in general, an agreed-upon description of what linguistic devices count as hedges -- and more significantly what do not -- does not emerge from the substantial literature on this topic. What do exist are varied definitions of hedging, which of course result in correspondingly varied taxonomies. While the definitions given by most researchers are not always so different as to be mutually exclusive, and while all the taxonomies given have at least some corresponding items, it is nevertheless necessary to clarify which (if any) researcher's definition and taxonomy I will be using and to justify why I have chosen it. I will not necessarily be trying to construct the most sophisticated definition, but rather to give the concept sufficiently clear boundaries so that it can be operationalized in analytic practice. That is, I am by no means trying to construct my own definition of hedging; I wish simply to find a clear working definition to use for my research -- research which, in part, involves the location and identification of hedging devices in academic text.
First, it is helpful to give an overview of how hedging has been looked at in the literature and what controversies or disagreements exist when it comes to finding a precise definition. George Lakoff's (1972) description of hedges, which, as I've mentioned, was the first to be introduced in the field of linguistics, as "words whose job it is to make things more or less fuzzy," is -- though of course an important and useful one sparking years of research -- itself problematic. One problem lies with Lakoff's use of the expression "more or less." All other research has considered hedges to be words which make things more fuzzy -- not less fuzzy. Making things less fuzzy is now thought to be a different linguistic concept, with different pragmatic and linguistic properties; Hyland (eg 2004) calls these items designed to make words less fuzzy "boosters." If we disregard this part of Lakoff's definition, we are left thinking of hedges as words which make things more fuzzy. This may appear to be a simple and straightforward definition on first glance, but with a bit of thought it becomes clear that the word fuzzy as it relates to hedging is, well, fuzzy. What is meant by Lakoff's little adjective and the linguistic phenomenon it attempts to describe has been a hot topic of debate in the research literature on hedging.
There is of course a certain level of correspondence in the research on hedging: all authors seem to be in agreement that written hedges express an attitude of uncertainty on the part of the author and/or a degree of non-commitment to the truth of a given proposition. However, the agreement stops with attempts at further, more precise definitions and to an even larger extent with attempts to come up with a definitive group of linguistic expressions to be considered as hedges. This can be seen by a quick examination of some of the principal research. The relatively early study by Prince et al. (1982) classifies hedges into two different groups: approximators which show uncertainty/non-commitment "within the propositional content proper" and shields, which show uncertainty/non-commitment "in the relationship between the propositional content and the speaker" (p. 86). While Prince et al. focus on spoken academic discourse, research in academic writing discusses similar types of hedges (see for example Salager-Meyer 1994).
Skelton (1998b), who prefers to call hedges "comments" (to avoid the "pejorative connotation" of the word "hedge"), presents three categories into which comments fall: Type one comments indicate tentativeness or levels of probability and include copulas other than be; modal auxiliaries; adjectivals and adverbials introduced by It is, This is, There is, or which are sentence or clause-initial and immediately followed by a comma; and lexical verbs. While Skelton focuses by far the most attention on Type 1 comments, he also discusses Type 2 comments which "are concerned with the way adjectivals and adverbials in general function in academic text," and Type 3 comments, which deal with the "association between commentative language and stylistic markedness" (p. 102).
In some contrast, a few authors focus on hedging's pragmatic function and its link to politeness, such as R. Lakoff (1972) and Myers (1989), who argues that hedges are a social phenomenon and are perhaps best understood as politeness strategies. Myers's taxonomy includes modal conditional verbs and modifiers and, perhaps a bit too broadly, "any device suggesting alternatives [...] -- anything but a statement with a form of "to be" that such and such is the case" (p. 13). Salager-Meyer (1994), who adopts a functional approach in her attempt to define hedging, deals with the concept of modesty (related to politeness) and believes that research on hedging should give more emphasis to the fact that hedges are "the product of a mental attitude" (p. 152). She adopts for her research a definition that "goes beyond [...] mere association with speculation" and entails "purposive fuzziness and vagueness (threat-minimizing strategy); that which reflects the authors' modesty for their achievements and avoidance of personal involvement; and that related to the impossibility or unwillingness of reaching absolute accuracy and of quantifying all the phenomena under observation" (p. 153). Her corresponding taxonomy includes five categories: shields, which include modal verbs expressing possibility, "semi-auxiliaries" (or copulas other than be), probability adverbs and adjectives, and epistemic lexical verbs; approximators; words which "express the author's personal doubt and direct involvement"; emotionally charged intensifiers; and compound hedges (p. 154-155).
Hyland (1994, 1998) focuses on hedging's link to epistemic modality, defined by Lyons as "any utterance in which the speaker explicitly qualifies his commitment to the truth of the proposition expressed by the sentence he utters" (cited in Hyland 1994, p. 240). Hyland also acknowledges hedging's social function saying that it's "a central means of gaining communal adherence to knowledge claims" (p. 241). In other words, hedging is a way for scholars to situate themselves within their discourse communities. According to Hyland, hedging "reflect[s] a relation between a writer and readers, not only the degree of probability of a statement" (p. 241). Hyland's taxonomy of hedging devices is quite extensive (especially in Hyland 1998) and includes modal auxiliaries, adjectival, adverbial, and nominal modal expressions, modal lexical verbs, IF-clauses, question forms, passivization, impersonal phrases, and time reference (1994, p. 240). Hyland (1994) also clarifies that "Many instances of hedging take unpredictable forms, for example by referring to the uncertain status of information, the limitations of a model, or the absence of knowledge" (p. 243). Hyland's taxonomy, then, does not just include specific linguistic forms, but a range of possible expressions.
Peter Crompton (1997), who believes that the lack of agreement among researchers when it comes to precisely defining hedging as a linguistic phenomenon is problematic, proposes a "narrower" definition of hedging: "A hedge is an item of language which a speaker uses to explicitly qualify his/her lack of commitment to the truth of a proposition he/she utters" (p. 281). In order to determine whether or not a given proposition involves the use of hedging, Crompton proposes the following diagnostic question: "Can the proposition be restated in such a way that it is not changed but that the author's commitment to it is greater than at present? If "yes," then the proposition is hedged" (p. 282). Crompton includes the following in his taxonomy of hedges: copulas other than be, epistemic modals, clauses and adverbials relating to the probability of the subsequent proposition being true, "reported propositions where the author(s) can be taken to be responsible for any tentativeness in the verbal group, or non-use of factive reporting verbs," and "reported proposition[s] that a hypothesized entity X exists and the author(s) can be taken to be responsible for making the hypothesis" (p. 284).
Overall, we can see that, although the theoretical standpoint behind each may vary to a certain extent, the fundamental base of these researchers' definitions of hedging is essentially the same: all involve expressing degrees of uncertainty (I believe that both uncertainty used intentionally as a way to avoid responsibility and uncertainty expressed because more precise figures are unavailable require hedging devices, though some researchers would disagree); and all the definitions I examined give some attention to hedging's pragmatic and/or social functions. It is the terminology and the taxonomies of hedging expressions which differ to such an extent that I must pick and choose among them in order to do my own research. Because my work involves the use of a corpus and, more specifically, searching for instances of hedging within the corpus, it is helpful to come up with a list of which linguistic expressions I will be considering in my search. In an attempt to be as accurate as possible and to remain fairly neutral, I have chosen to accept as hedges those linguistic items listed in Crompton (1997) as discussed by two or more researchers (p. 280). These include copulas other than be, certain lexical verbs used in certain contexts, modal verbs, and probability adverbs and adjectives. It is also necessary to define more specifically which modal verbs and lexical verbs I will be using: I will consider only very "weak" lexical verbs (like suggest), so that I may be certain of their hedging content (for more discussion of this issue see Johns 2001), and only modal verbs which express epistemic uncertainty. Some further explanation is necessary here: One is able to say that something "can be done" -- meaning that it has been done, or is factually able to be done; in this case can is not a hedging device. On the other hand, one is able to say that something "may be relevant," in which case, may is expressing epistemic uncertainty on the part of the speaker and is therefore a hedging device. The same distinction applies to probability adverbs and adjectives: the expression "possible to" cannot be used to hedge, as it expresses factual ability; the expression "possible that" can be used to hedge, as it has epistemic content.
In addition to these more or less agreed upon linguistic categories, I will include several other items. The first of these is approximators, as described by Salager-Meyer (1994). I do so because, although Crompton claims Salager-Meyer is the only author to include this item in her taxonomy of hedging, many of the articles I've looked at (specifically those on vagueness in academic writing) also considered approximators as hedges. Also, approximators fit with the basic theoretical standpoint I'm adopting: the relatively agreed-upon idea that hedging is used to express degrees of (avoidable or non-avoidable) uncertainty. Next, I will include items which are semantically related to (but belong to a different word class than) the lexical verbs I consider as hedges (eg: implication, suggestion, etc). Crompton states that Hyland is the only researcher to do so, but I see no reason why I should not include these related words, as they have the same semantic content as the lexical verbs (and it is the semantic content of a word that creates a hedged effect, not that word's part of speech). Using the same reasoning, I will include words related to the copulas other than be (such as appearance and seemingly) and nouns of probability, when appropriate (such as possibility when clearly used in an epistemic sense). I will not include any other items mentioned by only one researcher, such as IF-clauses (Hyland, 1994, 1998) and "expressions of the authors' personal doubt and direct involvement" (Salager-Meyer, 1994).
I would also like to point out that I believe Crompton (1997) is correct when he says that "to count all uses of certain linguistic tokens as hedges, is to run the risk of misrepresenting the discourse" (p. 279). For this reason, I will attempt to consider not only the lexical items I take to be hedges, but their placement and meaning within their respective propositions, in order to verify that these expressions are indeed being used as hedges. By doing this, I hope to avoid some of the "misrepresent[ation of] the discourse" that Crompton speaks of. I of course acknowledge that introspection is not always a reliable form of data analysis, and is quite difficult when working with the large amount of data yielded by corpus research (especially research using Hyland's sizeable corpus of 240 academic research articles) but I believe it is better than somewhat blindly considering only surface forms without taking into account any of their semantic context.
The hedging categories, with some obvious linguistic realizations, are therefore as follows:
From here, I will move on to a discussion of how multiple hedging has been looked at in the literature and how these explorations by other researchers relate to the current research.
Views on hedging as a phenomenon of academic writing have undergone a dramatic shift within the past 15 to 20 years. Skelton (1988b) shows that at the point in time of his article, hedges were quite strongly looked down upon, the term hedging carrying "unfortunately pejorative connotations in ordinary language" (p. 98). In fact, the idea that hedges should be used -- not avoided -- is presented by Skelton as an almost radical idea. (Today, at least among academic researchers "in the know," this idea is accepted without question, perhaps even taken for granted.) Over time, more and more articles justifying the legitimacy of hedging in academic writing have been published and today the term hedging does not carry as strong of a "pejorative connotation." Unfortunately, all is not as well as it should be. To this day, many style guides still advise strongly against hedging; the widely used Strunk and White (1979), for example, calls qualifiers (another words for hedges) "the leeches that infest the pond of prose, sucking the blood of words" (p. 73). This comment could perhaps be appropriate in talking about business or technical writing, which aims for clarity, precision, and conciseness, but it hardly seems appropriate for academic genres, where hedges often have an essential role (for more examples of this inappropriate type of negative treatment, see Hyland 1994 and 1998). And, according to Hyland, at least as of 1998, many ESP/EAP textbooks have failed to give an adequate amount of attention to hedging (see Hyland 1994 and 1998). If our view of what constitutes good academic writing are based on authentic texts and the discourse practices involved with those texts rather than prescriptive rules determined by some (often unknown or unnamed) authority's idealized version of a language (and I quite think they should be), then we cannot ignore or deny the legitimacy of hedging's presence, whether in speech or writing. Indeed, the importance of hedging has been demonstrated, with increasing frequency over the last 20 years or so. The most extensive of these works devoted to demonstrating the validity of hedging and to defining some of its characteristics is Ken Hyland's book Hedging in Scientific Research Articles (1998). Other works include Banks (1998), Myers (1996), Hyland (1994), Skelton (1988a), and the previously mentioned Skelton (1988b).
It will be useful at this point to see where multiple hedging fits in through a further examination of some of the justifications of hedging provided in the literature. Hyland (1994) focuses on arguing that the strong presence of hedging in academic writing requires an equivalently strong amount of attention in EAP textbooks -- an amount of attention which, in Hyland's view, is rarely found. By this point in time, hedging has found its place in the research literature, but according to Hyland, not much has been done to place the research done into practice. Hyland stresses that teaching materials should be revised to place an appropriate amount of emphasis on hedging. In his view, the problem students face is that they underhedge; he does not mention overhedging as a potential problem. One might feel here that Hyland is perhaps overstating the need for focus on hedging in EAP textbooks. While hedging does occur very frequently and should, of course, be given some attention in any well-developed set of language teaching materials, it is possible that hedging does not receive more focus because it is not extraordinarily difficult for students to accomplish some base level of hedging, like the use of modal and lexical verbs, for example. It's likely that a relatively short amount of coverage would suffice. This does not take away, however, from Hyland's point that the negative attitude towards hedging readily encountered in the past is problematic and that EAP materials should work to counter any negative associations with this useful phenomenon. Also, his point that a lack of attention may lead to underhedging is potentially valid and should be taken into consideration.
Other justifications are provided by authors' work on vagueness (which is not quite the same as hedging, though definitely related, as it can be used to moderate levels of certainty). David Banks (1998) writes about the importance of vagueness, focusing on quantification in scientific journal articles. Here, the focus is on dispelling the myth that scientific writing should strive for total objectivity and should avoid vagueness. According to Banks, a certain level of vagueness is not only acceptable in scientific discourse, it is necessary. He implies that previous assumptions which do not consider vagueness as an essential part of scientific writing should be reconfigured, stating that "it is of upmost importance that we do not allow our understanding of vague quantification in the scientific journal article to remain vague" (p. 26). He does not, however, mention the use of multiple expressions of vagueness or being overly vague.
Myers (1996) also discusses the legitimacy of vagueness, arguing that vagueness can be used strategically in academic writing. Instead of teachers telling students and editors telling authors that vagueness is to be avoided at all costs, an attempt should be made to understand how vagueness can work as a useful technique that extends the scope of a text through time and space, thus giving the writer a larger role in the reader's interpretation. Myers points out that there is such a thing as being too vague, but it's difficult to pin down. As he says "Vagueness is appropriate in some contexts, but writers have to understand how and why they are using it." (p. 12) He claims that people, especially teachers, need to take time to better define the notion of vagueness, allowing room for its intentional and appropriate use: "The question to ask in teaching is not whether an expression is vague but: For whom is it vague? Vague as opposed to what other expression? To what end is it vague?" (p. 12).
Channell (1990) also argues in favor of vagueness, saying that "the view that the precision of science and scientific language depends upon the precision of its terms is certainly very plausible, but it is none the less, I believe, a mere prejudice" (p. 95). While she does not specifically deal with multiple hedging, or over/underhedging, Channell stresses the need for a clear understanding of using vagueness appropriately to be imparted to students: "Clearly, prospective writers [...] need to develop a [...] sensitivity to the conventions relating to precision versus vagueness" (p. 117). In her view, what is most important is emphasizing to students that "vagueness is appropriate in certain circumstances" (p. 117).
It seems that these articles, especially Hyland (1994) and Banks (1998), are so intent on arguing against the contention that hedging is to be avoided (an understandable position since, as we have seen, hedging still needs a lot of arguing for) that overhedging isn't really mentioned. John Skelton (1988a), who suggests that hedges should be broken down into two distinct classes, comments and propositions, also argues for the general importance of hedging to academic discourse. However, unlike the previously discussed authors, Skelton is quick to point out that, although a lack of sufficient attention given to hedging can certainly lead to underhedging, it may, just as importantly, lead to overhedging as well. Undergraduate students in the sciences may underhedge because they are told to be "objective and propositional," resulting in overconfident-sounding claims like "The jump in the reading was enormous and a great surprise" (p. 40). On the other end of the spectrum, the "contract of inexactitude" that hedges (or for Skelton "comments") attempt to create between writer and reader can fail to be upheld by a writer who presents a large number of comments in a given chunk of text. He cites the following example from the textbook Reading and Thinking in English (British Council 1980):
"Before we consider what mechanisms could possibly underlie the metal-bending effect, we must first help ourselves by starting with a brief summary of what it is that we shall have to try to explain. The multitude of the accounts make it clear that we are dealing with a genuine effect which can happen sometimes as a result of direct contact with a subject, and sometimes without it. The main action in the case of direct contact appears to be that of gentle stoking by the fingers of one hand. The length of time taken to cause an appreciable bend seems to vary, but it is normally less than thirty minutes and more than two or three; moreover, for a particular subject it can vary considerably from one day to the next." (cited in Skelton 1988a, p. 40).
It's interesting to note here that not only are a large number of hedging expressions used, but the presentation of the data is also quite inconclusive and unhelpful. One can also see that the writer uses hedging devices when they are not at all necessary, for instance by saying that the length of time "seems to vary" and then giving direct evidence that it does indeed vary. Skelton clarifies that this overhedging is not as apparent or as off-putting to the reader as underhedging but is still problematic as it will tend to give the reader the impression that the writing is too vague. Skelton cites a "typical student response" to the previously quoted passage: "It's all up in the air, no facts, real...it's all maybe this, maybe that, he never gets down to it. It's just vague" (p. 41). As far as how much and what kinds of uncertainty are acceptable/appropriate, Skelton can only say that it is an area needing future research.
While the previously discussed articles have suggested that the lack of sufficient attention given to hedging in English style guides and EAP textbooks (and the assumption that scientific prose should be completely objective) mainly leads to underhedging, various contrastive rhetoric based studies (eg Clyne, 1991; Hinkel, 1997) suggest that NNSs writing in English have a tendency to hedge more than NS writers and that this may create an impression of excessive indirectness for NS readers. Clyne (1991), for example, shows that German-speaking scholars hedge more when writing in English than do English-speaking scholars. He claims that this is likely due to both the strong presence of hedging in German and a lack of comfort when writing in a foreign language. According to Clyne, the abundance of hedges in German authors' written English is not wrong, per se, but it can be problematic, for German-speaking author and English-speaking reader, because it does not meet the "expectations of discourse" of academic written English. (Whether or not NNSs should be expected to conform to the discourse expectations of academic written English is another issue -- undoubtedly important, but beyond the scope of this paper).
Hinkel (1997) also provides evidence supporting the idea that NNSs L1 hedging habits may interfere with their use of hedges in English. Her article posits that NSs and NNSs use different types of hedges at different rates, so that, while NNs use possibility hedges more than NNSs, and hedged performative verbs are used at the same rate by both groups, performative, lexical, and quality hedges are used more by NNSs. Hinkel seems to be in agreement with the consensus in saying that "what represents appropriate levels of indirectness in written and academic discourse is not always clear," (p. 363) also mentioning that "when students are instructed that English writing is expected to be direct, they often produce expository pieces so open and frank that they can be perceived as inappropriate" (p. 363). Hinkel's research highlights the bind that many NNSs writing in English doubtless find themselves in: on the one hand, the hedging practices for NNSs whose native languages are indirect and vague may influence these writers to transfer these qualities onto their English prose, resulting in a piece that might strike the reader as overhedged; on the other hand, these same students may underhedge because of attempts to change made by teachers to lessen the degree of these students' indirectness -- that is, precisely because they are told not to overhedge.
Level of education may also have an effect on strength and frequency of hedging, though there is no conclusive evidence. Shaw (2000) for example discusses a group of dissertation writers who tended to hedge claims that were already hedged (in other words, to use multiple hedges). For example, Shaw points out that the dissertation writers may be more likely to use phrases such as "suggesting that X may be Y" rather than "suggesting that X is Y" (p. 52). Although Shaw does not explicitly say so, this is perhaps worth remarking on because it may indicate that writers at different levels in their education may hedge with a different level of strength and frequency. In this case, the dissertation writers may be hedging more than their colleagues who have already attained a PhD. But Shaw doesn't say whether or not more experienced writers have the same tendency to add more hedges to already hedged claims, so it is difficult to tell if this is significant. It is also interesting to note here that, as mentioned above, Skelton (1988a) shows that undergraduate students in the sciences may tend to make overconfident-sounding claims. Suggestions have been made, then, though it remains to be seen how valid they are, that lower standing on the academic totem-pole can result in both underhedging and multiple/stronger levels of hedging (perhaps overhedging as well, though the hedging that Shaw discusses is not talked of as problematic). But again, one cannot draw conclusive claims from this somewhat sparse evidence.
The situation seems quite problematic, thus, for NNSs writing academic English and/or for inexperienced writers of academic English: on the one hand these not-yet-expert (but, for the most part, not-quite-novice) writers are expected to express uncertainty appropriately, without seeming overconfident or unable to see the validity of opposing evidence; on the other, they are expected to do so without going overboard and hedging all of their claims into obscurity. Exactly where this narrow margin of correct amount/intensity of hedging is found is difficult to determine. In fact, it seems that not even experienced linguists and discourse analysts seem to be able to pin it down precisely -- let alone relatively inexperienced writers (this is not a fault on the part of the experts: language itself does not take very well to matters of precision). In other words, the level of uncertainty a writer should adopt towards his or her expressions is just that: uncertain.
Some authors have attempted to delve into this subject by looking directly at levels of uncertainty in academic text. Françoise Salager-Meyer (1994) devotes some attention to the level of hedging considered acceptable in academic discourse (more specifically medical discourse, though her results can most likely be generalized, at least to other disciplines with a tendency to follow the IMRD pattern for writing research papers), claiming that "the choice of expression of tentativeness and flexibility is dictated by the general structure of the discourse" (p. 149). In other words, the level of acceptable hedging depends on the area of the paper and the type of publication. The results of her study indicate that the Discussion section is the most heavily hedged section of a paper and the Introduction section second most heavily hedged (the Methods and Results section tend to use much less hedging). She also discusses multiple hedging, which she refers to as "compound hedges." Though she does not explicitly discuss the question of whether or not compound hedges are acceptable, her treatment of the subject indicates that she believes they are (they are certainly used in the research papers and case reports that she uses for her study). In fact, she considers compound hedges as a category of hedging, that is as a type of hedge, and places them alongside other types of hedges (such as shields, approximators, and emotionally-charged intensifiers). Why she chooses to define these compound hedges as a separate category of hedging, despite the fact that compound hedges are made up of other categories, like shields and approximators, and have no distinguishing semantic features of their own, is unclear. Compound hedges follow the general trend she establishes, occurring most frequently in the Discussion section, relatively frequently in the Introduction section, and not very frequently in the Methods and Results sections. The reason for the strong presence of compound hedges in the Discussion section is, according to Salager-Meyer, due to the fact that, "It is in this last section of research papers that writers speculate, argue, contrast, and extrapolate from the described results, and at the same time avoid stating results too conclusively"(p. 163). The stronger need to demonstrate levels of uncertainty which occurs in the Discussion section calls for a greater amount of hedges. A strong level of uncertainty, thus, seems to be acceptable and even expected in research papers, but, Salager-Meyer points out, popularization articles and texts-books are expected to avoid any strong levels of hedging (she cites an example: " "this suggests the possibility" is replaced by "they discovered" " (p. 165)). Evidence supporting Salager-Meyer's proposal that the strongest and most frequent use of hedging appears in the Introduction and Conclusion/Discussion section is also validated by research done Martìn-Martìn and Burgess (2004) in their study on academic criticism in research article abstracts and by David Banks's (1994b) book chapter "Some Hedges."
In addition to Skelton (1988a) and Salager-Meyer (1994), several other researchers have dealt directly with multiple hedging. Clyne (1991), for example, directly focuses on multiple hedging, which he refers to most often as "double hedging" (also mentioning "triple hedging" once or twice). Clyne looks at the use of hedging in a corpus of 52 texts, a compilation of English texts written by both English-speaking and German-speaking authors and of German texts by Germans. As mentioned previously, the German-speaking authors hedge more than the English-speaking authors, both when writing in English and when writing in German, and this trend is the same for the use of multiple hedges. In fact, the results of Clyne's data indicate that the use of multiple hedging is a great deal lower for English-speaking authors. This is surprising, seeing as, for example, multiple hedges occurred so frequently in Salager-Meyer's (1994) study that she designated them as a distinct category of hedges and that David Banks (1994a and 1994b), as will be discussed in more detail later, sees double hedges so frequently that he is able to determine their collocation patterns -- certainly such an uncommon phenomenon as Clyne makes double hedging out to be wouldn't have its own set of collocations . One might guess that the large difference between use of hedging for German-speaking and English-speaking scholars results from extremely large amounts of hedges in German authors' work, but this is not the case, according to Clyne; hedging devices in texts by English speakers occurred an average of only 6.25 times (with the German authors' texts at a much higher average of 24 instances). Clyne does not clarify what percentage of the texts is made up of hedges, but as he is examining published works, including articles and conference papers, it is reasonable to assume that the percentage rate of hedging expressions for English-speaking authors would come out to be quite low, especially in comparison to the percentages given elsewhere: Salager-Meyer (1994) gave hedging expressions an occurrence rate of 13% "with respect to the total number of running words in each division" for the Discussion section of research papers (p. 155-157). Clyne also claims that multiple hedges of greater than two hedging expressions ("triple hedges", etc) were completely absent from the texts by English speakers, though not from the texts by German speakers, which is a bit difficult to believe and, if true, is probably a result of the small size of the corpus. Hyland's large corpus corpus of 240 research articles provides a significant number of triple hedges, such as "This might seem to help explain why it is that (2) is true but (2*) is not" and "While teachers might be able to suggest a number of strategies that students may find helpful..." (depending on one's definition of hedging, these examples could contain even more than three hedges). However, while Clyne's figures on hedging in the texts of English speakers may be a bit hard to accept (given the conflicting results of other studies), his point that German speakers hedge more frequently and more strongly than English speakers is well-taken. We have already seen that hedging may not be adequately explained to non-native English speakers, so it is completely understandable that German authors attempt to transfer their knowledge of hedging in German (which is strong and frequent, according to Clyne) into English, and perhaps in doing so they end up overhedging their claims. The idea of linguistic transfer leading to overhedging (or at least a greater occurrence of multiple hedges) is also demonstrated by Hinkel (1997), as discussed previously.
Perhaps the most direct address of multiple hedges occurs in David Banks' (1994b) book Writ in Water: Aspects of the Scientific Journal Article and in his article "Hedges and How to Trim Them" (1994a). Chapter 8 of Banks (1994b), "Some Hedges" discusses certain multiple-hedge collocations that may be noted. (These collocations are also discussed in Banks 1994a). Banks lists the following a typical combinations of hedging devices: lexical verbs linked to modal auxiliaries by the use of the modal in a subordinate clause following the lexical verb; a lexical verb and an adverb; a verb plus complement reinforcement; a modal auxiliary and an adverb; a periphrastic modal and an adverb; a complex noun group; and, most commonly, a lexical verb with hedging content combined with a modal auxiliary. In "Hedges and How to Trim Them" (1994), the results of Banks's corpus study of eleven scientific articles results in "58 sentences which possess more than one hedging device" (p. 587). He calls these multiple hedges "fertilized." He also speaks of "trimmed" hedges, which are de-emphasized hedges or combinations of hedges and "boosters" (as defined in Hyland 2004). According to his research, fertilized hedges are much more common and occur in many more varieties than do trimmed hedges. He sums up by saying "A hedged style has become a requirement of scientific journals" (591). One can assume that Banks' descriptive study of multiple-hedge collocations carries with it the implication that using double hedges is perfectly acceptable, and this last citation seems to affirm the idea. Indeed, most of the research examined here which mentions double or multiple hedging in one way or another (except that done by Clyne) carries a similar implication; however, neither Banks nor any of the other researchers make any judgment as to how much hedging is acceptable in a given proposition.
Now that we have considered the treatment of multiple hedging in the research literature, let us move to a brief overview of some textbooks used for teaching academic writing, which will not only give examples of the different extents to which hedging is covered in textbooks (which is explained in much more detail by Hyland 1994) but will also give an indication of whether or not textbooks devote time or focus to multiple hedging and the question of its acceptability or to underhedging and overhedging as potential problem areas for students. Writing in the Sciences (1998) gives a comparatively large amount of attention to hedges which it refers to as "qualifiers." The book places emphasis on the importance of careful conclusions and acknowledging uncertainty giving examples of verbs, adverbs and adverbial phrases, and modal auxiliaries which can be used for this purpose and providing several practice exercises. It mentions underhedging as a problem but not overhedging. There is also no mention of multiple hedging mentioned.
Another text, Responses to ESP (1997), does briefly mention hedging, though it does not give as much attention to the phenomenon as does Writing in the Sciences. In the section "Some features of scientific English" Alastair Sharp provides a list of "some of the features generally recognized as being important in scientific discourse" one of which is modals. Modals are mentioned as essential for hedging (which is very briefly explained as "the modification of language to limit the strength of a knowledge claim") but there is no mention of other types of hedges. A short exercise is given, but there is no mention of underhedging or overhedging.
Perhaps the best overall coverage of hedging that I found occurs in Academic Writing for Graduate Students by Swales and Feak (2004). Unit 4 of the book, which focuses on data commentary, has a section explaining qualification and strength of claim (which includes hedging devices, though the term hedging is not directly used). The book clarifies that it is problematic to describe rather than comment, but it is also problematic to "draw unjustified conclusions," and therefore it is important to find the right strength of claim, to be cautious in expressing a claim, and to know what expressions to use. Words which can be used to express probability, distance, and generalization are given and discussed, and there is also a section on "weaker verbs" (examples are given). The book also mentions that these expressions can be combined (multiple hedging) -- that is, multiple hedging is an acceptable and useful strategy -- but it should not be overdone, or no claim will be made at all, as in "It could be concluded that some evidence seems to suggest that at least certain villagers might not have traded their pottery with others outside the community" (p.129). It is the only textbook of those that I've examined which mentions multiple hedging (as an acceptable strategy) and discusses both overhedging and underhedging.
But again the question arises: where do we draw the line between being "confidently uncertain" (Skelton 1988b, cited in Swales and Feak) and overdoing it? So far, we have examined the treatment of multiple hedging and its link to overhedging and underhedging in research literature and EAP textbooks, yet we have found no concrete answers to these questions. This brings me at last to my research, which attempts to provide some sort of answer to this question of how often multiple hedging is done and to examine the judgments of different groups within the academic world on how seldom or frequently hedging should occur. To get an idea of how often multiple hedging is done, I've looked at select expressions in the Hyland Corpus, which contains 240 research articles coming from 8 different academic fields. To get an idea of the level of hedging people consider appropriate and to see if level of education or native/non-native speaker distinction affects attitudes towards hedging (and, one can assume, therefore use of hedging) I've conducted a survey of 3 different academic groups at the University of Michigan: teachers of academic writing, NS undergraduate students, and NNS graduate students. It is now appropriate to explain these in more detail and provide the results of my research.
To get an idea of the frequency with which multiple hedging occurs, I turned to the Hyland Corpus. Since examining every proposition of each of the 240 articles in the corpus for the presence of hedging devices is not a realistic goal, it was necessary for me to choose certain expressions and examine their overall frequency and the presence of hedging expressions in their immediate context using the Wordsmith concordance feature. First, in order to get an indication of how frequently hedged expressions occur in the environment of at least one other hedge, I examined the modal verb might and the probability adverb perhaps. I chose these two expressions because, unlike some of their counterparts, they are almost always used as hedges and thus should give a good starting ground to the present research. The results follow. A Wordsmith search yielded a total of 868 entries for the word might. I examined these 868 and deleted the irrelevant entries: there are some transcripts of speech in the corpus, which I chose not to include in my analysis as I am attempting to focus on academic writing; there a number of instances in which the given hedging expression occurs within a citation (I chose not to include these in my analysis because they don't really contribute to the overall strength of hedging in the claim); and finally, it seems that a Wordsmith search turns up a few repeated examples, which I tried to be aware of and exclude. After deleting these entries I was left with 810 examples, of which I examined the surrounding context (attempting to read at least the sentence the word occurred in), searching for other hedging expressions. My criteria as to what linguistic devices I included as hedges are defined earlier in the paper. It is also worth mentioning at this point that, although there has been some suggestion that hedging devices can carry over from one expression to another (Skelton 1988b), to avoid inflating the results of my data, I included only those hedges which fell in the same sentence as the word might. I was able to find another expression of hedging in the same sentence as the word might for 328 of the 810 might entries; this yields a percentage rate of 40.49%. I followed the same criteria in my examination of the perhaps entries, and found that 103 of the 282 relevant examples contained an instance of another hedging expression within the same sentence as the word perhaps -- a percentage of 36.52. In other words, around 40% of the hedged might and perhaps expressions were in fact instances of double hedging -- a much, much larger figure than that given by Clyne (1991). This is a substantial figure, examining over 1000 corpus entries. Even if I had been using a very broad definition of hedging, which I have been clear to point out I did not in fact use, 40% is a significantly large enough amount to warrant the claim that, not only is double hedging acceptable, it is quite common. The results of the might and perhaps search give us the beginning of an awareness of the rate of occurrence of double-hedges among already hedged expressions, but what of stronger types of hedges? How common or rare are triple hedges, for example? In an attempt to answer these question, I chose to look directly at an expression of double hedging -- the "may + hedging lexical verb" feature mentioned as one double-hedge collocation by Banks (1994a and 1994b) to see both how often this collocation appears in the total number of may entries, and to see if it tells us anything about triple hedging. The results of my findings are as follows. A Wordsmith search produces a total number of 2256 entries for the word "may"; after narrowing down these entries so that I was left only with the entries where may was followed by a weak lexical verb, I was left with 87 entries. This puts the percentage of may entries taking the "may + weak lexical verb" form at approximately 4%. It is important to emphasize here that this percentage is in no way meant to suggest the overall percentage of double or multiple hedging in the may entries; many of the entries deleted in this specific analysis contained other hedging devices than weak lexical verbs and thus, though they provided examples of multiply-hedged constructions, were not included in the present results. The overall percentage of may expressions which are doubly or multiply-hedged is therefore much higher than 4% -- likely somewhere closer to 40%, as suggested by the might and perhaps entries results. It is also important to point out here that I considered only a rather narrow set of verbs to be "weak" and therefore hedges. That is, my decisions regarding whether or not to consider a lexical verb as "weak," were quite a bit more selective than other researcher's have been, and only included verbs with a very weak level of assertion. For example, I did not include indicate -- the hedging status of which has been debated (Johns 2001) or other more "questionable" verbs. Had I included every non-factive verb encountered in the data (as Crompton1997) does in his taxonomy of hedging), I would have had a much higher figure of between 300 and 400 entries (13.3 % of all may entries for 300 entries) fitting the "may + hedging lexical verb" structure. As it is, though, I selected only 87 "may +lexical verb" entries, and of these 87, 26 entries -- 29.9% -- had an additional hedging device in the same sentence. Again, this is quite a significant number. The data set is perhaps a bit too small to allow for any definite conclusions, but this preliminary analysis places the rate of triple hedging at around 30% of all double-hedged expressions. It would be interesting to examine as well the occurrence of even larger congregations of hedging expressions (i.e. quadruple hedging) to see where this relatively strong occurrence rate drops off). These results show that, despite the narrow criteria I assumed in looking at the data, the presence of multiple hedges in academic text is quite strong; double hedging may occur as commonly as in 40% of hedged expressions, and triple hedging seems to occur at around a rate of 30% of double hedged expressions.
Next, let us turn to the survey. For this, an authentic academic article (Martìn-Martìn & Burgess 2004) that makes use of hedges was chosen and each of the hedges in the first 7 paragraphs of the Discussion/Conclusion section was highlighted and dropped into a multiple-choice format where hedges of greater and lower strength framed the original. Survey respondents were then asked to choose which of the multiple-choice expressions seemed most appropriate to the sentence, without knowing what expression actually occurred in the original. There were a total of 29 multiple-choice sets, a double-hedged choice was given in 17 of these 29 sets. There were 4 double-hedge expressions in this section of the original article and all 4 were presented as options in the relevant multiple-choice set. There were three groups of respondents (all of which work or study at the University of Michigan): four undergraduate students in the school of LS&A, all of which are native speakers of English; nine non-native English speaker graduate students from various fields; and eight teachers of academic writing at UofM's English Language Institute (a center for ESL teaching, testing, and research). In considering the completed surveys, I attempted to assess several elements: one is how likely the respondents were to choose double-hedged expressions as an appropriate choice (and to compare these choices to the double-hedged expressions in the original; another is the level of conformity among the respondents' answers (in other words, were the respondents' answers likely to match up? Or were the respondents at least likely to consistently choose a weak rather than a strong expression or a strong expression rather than a weak expression for a given multiple-choice set); another is whether or not any of the groups had a strong tendency to consistently choose stronger or weaker expressions than the original expression (this could indicate a tendency to underhedge or overhedge); and, of course, I did my best to note any other interesting trends in the data. The results from each group are given, followed by a comparison of the different groups' results.
We start with an examination of the NS undergraduate group. The four undergrads picked a total of 5 double-hedged expressions (several of which were picked by more than one person for a total of 11) as an appropriate choice; three of the respondents chose 2 double-hedges and the other respondent chose 5, giving a group average of 2.75 double-hedges chosen as acceptable by each person. Of the 11 chosen as acceptable, only 2 were not double hedges in the original. In other words, the undergraduates usually chose double-hedged expressions where a double-hedge appeared in the original. However, only 3 of the 4 originally double-hedged expressions resulted in a double-hedged choice by the undergrads. Specifically, the double hedge "may imply" which appeared in the original was never chosen, and a stronger expression always selected instead. It is interesting to note as well that the undergrads had a strong tendency to correspondingly select expressions that were either weaker/same or stronger/same than the original. In other words, for only 3 of the 29 multiple choice selections was there disagreement over whether the appropriate expression should be stronger or weaker than the original. In addition to the 3 expressions over which there was conflict, 12 of the expressions were chosen as weaker or the same, 12 were chosen as stronger or the same, and for 2 of the expressions, only the exact same expression was chosen as appropriate by the undergrads. Although the undergraduate sample may be a bit too small to offer definite conclusions, one can note some interesting features of this data. One is that, overall, the undergrads seem to have a sense of how much hedging is appropriate in a given clause, with many of their answers matching the original expression and most others differing from the original only by one or two degrees of strength. Another is that, given their equal tendency to choose a stronger or weaker expression, they seem unlikely to suffer from a tendency to underhedge or overhedge. Indeed, if anything, the undergraduates may have a tendency not necessarily to underhedge, but perhaps to avoid the use of double-hedges, as their average number of double-hedged expressions chosen was a bit lower than the number of double-hedged expressions in the original. However, the general results of the study show that the undergraduates have a fairly good grasp on hedging techniques (at least in recognition, one can't conclude in regards to production from the results of this survey) and the fact that they have chosen a few double-hedge expressions here and there shows that, though they may not always believe it the best option, they consider double-hedging the appropriate choice in some cases.
Next, let's turn to the NNS graduate students. It is worth mentioning that all of the graduate students in this group are presently taking an ELI class to help with their dissertation writing, indicating that they have either a need for or an interest in ameliorating their EAP skills. The nine graduate students picked 4 double-hedged expressions as the most appropriate choice (several which were chosen more than once for a total of 15), with an average of 1.666 double-hedges selected as appropriate by each person. Only 2 double-hedged expressions which were not double hedges in the original were chosen as the most appropriate. Just as with the undergraduate group, the majority of the double-hedge selections were double-hedges in the original article as well. However, 2 of the 4 expressions which were double-hedges in the original were never chosen by the grad students; instead, a stronger selection was always chosen in its place: "may imply," which was also never chosen by the undergrad group, and "would seem." Perhaps the modal complexity of the expression "would seem" was a bit difficult to interpret for the NNSs, leading them to instead choose a more straightforward option like "seems." The grad students also evidenced a tendency to agree on whether an expression, if it differed at all from its original, should be weaker or stronger than the original. In 6 of the 29 expressions there was some disagreement -- at least one person chose a stronger option while at least one other chose a weaker option, but the other 23 expressions showed agreement. For 13 of these, the grad students chose the same expression or a stronger one, for 9 of these the grad students chose a weaker expression, and for 1 of these, every grad student chose the same expression as that in the original.
Let us turn finally to the ELI writing teachers, eight of whom responded to the survey. 12 different double-hedges were picked as appropriate by the teachers (as with the other groups, several of these expressions were picked by more than one person for a total of 32 double-hedge expressions selected). In the case of the teachers, all 4 of the originally double-hedged expressions were selected as appropriate by at least one person -- though the groups of teachers conformed with the other groups in that "may imply" was chosen very infrequently -- only twice. The other 3 originally double-hedged expressions appeared quite often among the double-hedge selections, and in addition to these 4 originally double-hedged expressions, 6 other double-hedges were chosen by at least one person (and, interestingly, in many cases by more than one person). The average number of double-hedge expressions per person for the teachers is 4.125 -- much higher than both other groups and very close to the original number of double-hedges. It is interesting to note here, however, that while the average fell at around 4 double-hedged expressions, only a couple of teachers' choices fell in range of this number. In other words, while some teachers picked 6, 7, or as many as 8 double-hedged expressions as appropriate choices, others chose only 2 double-hedges as good options, and in two cases, only 1 double-hedge was selected. This indicates that personal style perhaps plays a role in hedging, though to what extent, and whether this is a feature only of EAP teachers and not EAP students is not clear. Moving on, the teachers also, unsurprisingly, showed a strong likelihood to agree, in the case of difference from the original, on whether an expression should be stronger than the original expression or weaker than it. For 5 of the multiple choice sets there was some disagreement, but the remainder showed consensus: in 9 sets, the appropriate expression was chosen as stronger than or the same as the original, in 13 cases, a weaker (or the same) expression was chosen, and in 2 cases, only the original expression was chosen as the appropriate option. This falls in interesting contrast to the ELI students, whose results were the exact opposite: 9 were chosen as weaker or the same and 13 as stronger or the same.
In sum, the average number of double-hedged expressions selected as appropriate choices was highest for the teachers, a bit lower for the undergraduate native speakers, and lowest for the ELI students. No group had a significant tendency to choose stronger expressions rather than weaker expressions or the original (which could indicate a tendency to underhedge) or vice versa (which could indicate a tendency to overhedge) -- though the small differences pointed out above may have some significance; for example, if we can consider the tendency to choose expressions of a certain level of strength as evidence of use, it is possible that ELI students use stronger language/less hedging in their writing than ELI teachers. It is not clear if this stronger use of language would be a problem, but it would not hurt to make the ELI students aware of this tendency and to clarify that multiple hedges are a useful and acceptable strategy. We have seen also that each group has a tendency to follow the same patterns (all going strong/same or weak/same the majority of the time); the ELI students have the strongest level of disagreement, but they are closely followed by the ELI teachers, so it's probably not a result of their lack of knowledge of the language (the disagreement among ELI teachers may also be a result of stylistic preferences, as discussed earlier in connection with the average number of double-hedges chosen by the ELI teachers). Assuming that teachers have authority on the subject, (which, it must be emphasized, is indeed an assumption) the fact that the ELI teachers chose double hedges more than any other group may indicate that both groups of students are not using double hedges as much as they should, or at least could. Also, the ELI teachers' double-hedge selection average is the closest of the three groups' averages to the actual number of double hedges in the original article -- a bit of evidence for their perhaps greater understanding of the phenomenon, though one can not draw conclusions on rights to authority from this little bit of evidence. Although not many options were given, triple hedges were never chosen by any of the groups, indicating that they're not terribly common (recall that the Hyland data showed they were certainly acceptable -- that is, they occurred, but that they occur significantly less frequently than double hedges. While the undergrads and ELI students would likely benefit from a clearer understanding of hedging practices, it is not my intention here to give the impression that the situation is grave and serious for these students. First of all, although the student respondents examined here tended to select multiple-hedges as appropriate options at a lower rate than the teachers and at a lower rate than that which occurred in the actual article, the rate of difference was not so large as to be alarming, and, although I'd like to think that the results of the survey give some indication of actual use in the respondents' own writing, this does not necessarily mean the students will be perceived as underhedgers. Secondly, although the rhetorical culture of the US has tendency to put a lot of the onus, in the case the communicative burden, onto the writer, we should remember that many readers make allowances and would likely not be overly disturbed by a bit too much indirectness or a bit too much directness; as long as students aren't making unwarranted dangerous claims in their writing or hedging so much they make no claim at all, no great damage has been done.
In this section we have examined the frequency of double-hedging among hedged expressions and the presence of triple hedging among double-hedged expressions through a corpus search, and we have looked at attitudes towards multiple hedging by both students (native and non-native English speakers) and teachers of EAP and have made some inferences about levels of multiple-hedge use among these groups.
We have established quite strongly that, no matter what beliefs were held in the past, and no matter what disapproving attitudes remain today, hedging is a common, legitimate, and useful rhetorical strategy. We have also established that multiple hedging, though it can be overdone, occurs quite frequently and is a useful technique for expressing strong degrees of uncertainty. Hyland's corpus of academic research articles has shown us that hedged expressions occur in the presence of another hedge up to 40% of the time, and that these double hedges are in fact triple hedges somewhere around 30% of the time. We have also seen that, although students may use multiple hedging less, double-hedges are considered acceptable options by students and teachers of academic writing. Further research could attempt to assess students writing, looking to see if multiple hedging does indeed occur less than in the writing of so-called experts; research into the influence of stylisitic preference on the use of hedging could also be beneficial. Pedagogical theories and their practical counterparts, textbooks, should take research such as the present into account, and more textbooks would do good to follow in line with Academic Writing for Graduate Students by mentioning multiple hedging as a useful and appropriate option. In the end, it seems that, despite what some researchers may think and despite any lingering pejorative connotations associated with hedging, hedged expressions, including multiply-hedged ones, are, as Banks (1994) says "a requirement of scientific journals" and an important technique for any scholar of EAP to have up her sleeve. As it may be difficult for less experienced writers to consistently select an appropriate level of hedging (due to the nuances of lexical selection), teachers and EAP teaching materials must strive to make it as clear to students as possible where this comfortable middle ground is found. It is my hope that studies like the current one will help to turn this goal into actuality.

Speech and writing have usually been seen as two totally different media; the differences between them can be significant in some languages, such as in Chinese and Arabic, whereas in other languages, such as English, the writing reflects speech somewhat more closely. However, even in English, the style, syntax, and wording of the written language are vastly different from the actual spoken language. The distinctions have been eroded by the new-age technology that gives people the power of communication at their fingertips. E-mail, for instance, takes aspects of both spoken and written language to form a new genre; in this new genre, "proper" grammar or punctuation is not enforced for purposes of expediency. Even further melding of speech and writing occur as a result of the new phenomenon of instant messaging (IM). In this paper, I explore the similarities and differences between IM and face-to-face conversations, using data gathered primarily from my IM conversations with members of my singing group that is part of an IM group.
The main instant messaging program that is used among college students today is America Online Instant Messaging (AOL IM, or AIM). According to studies by Thurlow & McKay, 2003), "70% use [the internet] for instant messaging. These statistics are higher for older teenagers at...83%." I started using this program in 1999 simply because many of my friends were using it at the time to chat. "Recent AOL research on 7,000 young people shows that the internet has in fact become the primary communication tool for young Americans." (Thurlow & McKay, 2003) It is different from most other instant messaging programs because it allows you to place your buddy's "screen name"s (usually creative identities to be used online, such as HockeyChik03 or BaBygUrL701) on your buddy list. It is safer and more intimate than most other chatting or IM programs because only those who know the exact screen name can IM that person. When a member on your buddy list is online and available to talk, the screen name will appear on the list and you can IM the person simply by double clicking their screen name and entering text into the IM window. Messages that are already entered will move up on the screen and new IMs will appear at the bottom. IMs are instantaneous -- they take less than a second to be sent to the other person, so conversations move as fast as one can type. Furthermore, you can have multiple IM conversations at once by having more than one IM window on your computer screen.
The data used in this study is taken from IM conversations with members of Gimble A Cappella. Gimble is a student-run a cappella singing group that began in 1997 as a part of Arts Chorale. Currently there are 17 members, ranging from freshmen to graduate students from various fields of study; each of these members were selected into the group through a music audition that demonstrates their musical abilities in various areas. I have been in Gimble for five semesters, the last two of which I have been the music director of the group. About 15 members of the group use AIM regularly (though all 17 members do have screen names) and these are the people with whom I talk most frequently via IM, mostly because we have similar interests.
Below is a sample IM text from a conversation that took place about two months ago:
The names on the left that appear before each IM line are the screen names, Mallee01 and SunE13. A conversation this size takes approximately five minutes, which can be longer or shorter depending on how much of a pause there was between IMs.
Instant messaging contains aspects of both writing and speech. It is similar to writing in that the discourse has to be written and read in order to be understood, and therefore places a certain importance on spelling and punctuation, while eliminating the focus on pronunciation. All the intonation, emphasis, and mood must be portrayed solely through the written text. However, instant messaging also resembles speech in that the syntax of the utterances found in IMs are usually incomplete sentences, while it is enriched with exclamations, expressions, and even laughter. Furthermore, IM takes on the reciprocal characteristic of face-to-face conversations; Cook (1989) states that "discourse is reciprocal when there is at least a potential for interaction....The prototype of reciprocal discourse is face-to-face conversation." Because IM is mainly used for social interaction and is carried on by reading and responding to each other's message, the level of reciprocity is high. As is the case with face-to-face conversations, what one says on IM depends entirely on the way the person on the other end responds; this leads to a complex system of back-channeling, as we will discuss later in the paper.
Face-to-face and IM conversations both take on the use of subject-initial ellipses, in which the subject of the clause is elided, but understood to be there:
In the first clause the subject I is elided, and in the second clause the impersonal it was left out. This type of construction is typical of speech and is a frequent syntactic element in instant messaging. Similarly, contractions such as "gonna", "wanna", and "kinda"that are common in speech also appear often in IM. This shows how instant messaging closely reflects the elements and style of spoken language.
Although instant messaging greatly resembles face-to-face conversation, due to the special text-based manner of conversation and the growing need for expediency in the age of technology, differences do arise. For instance, IMs tend to have shorter conversational turns -- in fact, almost a third of the turns are one-word responses. IM conversations look to express things in the simplest ways possible to minimize typing; if a message is going to be a long, complicated utterance, the person doing the messaging (or IMer) will break the utterance into parts. Consider these two samples from two different conversations:
Both of these IMers used multiple lines1 to separate what would have been a long strain of words. This is often done in order to simplify the utterance and make it easy to read and process; typing a long paragraph may turn the other person off from reading the message. Also, by cutting the utterance into parts, it keeps the interest of the reader because he/she knows that another message is on its way.
Face-to-face (F2F) conversations differ from IM in that the turns can be dominated by certain individuals, whereas turns and flooring in IMs are fairly equal most of the time. Example 1 is a perfect example of this; the first part of the conversation is Mallee01 discussing her plans, while SunE13 listens and sympathizes: "ahh" and "is that why you can't make it to the gig tomorrow?" In the second half, they reverse roles so that SunE13 is now complaining about her schoolwork, while Mallee04 supports by prompting, "are they in hard classes?" and "those are always time consuming." Neither person dominates the conversation, but they take turns speaking and listening in an equal, complementary way.
Often times in casual speech, many of the articulated sounds and syllables (particularly those that are most frequently used) are shortened or combined for speed and ease of pronunciation. For instance, the utterance "I'm going to class" may be shortened from [aim goiŋ tu klæs] to [aŋgoinə klæs]; most native English-speakers would have no trouble understanding the latter articulation of the utterance. Similarly, in instant messaging, frequently occurring phrases or words are often abbreviated or take on acronyms, and they are mutually understood by those who are familiar with instant messaging. Some are fairly obvious and easy to decipher:
Some are a little more difficult:
Others take a considerable amount of imagination:
Generally, these abbreviations and acronyms arise to save time in typing everything out; rarely will you see anyone writing out "be right back" when the simple "brb" can be used. Expert users of IM can usually tell if the person to whom they are talking is new to IM when he/she types out phrases and words that are typically abbreviated, or if he/she hyperextends by shortening a word that is usually not abbreviated (or using the wrong abbreviation), such as "ty "for "thank you".
Younger IM users tend to utilize more abbreviations in order to be "hip" or unique:
r (are), 4 (for), b (be), y (why), 2 (to/too), wuz (was), sry (sorry), wut (what), thanx
In fact, some of these are not much shorter in abbreviation form, but rather they are alternate spellings of the original word to make the statement look more interesting. By college, these types of abbreviations are considered to be too childish, flighty, and superficial; they are generally avoided and used only in mocking or joking.
An interesting phenomenon that occurs exclusively in instant messaging is the ability to have overlapping conversations, or talk about two different topics at once with the same person. Consider the following IM conversation:
Due to the fact that while one person is typing, the other person can't see what he/she is saying (until the message is sent), often times the conversation topics will overlap. Lines 1, 3, 4, 5, 7, and 9 discuss having Friday classes, and lines 6, 8, 10, 11, 12, and 13 discuss breaks between classes; one can see the two clearly distinct topics by reading the lines in the two groups mentioned above. Although overlapping conversation topics such as this can technically occur in speech, it is a much more common trend in instant messaging as a result of the way the timing of IM conversations take place: a few seconds to read the other person's message, a few seconds to type a response, and a second to send the message. Given that in IM these steps do not happen all at once, double conversations can easily occur.
In instant messaging there is a difficult task in establishing a balance so that "speech" can be converted in writing form and still retain the essence of conversation. Without being able to see or hear each other, the IMers are not able to express or discern the sense of intonation, emphasis, or mood behind the utterances, which play a significant role in F2F conversation. However, to overcome this possible communication block, text-based manners of expression have manifested themselves in IM. For instance, repetition of letters signify the elongation of the sound:
Capitalization is used for emphasis, or to show yelling:
The use of ellipses indicate pauses, unfinished thought, uncertainty, or keeping a statement open-ended (usually a sense of drifting-off when used at the end of an IM):
The asterisk indicates a self-correction of a mistake and is comparable to the act of going back and correcting oneself in speech.
Also in response to the impersonal nature of communicating via internet, users of instant messaging often try to express their individuality and style by the creative use of fonts, sizes, and color in the text. One person may use 12-point bubbly font with a yellow background, while some may use 10-point green script with a gray background; these choices usually reflect the creativity and personality of the user. Still further expression of individuality can be shown through the buddy profiles, buddy icons, and away messages. Buddy profiles are basically there to provide others with personal information, but many people use it for other creative purposes; profiles can contain telephone numbers, famous quotes, song lyrics, links to websites, shout outs to friends, inside jokes, or even daily updates about one's life in general-a heart-to-heart of the day, perhaps. Buddy icons are small pictures that appear on the bottom left corner of the IM window that can be used to individualize oneself. Away messages are selected when the IMer has to leave the computer but wants to stay signed on so that he/she can still receive messages. Away messages range from simple ("at class, leave a message") to elaborate ("SO much to do today, class 10-1, work 1-5, meeting 5-6, dinner 6-7, then out to study for the rest of my life...kill me NOW"). With the use of fonts, sizes, color, as well as buddy profiles, icons, and away messages, IM users can express their different style and personality without voice or physical appearance.
Also as a consequence of not being able to see or hear each other, it is often hard to tell whether the person is listening to what the other is saying. In speech, back-channels, such as "yeah" and "uh-huh" is often used to signify that one is listening while the other person is telling his/her story. Similarly, a text-based system of back-channeling has developed in IM; not only does it let the other person know that you are listening, but it also ensures that you get a message back. There are six major types of back-channeling that occurs in instant messaging. The first method is through the use of smilicons, small faces that can be used within an IM conversation that convey expressions and emotions. There are 16 standard smilicons available to use on AOL IM: the smile, frown, laughing, crying, embarrassed, innocent, foot-in-mouth, lips-are-sealed, surprise, kissing, money mouth, sticking-out tongue, cool, wink, angry, and undecided. Usually, a ☺ is used to respond to something pleasant, and a ☹ for something sad or disappointing. The smilicons can be used in isolation to indicate that you're listening:
Here, the frown indicated to SunE13 that Nirone83 is listening and sympathizes her, and prompted SunE13 to continue speaking.
The second method of back-channeling is through laughter, as is also common in speech. The standard laughs are "haha", "hehe", or "lol", which occur in almost every IM conversation. There are also some alternate types of laughs, such as "muahaha" (evil laugh) and "hee hee hee" (giddy laugh) that convey slightly different feelings of laughter3. Expressions of laughter are not necessarily in response to something humorous, but rather as a friendly comment indicating light-heartedness:
Other common classes of back-channels used in IM are affirmative responses (such as yeah, yup, good, yes, sure, sweet, cool, yay, and okay), sympathetic responses (such as oh man, awwww, dang, that sucks, and that's craziness), and neutral responses (such as ahhh, oh, and hmm). These types of back-channels reflect the content and mood of what has just been said, which indicates to the speaker that the listener is paying attention.
The last type of back-channeling used in instant messaging are questions that are used to prompt the speaker to keep talking, such as "why's that?" or "what did she want?" It encourages the speaker to elaborate on what he/she has just said with the knowledge that the other person is listening and is interested in what he/she has to say.
Instant messaging has become more than just another mode of communication -- it is one of the primary ways that college-age students in the United States keep in touch with one another. Due to the ease and efficiency of communicating with multiple people with the tips of your fingers, more and more college students use IM for social interaction. Through frequent use, instant messaging has become a genre of its own, an offspring of writing and speech with its initial roots in e-mail; users of IM have found creative ways to get past not being to see or hear each other in order to emulate the complexity and personal nature of face-to-face conversation, but retain the speed and accessibility of instant internet communication.

No one would question that there are fundamental differences between spoken and written language. Many features, including formality and spontaneity, are inherently different between these two types of discourse, although, of course, a text's features depend heavily on the context in which it is found and other factors. On the other hand, certain similarities exist between the two types of communication, and some features of one modality may parallel those of the other in function.
One phenomenon that helps illustrate this point is the concept of repairs and reformulations in speech. When one speaks, "there is no going back and changing or restructuring our words as there is in writing" (Cook 1989: 115). However, although a previous utterance cannot be erased from history, further elaboration of it can often alter the way it is interpreted. This is where repairs and reformulations enter the picture, providing speakers with the ability to change what he or she just said, at least to a certain extent. Use of these methods can be helpful in many situations, ranging from the frivolous (a joke being misunderstood among friends) to the serious (a statement being misinterpreted in court). The cases under consideration in this analysis fall somewhere in-between: the academic discourse that constitutes MICASE.
Locating previous research on a similar theme was difficult. Bruti (2004), however, has conducted similar analyses of reformulations across a set of biology textbooks, called the Pavia biology corpus. She examined this corpus for instances of the phrases "namely", e.g., "and that is". Her methods of gathering data and making observations with respect to semantic equivalence, expansions versus reductions, and the like have helped shape the foundations of this paper. Of course, the fact that Bruti analyzed written sources makes a comparison with MICASE a bit questionable, but this paper is not going to take much of her data into account, only her techniques.
In beginning my research, I (with assistance) brainstormed phrases that one might use when he or she wanted to fix a speech mistake, clarify an idea, or rephrase an ambiguous utterance. In so doing, several examples came to mind, often as part of a set of phrases with slight variation (i.e. "that's what I meant,"
Next, the apparently relevant results were sifted through and any data that did not involve repair were excluded. An example of one of these misleading utterances was the use of "meant" as "intended but foiled," as seen in the excerpt "I meant to bring a book to be able to read you this uh this big long quote." These and other similar instances of the phrases were removed from consideration. Due to the large amount of potential data, any utterances that I judged as "questionable" were eliminated, so some repairs were most likely thrown out because they were not obvious at first glance. The final data set was composed of 387 samples of reformulation.
I then divided these instances of repair words (which appear in contexts which I judge to involve repairs) into four categories, or types. These can be summed up in the following table, setting A as the person who utters the repair word (usually referred to hereafter as" the speaker") and B as a fellow conversant or passive listener. The types vary in their combinations of three parameters: who uses the repair word, who makes the mistake in speech, and who corrects the mistake.
Type 1 repairs involve a speaker making a mistake and then correcting him or herself using a repair word. Type 2 is where a speaker makes a mistake and a listener corrects him or her, and the speaker agrees with the reformulation using a repair word. Type 3 occurs when a speaker corrects a listener's mistake using a repair word, and type 4 involves a speaker asking a listener for reformulation of a mistake he or she made, using a repair word in the request. For the purposes of this paper, types 1 and 2 were considered self-repairs, as the person using the repair word is the one who had originally made the mistake. (Of course, the "mistake" does not have to be a factual error; it is simply a statement that is perceived as less than ideal by someone in the situation.)
Lastly, I looked at the data and, for each phrase, I separated the data into instances of expansion and reduction. This has been done only for the self-repairs, and only those classified as type 1. The amount of change between the original utterance and the reformulation was noted, especially with respect to any discrepancies in length.
The total instances of each repair phrase found in MICASE are shown in the following table. These are broken down according to the type of reformulation found in each instance.
Type 1 repairs can be further broken down into those that are made immediately and those that are delayed, being brought up later in the conversation. However, only three instances of delayed self-repairs were found in the data (two using "meant "and one using "misspoke"), so separating them in the data seems a bit superfluous.
Following are the specifics of each phrase: if the reformulation is an expansion or a reduction, how changed the reformulation is from the original statement, and any further comments that are warranted by the data. Illustrative examples are given for each of the three contexts using each phrase, if applicable.
This phrase is used mainly in the context of expansions, as when explaining a concept or giving examples that illustrate a point ("it is a call to personal and social transformation. in other words we can imagine and reconstruct various ways of creating sustainable relationships with each other, between partners between partners and children at different stages of our lives"). In second place for the amount of data found are reductions, reformulations that state the point succinctly ("men and women, have and they should have equal roles in both family care and work and public involvement, in other words both men and women should be, full human persons"). The remainder of the data could not easily be classified into either of these categories, as the reformulation contained about the same amount of information as the original statement ("the labor movement which rose in the late nineteenth century in this country championed the middle-class white family ideal. in other words they tried to raise the male wage to the level, where the wife could become a full-time housewife").
Reductions are the most often used reformulations with this phrase, and one particularly common type is to specify the concept after explaining it ("he's throwing, kind of an, anchor off. notice that she bounces up and down. pulling the boat in, sways. no. kay so that's what i mean by, boat-on-dry-land schtick"). Expansions are relatively common as well, where the speaker elaborates a term he or she has brought up ("what clinicians call body angst, or i like this term better, bad body fever, alright, and i_ what i mean by that is a continuous internal dialogue with the self, about what's wrong"). The type with the fewest representations is the same-length reformulations ("sometimes i refer to that as, vertically-dominated region of the rack and what i mean by that is the vertical motor, is the critical motor there").
Half of the instances of this phrase are found in the context of expansions, occurring especially often when defining technical terms ("they're called clades, and clades is another way of call -- of saying monophyletic group"). Also quite common in this group were reformulations of about the same length, when just rephrasing a concept using different words ("one way of putting it is that all the laws, of physics... work equally well, in any inertial frame of reference. and, another way of putting it is, the concept of absolute motion, so-called, whether that you're definitely moving or not"). Reductions appeared in the lowest proportion, mainly summing up a long initial utterance ("with anybody at least in a public situation i mean that, you sort of go out of your way to be polite and to not offend, um, and, and i suppose another way you can get at the same phenomenon is the ques-is in the notion of being honest").
This phrase is most often found in the context of expansions, to explain an idea in more detail ("so when i said they were free i quote they were free relative to going out into the world and looking at each sensor value"). Close behind are the reductions, summing up the previous statement in a few words ("this sort of misinterpretation of the Bible doesn't, occur in our world. yeah. i just quote specifically that. oh okay"). Less frequent in these instances, although still found, are reformulations of similar length and structure ("well i mean there's, three choices. that's what i quote. no three-part i quote to_ just, three choices").
Expansions are the most common types of statements following this phrase, as it is often used to detail an important concept ("uh and yet single women, uh that is to say w-uh, women who were never married or widows"). Next in rank are the reformulations that are about the same length as the original utterance, like simple restatements ("is there a time when independent judgment, and that includes technology, age of technology and science. that is to say, a point when, authority rests in something that is new something that is devised by individuals"). The two reductions involve a summary of what has just been explained ("the attitude that seems more modern to us than we would find in other thirteenth century thinkers that is to say, um, the, the, the utilitarian rule").
The three types of reformulations all have about the same prevalence when used with this phrase. Reductions are used when the original statement can be summed up in a very succinct way ("the concept of the predicate, Namely unmarried, is already in the concept of bachelor"). Next, utterances of the same length appear when the idea is just being put forth in similar words ("so in the c -- does this happen here where you have, basically two options, of characteristics, Namely, two different actions, of a person"). The last group of reformulations using this phrase involves expansions, where more detailed phrases are used in the second position of the utterance ("we've got some kind of, thing that needs explanation here Namely the fact that, every time we think of things we think of them in terms of time").
Expansions are found most often for this phrase, as would be expected, as it is often used to give examples or illustrations of an idea ("you're going from a sound here that's labial i.e. involving articulators that are in the front of the articulatory apparatus"). Reductions come about when the definition of a word is given before the word itself ("so trade, calculated in terms of a multipurpose medium of exchange and standard value, i.e., money"). The lone instance of a similar-length reformulation appears when the speaker substitutes another phrase with the same meaning, in this case a name ("you know outside the little cottage, that he shares in Berkeley with Alva Goldbrook i.e. Allen Ginsberg").
The reformulations using this phrase tend to have quite long, detailed follow-up utterances as the second part, and these are often not given immediately after the original utterance ("at this point, uh let me clarify at this point most of the te -- most of the texts a vast majority of the texts brought from India"). Most of the examples have a second part that follows quite far behind the original utterance, making it difficult to judge for certain what kind of reformulation it is. In addition, many of these examples are rephrasing an overall concept, although instead of summarizing them, the reformulations are also composed of detailed statements.
The corpus' only examples of this phrase are in the context of expansion, pinpointing the details of an unclear concept ("so all these circles represent goods which can be either, you know, a task or a resource. um, on this end, I have these box so uh you might another way uh another way to rephrase that might be, that, tasks are, resources that are supplied by other, agents"). If there had been more examples, same-length reformulations would very likely also have been found, since the word demands a fairly equivalent or more-detailed explanation in the second half.
This phrase was only found in contexts where the reformulation was an expansion of the original statement ("um, i'm now looking at injury prevention um, more specifically as a component of child advocacy"). By definition, this phrase would require the use of a more detailed reformulation, so the prevalence of expansions is no surprise. Reformulations of a similar length might be possible using this phrase, but reductions would probably appear awkward and poorly-worded.
The one example for this word came in a type 4 utterance, where a speaker asked a fellow conversant to reformulate his or her statement ("yeah how would you say that? in a nifty little paraphrase like three words. five words. six maybe."). The speaker is obviously asking for a reduction of the original phrase, and one would guess that this would be how the word would be used in a type 1 utterance.
The one instance of this phrase is used as an expansion, and the speaker uses it a bit strangely ("no it's it's wrong to look at it as the elites, spreading it to the masses that was a, a misspoke, on my part. it's that these we -- tended to be mass movements, with new kinds of leadership, that hadn't been seen, in these parts of West Africa before"). Considering that this is just one example, and the usage of it is not grammatically correct, it is not a particularly convincing argument for the context of the phrase. It is likely that this word can be used for expansions and same-length reformulations, though not quite as much for reductions, since it implies an actual error in the original utterance, and this would probably require a longer explanation for the sake of clarification.
The following table and chart illustrate the totals calculated across all twelve phrases in terms of expansions, reductions, and same-length reformulations.
Of all 359 instances of self-repair (type 1 reformulations), expansions made up more than half of the total. This shows a very clear tendency for people to follow announcements of self-repair with an elaboration of the original utterance, providing more rather than less information in the new statement.
This pattern does not seem particularly surprising, given speakers' intuitions on the concept. Giving an explicit announcement that a concept will be fixed implies that the repair will be easier to understand and thus, most likely, more detailed and informational than the original statement. Of course, when a statement can be better-clarified using only a few words, this will be chosen over elaboration. The last option, of using a reformulation of similar length and content, can be used with most of the repair phrases as well, usually when the original utterance has to be only slightly modified. All three of these choices occur in the vicinity of repair words, and they are all represented quite well in the data, though the proportions vary by the individual phrase chosen for a specific context.
Still, even though the results are not exactly surprising, the numbers are quite striking. Perhaps academic contexts tend to stress details at the expense of concise ideas, meaning that patterns of self-repair in different types of corpora would be fundamentally different. This question, however, would require much further research.

Most of the current research being conducted surrounding the newly formed Nicaraguan Sign Language has been focused on the role of children in its creation and development. Proponents of creolization theories which emphasize the importance of the innate capacities of children in language creation and acquisition have cited the events of the language's formation as evidence in support of their theories. This paper, however, will examine the role of adult linguistic input in the initial formation and subsequent development of the Creole known as Nicaraguan Sign Language, in order to determine to what extent (if any) adult input is necessary for a Creole to form. We will review several positions held by scholars supporting primarily child-driven creolization theories, and also several theories stressing the importance of adults in Creole formation. We will then analyze data specific to the case of Nicaraguan Sign Language to compare the actual results of this natural experiment with the competing theories about the nature and origins of Creole languages.
The main questions being asked in this study ask: Are only children necessary for the initial formation of a Creole, or do adults also play a role? Do adults play an innovative role in the subsequent development of the Creole? And, what sources of input are required in order for a grammatically complex Creole to form as opposed to a more simplified Pidgin system of communication? We hypothesize that although children are the driving force in the initial formation of the Creole, adults are necessary for the development of the grammar into increasingly more complex forms. After a preliminary review of the data, it also seems evident that Nicaraguan Sign Language is not one homogenous system, but rather three manifestations of related but distinct communication systems resulting from the same social context (Kegl, Senghas, & Coppola 1999). Therefore, it seems prudent to expect that each of the three forms of Nicaraguan Sign Language will have formed from a different set of input. In other words, the amount of adult vs. child input required for each of the three versions of the language may vary.
There are several terms relevant to the discussion of Nicaraguan Sign Language data that should be clarified. Idioma de Señas de Nicaragua (ISN) refers to the full Creole nativized by the second generation of children, and continuously restructured by subsequent generations. ISN is the only one of the three manifestations of Nicaraguan Sign Language that can be considered a structurally complete Creole. Lenguaje de Señas de Nicaragua (LSN) refers to the signed Pidgin created spontaneously by the first generation of children in the community. Pidgin de Señas de Nicaragua (PSN) is the term used to refer to the more traditional Pidgin used for communication purposes between deaf and hearing individuals. PSN uses a mixture of spoken Spanish lip movements, signs borrowed from ISN or LSN, and common Nicaraguan gestures.
In addition to the Nicaraguan Sign Language-specific terminology, there are several general terms that must be defined. When we use the term Creole in this paper, we will be using the following definition: A full, natural language resulting from the social contact of two or more distinct languages; expanded from a Pidgin. A Pidgin is defined as: A contact language lacking in structural complexity and lexical variety. And finally, because this paper will focus on the role of adult input in the creolization of a language, it is necessary to define the parameters of the term adult : Any person old enough to have passed the sensitive period for first language acquisition (beyond adolescence) or any native user of a mature, historically established and structurally complex language.
The structure of the paper will include an overview of the history of Nicaraguan Sign Language beginning with its origin in 1979, followed by a review of the literature supporting child-driven creolization theories, contrasted with literature in favor of the necessity of an adult role in Creole formation. Following the literature review will be the analyses of texts and data from research on Nicaraguan Sign Language specifically. Finally we will compare the analysis to our initial hypothesis and present our conclusions to the problems outlined above, along with a discussion of the possible linguistic and social importance of those conclusions.
The deaf population in Nicaragua before 1979 consisted of individuals with no access to the spoken Spanish language of their surrounding society, and no network of communication among the deaf members of the population. There was no Deaf community to speak of, but rather a number of unconnected people separated from society by a strong cultural bias toward those with physical disability. The deaf of Nicaragua were generally thought to be cognitively deficient, unteachable in a school setting, and for the most part incapable of caring for themselves. As a result of their isolation from both the spoken language around them, and lack of exposure to any signed languages, the Nicaraguan deaf went through life never learning any language at all. The year 1979 would bring about a cataclysmic change, however, after the Sandinista revolution, the government created an initiative to educate the deaf of their country and opened two schools in the capital city Managua. Approximately 50 deaf children from distinct parts of the country were brought together in the first serious attempt in Deaf education in Nicaragua (Glovin 1998).
The newly created school was poorly advised to use a finger-spelling method in order to communicate with the children (Osborne 1999). Not having had any previous experience with language, the children had no concept of words or grammar, let alone sufficient knowledge of Spanish orthography to successfully communicate by spelling. Initially the children were forbidden from using their hands to communicate with each other or with the teacher in the classroom, but on the buses and during free periods the children began to compare the gestures that they used with their families in order to communicate among themselves. The teachers realized that although they were still unable to speak with their students, the children were somehow communicating with each other by use of rapid and unintelligible hand signals. Mystified and eager to understand what was happening in the school, the government recruited an American linguist, Judy Kegl, to decode the hand signals and explain how the children had been able to spontaneously create their own complex system of communication (Osborne 1999).
Kegl discovered upon her arrival that the signs being used by the then-adolescent first generation of Deaf school-children were more than just gestures, they were part of a complicated system of communication, later named Lenguaje de Señas de Nicaragua (LSN). Even more startling were her observations of the younger generation of children who had entered the school for the Deaf a few years after the first group. These young children communicated with their hands at a much more rapid pace and with a fluidity that the first group of teenagers lacked. The environment of the school in Managua was a mixing pot of languages, each child bringing his or her distinct system of home signs together into a micro society with a need for inter-communication. The result was a Creole, the Idioma de Señas de Nicaragua (ISN). The children had developed a fully complex and grammatically complete sign language, and were using it with the ease of native speakers (Kegl, Senghas, & Coppola 1999).
Kegl and other linguists have been studying the newly formed Nicaraguan Sign Language in an attempt to understand the cognitive processes at work in the creation and acquisition of language. Much of the work has focused on the important role of children and their innate capacity to learn and, in the case of ISN, create language (Bickerton 1984, Goldin-Meadow & Mylander 1990, Roberts 2000). However, there are existing theories about language acquisition and creolization that emphasize the effects of adults, along with the mature languages they use, on the formation of a language in language contact situations (Lefebvre 1998, Singler 1988, Mühlhäusler 1997).
The most well-known and oft-cited proponent of the theory that children are the driving force for Creole formation is Derek Bickerton, with his controversial Language Bioprogram Hypothesis (LBH). This hypothesis states that children are born with specific innate structures in place for learning language. When a child's language-learning program is activated, it uses the lexical information from his surroundings to fill in the structures already programmed in his brain, which according to Bickerton explains the grammatical similarities in Creoles of varying origins. Most relevant to our current study is the claim that creolization occurs within a single generation (Bickerton 1984). In a 1981 publication Bickerton states that "the period at which [a pidgin can creolize] will be decided, not by any internal development in the pidgin, but by the communicative needs of children." For him, therefore, the process of Creolization results not from any construction of language by the community as a whole, but rather relies solely on the requirements of the children to communicate, thereby activating their Language Bioprogram.
Another author who argues that children play the most important role in Creole formation is S. J. Roberts, and although she disagrees with some of Bickerton's interpretations of his data, they both agree that children drive the creolization process. Referring to Hawaiian Creole English: "Older children learned [Pidgin English (PE)] at school or from neighborhood friends, they brought it into the home where younger siblings began to learn it, children then began to speak to their parents in PE while being addressed in the [Ancestral Language (AL)], and eventually parents began to speak with their children in both AL and PE" (Roberts 2000). According to Roberts' interpretation then, the parents were still speaking their ancestral language while the children began the process of language mixing in school. The children then began influencing the adults and eventually the changes spread to the older generations.
A third scholar, Goldin-Meadow, emphasizes the ability of children to regularize and make more complex the input which they receive, producing a language far more developed than that which was presented to them originally: "children can produce language output which exceeds language input, and...children have the ability to organize the pieces of language they receive to produce a linguistic system which is governed by rules not used by the adults in their environment" (1990). Goldin-Meadow, along with Roberts and Bickerton would interpret the events leading to the creation of Nicaraguan Sign Language as evidence supporting the importance of child innovation in the process of creolization.
On the opposite side of the debate are authors who contend that although children may play a part in Creole formation, adults are a necessary and influential component of the process. Lefebvre could actually be considered to argue that adults provide the sole input required to form a Creole. She describes her interpretation of the creolization process: "the creators of a creole language, adult native speakers of the substratum languages, use the properties of their native lexicons, the parametric values and semantic interpretation rules of their native grammars in creating the creole" (1998). In other words, a Creole is formed by taking the rules from each substratum language's grammar and combining them. The process according to Lefebvre is the opposite of Roberts' interpretation, beginning with the mixing of the different adult language grammars which may then be extended and nativized to include children, thereby transmitting the Creole to subsequent generations.
Singler also argues that adults are the creators of Creoles. If one accepts the concept of a Creole as a language with substrate and superstrate influences, as is commonly done in reference to plantation Creoles and other "classic" Creole situations, then by definition there must be a strong adult influence. The substratum language itself is a developed adult model from which the Creole is derived, or at least heavily influenced: "substrate influence, by its very nature, assumes an important adult-language influence" (1988). Of course, this assumption is based on the idea that all Creoles do in fact have a substrate influence. In the case of Nicaraguan Sign Language, however, it is somewhat more difficult to define what the substrate languages are, given that in most cases the home sign systems that the children used were no more complex than a Pidgin, certainly not complete languages themselves, although they would be the best equivalent of a person's native or ancestral language in terms of the elements of a "normal" language contact scenario.
Another proponent of the importance of adults in language change, Mühlhäusler, draws his conclusions based mainly on research about Tok Pisin, a well-researched expanded Pidgin. He acknowledges that the distinction between a Creole and an expanded Pidgin is minimal, and that aside from their historical origins, the complexity in grammar and usage in each classification is comparable. On the topic of adult input in creolization, or the formation of an expanded Pidgin, Mühlhäusler remarks that these complex products of language contact "illustrate the capacity of adults to drastically restructure existing linguistic systems" (1997). Although the supporters of adult input do not categorically deny the influence of children on the process of language change, they stress the importance of an adult model and indicate that adults are in fact capable of significantly changing a language's grammar.
The case of Nicaraguan Sign Language is a nearly ideal natural experiment for testing the competing theories outlined above most closely correlates with the actual events of ISN's formation. We will be using several recent studies specific to Nicaraguan Sign Language development and their data in order to pinpoint what kinds of adult input affected the development of the Creole, and to what extent.
Adult input refers to any of a number of possible sources of input, not to a single readily identifiable source, and not always the same sources in every scenario. So to begin with, it is important to define the parameters of adult input within the Nicaraguan Sign Language context. One study deals not with Nicaraguan Sign Language in particular, but which sheds light on the situation outlines the different possible sources of adult input to a deaf child in a similarly language-deprived environment. In this study by Goldin-Meadow and Mylander (1984), it is suggested that adult input into early gesture systems may have been derived from the following sources: imitations of a hearing adult's immediately preceding gestures, a gesture model provided by the mother from which the deaf child could induce regularities, or thirdly, maternal responses from gestural communications by the child. It was concluded, however, that none of these situations actually shape the development of the children's language, which means that parental input was likely not a factor in the formation of the signed systems in Nicaragua.
Pidgin de Señas de Nicaragua undoubtedly received input from both the hearing and deaf populations. Spanish-speakers influenced PSN by adding a lip movement to the gestural repertoire, a characteristic that is not present in ISN or LSN. The deaf PSN users were also familiar with a more heavily sign-based system (as opposed to iconic gestures), and so some of the arbitrary signs filtered through to the Pidgin (Kegl, Senghas, & Coppola 1999). In the same article, Kegl, et al discuss the interactions between LSN signers with their instructors in the setting of a vocational school. "In the vocational school, the teachers themselves used a mixture of signing and speaking with the students (PSN). The students, in turn, used PSN with their teachers and other hearing staff members" (Kegl, Senghas, Coppola 1999). The communications between adult LSN signers and adult Spanish-speakers constitutes a definite source of adult input influencing LSN, and possibly filtering to ISN learners who use an evolved version of LSN as their input model.
Finally, according to the definition being used in this investigation, all of the LSN and ISN signers who have grown beyond their sensitive period for language acquisition use a crystallized version of the signed language. Their linguistic models are considered to be adult input even if by age they would be considered an adolescent. We will discuss in more depth the effect of adult input from each successive generation of ISN speakers in section 3.3, but here it can simply be said that the older generations of ISN signers are indeed an important source of adult input in the development of the Creole.
The initial contact between the first group of children to come together had a different set of adult influences from the generations that followed, because there was no coherent linguistic model for them to access, apart from the gestures and other movements that accompany speech with semi-regularity. "We believe that in many cases paralinguistic, non-manual gestures used with unconscious regularity by hearing Nicaraguans gesturing to Deaf signers or even to each other at home or in these school contexts may inadvertently contribute to what eventually become grammatical building blocks of LSN and ISN" (Kegl, Senghas, Coppola 1999). Beyond these paralinguistic gestures and rudimentary home signs used by individuals with their families, the initial adult input prior to the formation of LSN consisted of commonly understood motions such as pointing or movements meant to symbolically represent the motion or object itself. None of this input included a means to refer to events outside of the present concrete space of the speaker.
The formation of ISN resulted from a much more coherent language model than the original children were able to access. LSN had already formed by the time the second generation of children entered the school in Managua. The new children were able to use LSN as their main source of adult input, regularizing and making more complex grammar rules than their older peers. The result was, of course, a more complex language, and it seems that even though the LSN model was incomplete, it was sufficient to activate whatever mechanism children possess for native language acquisition. However, even ISN appears to have gone through a relatively gradual creolization process: "Although the first cohort, as children, had access to multiple sources of input (e.g., the interlanguage formed by older students in the early 1980s, family homesign gesture systems, and the gestures that accompany spoken Spanish), the language did not develop its full complexity by 1983" (Senghas & Coppola 2001). A partially formed adult model (LSN) was key for the initial creation of ISN, but the language would undergo further development in the years ahead.
A large amount of research has focused on the changes in ISN's grammar from one generation to the next. Led by Ann Senghas and colleagues, these investigations have revealed the startling speed at which the newly formed Creole is evolving. Investigates the changes in grammar of INS through its first few generations. One recent study by Senghas (2003) separates the participants into three cohorts, depending on the chronological year in which each person entered the ISN community. All of the participants learned the language before the critical or sensitive period for language acquisition, and speak it with a native proficiency. Interestingly, the oldest and youngest cohorts seem to be unaware that their grammars differ; rather, they view the others' version of the grammar rule as incomplete or incorrect. The middle cohort is conscious that there is a difference in the grammars of the generation immediately preceding them and following. Senghas concludes that even after the initial crystallization of the Creole's grammar with the earliest cohort (now the oldest members of the community) the subsequent generations of children entering the community reanalyzed the system used by the older children and made further adjustments to its grammar. All crystallized versions of ISN (spoken by anyone beyond the critical period) affect the formation of the language in each generation that follows.
A similar study by Senghas and Coppola (2001) examines the usage of spatial modulations in two groups of participants, divided according to the year in which they were first exposed to Nicaraguan Sign Language. The results show that the second group (the younger of the two) produced more spatial modulations than the first, indicating that "sequences of child learners are creating Nicaraguan Sign Language" (Senghas & Coppola 2001). The younger members of the group not only learn the grammar from the older members, but they actually make modifications and add layers of complexity that surpass the original model.
As explained in Kegl, Senghas, & Coppola (1999), there are actually three distinct manifestations of Nicaraguan Sign Language, each of which has its own possible set of adult influences. The most complex form of the language, Idioma de Señas de Nicaragua, is a natively spoken Creole which is continually adjusted and added to by each new generation of children that enter the ISN community.
The evidence implies that adult input was necessary for the formation of ISN. The Creole was not in fact fully formed by the first generation of children creating the language, but rather a result of the second generation building upon the adult model provided by their older peers (Senghas & Coppola 2001). Although the grammatical changes in the language took place during childhood, the model is transmitted by adults for future development and stabilization. ISN required both an adult model (LSN) and children's innovation to create and advance the grammar (Senghas 2003).
The Lengua de Señas de Nicaragua (LSN) is a less complex but still systematic form of the language, created by the first generation of children to come together. This form of the language, although not as structurally complex or fluidly spoken as the previously mentioned form, shows the immense creative capabilities of children; the group of children with no experience in any language, and without any coherent model from which to draw, was able to combine each individual's basic system of home signs, used primarily to communicate simple ideas with their families, into the communally accepted system of communication that served as a template for the following generations to build upon. Children seemed to be the principal creative force shaping the new language in its earliest native form. Therefore, aside from a possible lexical influence based on gestures which accompany the hearing population's speech, the formation of LSN appears to have occurred without any noticeable degree of adult input.
The simplest form of Nicaraguan Sign Language, Pidgin de Señas de Nicaragua (PSN), actually developed in parallel to ISN and LSN. ISN and LSN did not evolve directly from the corresponding Pidgin, but rather has developed as a simple means of communication between the Nicaraguan Deaf and their hearing counterparts. PSN contains many more gestural elements than the more complex sign languages used within the Deaf community (LSN and ISN), and it also links many of its manual signs with a mouthed version of the Spanish equivalent. Of the three manifestations of Nicaraguan Sign Language, PSN has the most obvious ties to the surrounding spoken language, and is the most susceptible to adult influence, simply because it is intended to be understood by adult hearing Spanish-speakers. The influence from children on the development of PSN is negligible, and therefore the adult input is the driving force behind its creation.
Although the formation of the three forms of Nicaraguan Sign Language each required a different degree of adult and child influence, we must revisit the main problem that this paper attempts to answer: what is the role of adult input in the formation and development in a Creole ? There are some interesting implications from the different processes required by the two Pidgins of Nicaraguan Sign Language (LSN and PSN), but the answer to our principal question lies with ISN, as the only true Creole to come out of the language contact scenario in Nicaragua. LSN is more structurally complex than the more traditional Pidgin, PSN, and represents the extent to which Bickerton's Bioprogram Hypothesis has some validity, but it lacks the same degree of complexity that full, native languages possess. Therefore, although a relatively complex Pidgin may form within the first generation of children, both children and adults are necessary in order for a true Creole language to form.
It seems that our language acquisition abilities have been evolutionarily programmed to allow us to acquire a socially constructed language from our parents. Nature also limits the extent to which a child can create a language anew, a practical restriction which prevents the spontaneous creation of a new language by countless children born every day. It is possible for a group of children to create their own system of communication similar in complexity to LSN, but it is not possible for them to natively learn a unique and original language without input from the society around them. Perhaps this is nature's way of ensuring the transmission of language through the generations, so that grandparents can communicate with their grandchildren, and so that stories may be passed down from generation to generation.
The findings of this study indicate that language does not and cannot exist in a vacuum. Although children have an extraordinary ability to acquire language and make innovative changes, that ability does not extend to the creation of an entirely new language. Rather, a language can only be fully realized if there is a stable communicative need within a social setting in which there is a constant presence of child innovation. This investigation has focused on the importance of adult input in the formation of a Creole, but it has never been doubted that children provide the creative spark that motivates the language change. It is the balance between adult and child input that allows for not only language structure, but verbal style, culture, humor, in short every aspect of a budding society.

The Michigan Corpus of Academic Speech in English (MICASE) is a compilation of speech spoke by both native and non-native speakers on the University of Michigan campus. The MICASE project was created with the intention of accumulating a corpus of the natural speech produced in an academic setting. It considers a number of different factors that allow for a diverse body of texts. These factors include gender, academic status, language status (native vs. non-native speakers), academic division, discourse mode and speech event type. These categories play an integral role when analyzing this data. English as a Second Language (ESL) instructors can use this information to identify common speech patterns that occur in academic speech in an attempt to better understand how and why common grammar structures exist and are used.
We used MICASE to assist us in our study of the use of the word so , our main focus being on anaphoric so ; as in the sentence "I don't think so ." Some researchers such as Susan Hunston and John Sinclair believe that anaphoric so must be a part of a local grammar. According to linguist John Swales "the heavy restrictions on anaphoric "so" suggest that it may constitute "a local grammar", i.e. a distinctive sub-grammar that is best treated separately from the language as a whole." This leads us to ask the following questions: Where does it come from; what are its uses; when is it used, and why is it unique to English? In this paper we will try to answer these questions based on the results found in the MICASE database.
There are many ways a speaker can use the word so . We will look at the following uses:
Deictic so is used to indicate degree, which usually modifies an adjective or manner. Some examples found in MICASE include:
When deictic so is to be used it is often accompanied by an indexing act indicating the size (or degree) to that of which the speaker is referring. Huddleston examples:
One of the most common forms of the word so in modern-day English is as a discourse marker. We've found that as stated in Discourse Analysis, "Traditional descriptions of their use do not give the full picture of the deployment of words like so and because in discourse"(204). The most common use so as a discourse marker results in a feeling of casualness amongst speakers. The word so is most often found at the beginning of a sentence when being used as a discourse marker. Of the many examples we have found of discourse marker so , here are a few:
Another interesting use of discourse marker so can be found in Discourse Analysis. "One conventional way of signaling the beginning of narrative chunks is with so "
The focus of our paper is on the use of anaphoric so . Some of the many examples of anaphoric so include:
Pro-clause complement with finite antecedent: I think so.
Examples from Huddleston:
Some examples found in the MICASE data include:
Using the word so often expresses a positive sentiment while the word not is used in the negative pro-form. Examples from Huddleston:
In the pro-predicative form, so is used as a predicative complement. The antecedent is usually and AdjP but other categories are possible. (ii. is an examples with a NP antecedent.)
MICASE Example:
In certain cases, so can be used to express surprise or emotion as a reaction to a previous statement. It is important to note, that in the absence of an auxiliary, this so would have to include a supportive do.
According to Huddleston and Pellum, the anaphoric so cannot be placed into a specific word category. The pro-predicative form in 63. can be an AdjP, NP, or PP. A pro-clausal so can be considered a pronoun or a 'noun clause'. so does differ from other NP's in that it cannot functions as a subject.
As previously stated, there are many different ways in which so can be used. Many of these uses cannot be placed into the anaphoric, discourse marker or deictic categories. Because of this we have created this other examples section where we will explain some of the other types of so .
The use of as and so indicate a relationship between the main and subordinate clauses. Huddlston examples:
When so is used as a connective adjunct it marks reason or consequence. Our resource also says that as with many other connective adjuncts, there is an anaphoric component in the meaning "for this reason, as a result of this."
Our final use of so deals with idiomatic expressions. It is often combined to form expressions referring to measurement.
This use of so can be glossed as "or something like that". Another common idiomatic expression is " "
We initiated our research by determining the total number of occurrences of so in MICASE. The database produced 16000 results, from which we took a sample of 500 entries. Of these 500 entries, 4% (20 entries) were Deictic, 79% (395 entries) were discourse markers, .6% (3 entries) were Anaphoric so , and 16.4% (82 entries) were other uses of so . From here we further investigated the use of anaphoric so ; the verbs to which it can be applied and the frequency that these verbs occur in.
We obtained a list of the verbs that take anaphoric so from The Cambridge Grammar of the English Language text by Huddleston and Pullum. The following is a list of the verbs we looked at: imagine, know, believe, seem, appear, afraid, suspect, suggest, think, say, hope, suppose, guess, assume, presume, fear, reckon, tell, gather, and trust. These verbs are all what one may call "mental state" verbs and some are used more frequently than others. We wondered if all mental state verbs could take an anaphoric so but found that many couldn't. For example:
While it perfectly acceptable to say: "A: Do you like this class?" it is not acceptable to say "B: *I like so."
The above examples prove that anaphoric so occurs in an extremely restricted environment and can only be used with some " mental state" verbs. We looked up the following verbs from the Huddleston text to find their frequency in MICASE.
Our results show that the verb "think" is the most commonly used " mental state" verb, followed by "guess", "say" , "believe", "hope", and "seem". Surprisingly, other common verbs that take anaphoric so, such as "imagine", "suspect", and "suppose" did not produce examples in MICASE. We attribute this to the fact that their uses are less common on campus, whereas they might be more common in other contexts. While there were a number of verbs used with so in present tense, only "think" and "say" were used in the past and conditional tenses. Some specific MICASE examples that demonstrated the use of "mental state" verbs are:
While not included on the chart, we also researched other verb tenses but they produced no further examples of anaphoric so . Because of its high occurrence in the MICASE database, we chose to take a closer look at the way in which the verb "think" is used.
We found that there were 152 instances of anaphoric " think so" in MICASE. We thought it would be interesting to compare the number of instances of negated and non-negated think so to see if this grammar structure is more restricted to a positive or negative use. We hypothesized that there would a higher number of non-negated think so, in the MICASE database, but surprisingly found that there was not a significant difference between the two (80 non-negated and 64 negated).
After looking at negation we decided it would be equally important to look at speaker position to see whether or not anaphoric so was more likely to occur with first or second person, singular or plural. Out of 152 examples, we found that the 1st person singular was the most predominantly used form (92.1%), while 2nd person singular was second with only 4.6%. The rest include 1st person plural at 1.3% and ellipsis use at 2.%. There were no examples of the 2nd person plural.
After looking at each of these characteristics separately (negation and speaker position), we decided to combine them to see the frequency of usage. In figure 1.3 one can see that negated and non-negated usage of think so occur almost equally. In figure 1.5 we see a similar pattern in which the negated and non-negated forms of 1st person singular are almost equal in number. While most entries of 1st person singular and plural never occur in form of a question, the majority of 2nd person singular occur in this form. Looking more closely at the chart it is evident that 2nd person singular in the non-negated form occurs twice as much as in the negated form. We interpreted this to occur because the use of negated "think so", as in "you don't think so?" can be used as a polite way to respond to disagreement. There are no occurrences of 2nd person plural in either chart and in that the numbers of ellipsis are equal.
After looking at the grammatical instances in which anaphoric so occurs we thought it necessary to examine whether it tends to occur in certain contexts more often than others and whether or not native speaker status influences its usage. There are many different divisions of speech events in MICASE where usage of anaphoric think so can be found.
We thought that since anaphoric so is often associated with casual speech and perhaps discussions that would spark uncertainty, that it would most likely occur in events where there is more group dialogue and therefore more relaxed speech. This is in contrast to events where authoritative figures are present and when formal speech is expected. For this reason, we think that think so would be most likely associated with speech events such as discussion sections, labs, small lectures, and study groups. The following graph shows the break-down of the occurrences of anaphoric so as they occur in the various speech events.
In looking at the chart one can see that anaphoric so does indeed occur most frequently in categories where there is more casual speech amongst peers in highly interactive settings. With thirty-eight occurrences, the use of think so in the study groups (SGR) by far exceeds all other speech events. Small lectures (LES) places second with 23 occurrences. The laboratory (LAB) and seminar (SEM) settings have similar numbers (15 and 12 respectively). Going down the chart, the event types become more formal and centralized, and because of this the usage of anaphoric so greatly diminishes.
As a result of MICASE being a corpus of the speech at the University of Michigan there are many factors that can attribute to the usage of anaphoric so such as age, speaker status and language background.
Looking at the charts below one can easily see that age and speaker status are closely related. There is a trend between these two charts because people in senior positions of the university tend to be older in age. Therefore, it is presumed that formal language is spoken more often by these speakers in these contexts.
Since so has such a restricted use, we wondered how prevalent it would be in the academic speech of non-native English speakers on campus in the previously mentioned speech events.
To gain insight into how anaphoric so translates into other languages we consulted native and non-native speakers of Spanish, French, German and Hindi. When asked how to translate "I think so" into Spanish, our consultant replied with "Yo Pienso." ("I think"). This shows that initially he did not know how to incorporate anaphoric so into his L1. We later asked how he would translate "Creo que sí" into English, he replied with "I think so." Our consultant for Hindi is from New Dehli, India but has learned Hindi and English concurrently throughout his whole life. Upon asking how he would say "I think so" he struggled to find even a semi-accurate equivalent in Hindi. While he does use anaphoric so in his everyday speech in English, he has never had to apply it in Hindi. These observations combined with other glosses we collected show that while there are structures that express the same idea, there is no anaphoric so in other languages. Here a just a few examples of the structure used for anaphoric so. Glosses are provided in the parentheses.
From here we decided to look at the language background of the speakers who use anaphoric so . We assumed that MICASE would support our hypothesis that non-native speakers would be least likely to use it in their academic speech. Using MICASE would provide us with the most accurate answer for this question. As Ann Mauranen stated, "Because MICASE aims at depicting how English is used on a campus, instead of providing a model of correct or ideal usage, it includes, among other things, a good deal of English spoken by people who would not fit into the category of speakers known as native speakers. In other words, the data has not been subjected to any linguo-ethnic cleansing, but rather it seeks to reflect the reality of English spoken in the characteristic activities of a major American research university" (166). The speaker status in MICASE is divided into four categories: Native Speakers (NS) which are speakers of North American English; Native Speaker Other (NSO) which are native speakers of non-American English; Near Native Speakers (NRN) which are non-native speakers who consider English as their current dominant language and who appear to have native-like fluency and grammatical proficiency; and finally, Non-Native Speakers (NNS) which are non-native speakers of English other than near-native speakers (MICASEweb).
Out of the 152 instances of think so in the database, we found 140 entries from Native Speakers, 7 entries from Non-Native Speakers, 4 entries from Near Native Speakers, and 1 entry from Native Speakers Other. This overwhelmingly confirms the hypothesis that of the speakers cited in the MICASE database, anaphoric so is restricted to Native Speakers of American English. Just as with our small sample of consultants, this data shows the absence of anaphoric so on a larger scale, in international English and in other languages.
Throughout our research we have more clearly defined the grammatical uses of so and more specifically the use of anaphoric so . We found that there are specific mental state verbs that can take this form of so and some like think and say are more commonly use than others. The MICASE data shows that it was only these two verbs that were able to take tenses other than the present. In our sample of 500 occurrences of so , only two of these examples were anaphoric, 95% or 152 of 160 entries of think so were anaphoric. Because the verb think produced the highest occurrence of anaphoric so , we chose to look at it more closely. When considering negation and speaker position of this verb, it was evident that negation did not play a significant role in the usage of anaphoric so ; however it was most commonly found that speakers used anaphoric so in the first person. Over all, the situations in which this structure occurs are those where there is a high level of interaction between speakers in a more informal environment. There appears to be a strong correlation between age and status in the university in regards to frequency of usage of anaphoric so . This is predictable because professional figures tend to be older in age and find themselves in more situations where they occupy formal roles. By far, our most significant find was the difference in usage or anaphoric so between native and non-native speakers of American English. The data shows that 92.1% of the anaphoric think so was produced by Native Speakers of American English, while Non-Native Speakers produced this so only 4.6% of the time. In conclusion, the MICASE data that we collected further proves that anaphoric so should be considered a local grammar because of its heavily restricted use both grammatically and contextually. We feel that in the future, anaphoric so will most likely become more common as the spread of American English takes place throughout the world. If anaphoric so becomes more frequently used, it will be necessary to develop second-language teaching/learning materials that deal with this localized grammar.

The task of recognizing textual entailment is a difficult one that can be approached in a number of ways. The first PASCAL Challenge for Recognizing Textual Entailment (RTE1) received submissions that applied various semantic, syntactic, and statistical methods towards performing this task (Dagan et al. 2005), all of which were based on sound theoretical footing, but none of which achieved eye-catching results.
Within the framework of the RTE1 challenge, a dumb baseline of 50% could be achieved by simply labeling all entailments as true (or as false): in comparison, the highest accuracy achieved by any RTE1 submission was 58.6%. The modest algorithm outlined in this paper achieves an accuracy of 53.8% on the same test set.
The fact that this modest approach outperforms 5 of the 16 original RTE1 submissions (and performs comparably to several of the others), most of which involve much more complicated systems, is indicative of the current plight of RTE. As with any discipline in its early stages, simple systems can offer initial strong results, while the more intricate systems will require further development before their potential becomes apparent (Bayer et al. 2005). (See my other paper for the promising approaches for RTE)
Despite the fact that this paper illustrates that the BLEU algorithm can be adjusted to perform better on RTE, I do not think this is an area that warrants further work. I can imagine certain potential applications for the BLEU algorithm within RTE (e.g. as a metric for comparing the hypothesis H to atomic propositions generated by a RTE system), but the algorithm is not useful on its own as anything other than a baseline.
Before going too far, it will be helpful to briefly outline what exactly is meant by textual entailment. For a more thorough discussion of the textual entailment task and definition, see (Dagan et al. 2005, sections 1-2).
In a nutshell, textual entailment is loosely defined to hold if the meaning of a hypothesis text H can be inferred by an average human reader (using only his knowledge of English and some general world knowledge) given a text T. For example, below are two T-H pairs. In the first, entailment holds (the entailment is judged to be true) while in the second, entailment does not hold (it is judged false)
Many entailments are mere paraphrases,1 while some are more involved and require the application of world knowledge. Entailment is said to be applicable to a number of different fields within NLP (see section 3.2 for a list of the subfields recognized by RTE1), where it is desirable to know whether the information in a hypothesis can be derived from a given source text.
The fact that so many entailments are paraphrases, repeating some or all of T in H, is the main reason that the BLEU algorithm works for RTE. As will be seen, n-grams cannot hope to capture every case of entailment, but the BLEU algorithm can tailored to suit the RTE task.
The BLEU algorithm was created by (Papineni et al. 2002) as a method for judging the performance of machine translation systems. In this use, BLEU compares the output of a MT system (called the test or hypothesis) to one or more human-generated translations (the reference). The score of the system translation is based on the number of n-grams (with values of n that typically cover the range from 1-4) appearing in the test that also appear in the reference, modified by a brevity factor that penalizes the test for being shorter than the reference (on the fair assumption that any two translations should be roughly equivalent in length).
The scoring algorithm goes something as follows:
1. For each i up to N, calculate a score si that is the ratio of the count of i-grams co-appearing in both reference and test (ctest,ref) and the count of i-grams appearing in the test (ctest):
2. Average the values of si. This is accomplished with a weighted geometric mean; the weight wi is typically kept constant for all i (wi=1/N for all i).
3. Calculate the brevity penalty. If the length of the test (t) is greater than the length of the reference (r), then there is no penalty (b=1). Otherwise, the penalty is logarithmically derived from the ratio of the two lengths:
4. Finally, calculate the overall score as the mean of all scores multiplied by the brevity penalty.
Alternatively, all together:
The scoring algorithm described above is that found in Papineni's Perl implementation of BLEU, which was used for the BLEU evaluations used in this study and served as the model for the modified BLEU algorithm described below.
Application of the BLEU algorithm to the RTE task makes sense on the level that an entailed hypothesis will very likely (though not necessarily) contain many of the same words that appear in the source text. Thus, the basic core of the algorithm, matching the co-occurrence of n-grams, remains valid.
However, the relationship between text and hypothesis in RTE is not the same as the relationship between test and reference in MT. The most important difference is that while in MT both test and reference are expected to convey the same information, in RTE the hypothesis is only expected to contain a subset of the information contained in the text. While it is true that in some cases of entailment H will contain roughly the same information as T, it is counter to the definition of entailment that H could contain more information than is stated (explicitly or implicitly) in T.
There are several consequences that derive from this fundamental difference. The first consequence is that it is clear which of T and H should be considered the text and which the reference in the BLEU framework. Clearly, the hypothesis should be considered the test (the equivalent of the candidate translation), since we want to count the number of n-grams in H that also appear in T, and not vice-versa.
A further consequence of this difference is that there is no longer a motivation for the brevity penalty. Entailment hypotheses are very often shorter than the source text, by virtue of the fact that they contain only a subset of information in the source text. Thus, directly penalizing the hypothesis for being shorter than the text is not productive in RTE.
It is a simple matter to eliminate the brevity penalty in the BLEU algorithm, but there is actually a second penalty against brief or truncated hypotheses hidden in the scoring algorithm. This arises from the use of a weighted geometric mean to average the n-gram scores. Although stated earlier in log terms, the formula for calculating sn can be equivalently stated as:
This formulation makes it is easier to see that if si is null for any value of i, then the entire score will also be null. This is extremely harsh in the RTE task because often, due to the fact that the hypothesis is a highly summarized or truncated version of the source text, there will be no n-gram overlap for higher values of n. For example, 63% of the entailment pairs in the RTE1 development set had no n-gram overlap for n=4.2
To rectify this problem (clearly we don't want 63% of our data to have a null score), there are two options: we could use a lower value of n, or we could change the averaging function. It is not desirable to reduce the value of n: 37% is still a significant number of entailments that make use of the 4-gram overlap, and it is likely that these longer phrases represent the algorithm's best hope for capturing syntactic features. Besides, even at n=2, a significant number (15%) of the RTE1 development set would receive a null score. It is preferable to have a continuum of gradated scores than to break the data into essentially null and non-null categories.
The obvious solution is to use a linear, rather than geometric mean. In fact, Papineni et al. state that this same averaging method yielded good results during the development of the BLEU algorithm, but was later discarded because it did not account for the exponential decay in n-gram overlap for increasing values of n. This is less of a concern in RTE, where the main objective of this algorithm is to measure word overlap. Thus, we can use a linear weighted average such as:
In fact, this average score will act as the overall score in our modified algorithm, since there is no brevity factor. The values for si and wi are calculated as above.
The evaluation for the performance of the algorithms was the same as that defined for the RTE1 challenge. Accuracy was measured as the fraction of correctly labeled true or false entailments as produced by the system (i.e. the percentage of judgments that are correct). A second measure, a confidence-weighted score (cws), was computed. This measure weights judgments based on their relative ranking as follows:
Although other measures for evaluation, such as precision, recall, and f, have been recognized as potentially insightful for RTE (Dagan et al. 2005), they were not included in this project because they were not part of the RTE1 challenge.
The RTE1 challenge consisted of a development dataset, containing 283 true entailments and 284 false entailments (567 total entailments), and a test set containing 400 true and 400 false entailments (800 total entailments). In addition, the RTE2 development set consists of 400 yes and 400 no entailments (800 total entailments; they decided to change the terminology, but yes/no denotes the same thing that true/false denoted in RTE1). Thus, the dumbest baseline for all of these systems, choosing always either true or false, is 50%.
The examples for the RTE1 datasets were subdivided into categories: these categories correspond to different areas of NLP and the entailments are representative of the type of texts that arise in that area. The categories in RTE1 were: information retrieval (IR); comparable documents (CD); reading comprehension (RC); question answering (QA); information extraction (IE); machine translation (MT); and paraphrase acquisition (PP). Most systems showed slight differences in performance between these categories.
The first run used the unmodified BLEU algorithm to assign a score to each text-hypothesis pair in the RTE1 development set. For this run and all others, N was chosen to be 4, which is also the default value in the Perl implementation. After running the algorithm on all T-H pairs, a cutoff score scut was determined such that all entailments with a score equal to or lower than scut were judged false, and all entailments with a score higher than scut were judged true.
As mentioned above, the unmodified BLEU algorithm assigns a high number of zero scores on the RTE dataset. In fact, zero is an attractive cutoff point; as figure 1 above helps illustrate, the optimal accuracy on the development set was found to occur at two points: scut = 0.002 and scut = 0.132. Both of these cutoffs give accuracies of 53.8% (299/567). The lower value was chosen, as it is unclear what is represented by the second peak; a cutoff score of zero, on the other hand, has a certain aesthetic appeal.
At this cutoff, the unmodified BLEU algorithm correctly identified 253 false entailments and 46 true entailments, for an overall accuracy of 53.8% (299/567). The difference in number of correct false and correct true judgments is simply due to the fact that the majority of hypotheses received a zero score, thus falling below the cutoff score.
Applying this same cutoff value to the RTE1 test data, the unmodified BLEU algorithm correctly identified 253 false entailments and 163 true entailments, for an overall accuracy of 52.0% (416/800).
Both figures 1 and 2 illustrate that the unmodified BLEU algorithm achieves its peak accuracy with a cutoff of zero, perhaps because this very low score is most likely to capture the false entailments with very low correlation to their source texts. However, it is difficult to explain why the algorithm seems to have an alternative peak at higher cutoff scores: this may be due to the algorithm capturing the very highly correlated true entailments (perhaps from the CD or MT tasks). The distributions also seem to indicate a difference in the nature of the development and the test data sets: the potential peak cutoff at 0.12 in the development data would have an awful performance on the test set.
It is probably wise not to read too much into these distributions, as this system is performing at a level only slightly higher than random guessing. The best way to think about the unmodified BLEU algorithm as a RTE system is that it is a binary function: a zero score predicts a false entailment, while a nonzero score predicts a true entailment.
Since it was specifically altered to give fewer null scores, the modified BLEU algorithm provided a distinctly different distribution of scores than the original BLEU algorithm. It also achieved higher accuracy for the RTE1 development and test data
As before, we chose the optimal cutoff score scut based on the performance of the algorithm on the RTE1 development set. The ideal value was determined to be scut = 0.221; this corresponds to the maximum accuracy, as can be seen in figure 3. At this value of scut, the modified BLEU algorithm achieved 57.8% accuracy (328/567), correctly identifying 131 false entailments and 197 true entailments.
The system did not fare as well on the test data: using the previously determined cutoff score, the modified BLEU algorithm managed only an accuracy of 53.8% (430/800), correctly identifying 160 false entailments and 270 true entailments.
As a side note, if the algorithm were allowed to re-train based on the test data, the best possible accuracy would be 55.3%, using a scut of 0.1333; see figure 4. This may be an argument in favor of lowering the cutoff score for future applications.
Considering that there seems to have been a significant difference in the make-up of the two datasets in RTE1, it is worthwhile to investigate the performance of these two systems on a new dataset: the development set for the Second Recognizing Textual Entailment challenge.
The RTE2 dataset is slightly different in format consists of the categories IE, IR and QA from above, as well as text summarization (SUM). The RTE2 data were chosen "to provide more 'realistic' text-hypothesis examples, based mostly on outputs of actual systems" (Bar-Haim 2005), and thus one may expect that the datasets will be different in some ways from the RTE1 datasets.
Using the same cutoff score of scut = 0.221, the modified BLEU algorithm achieved an accuracy of 60.4% (483/800) on the RTE2 development data set. Thus, whatever changes the developers made to the datasets seem to favor the n-gram approach.
Likewise, the unmodified BLEU algorithm was tested on the RTE2 development set, achieving 56.0% accuracy (448/800) using a cutoff score of zero.
The RTE2 results at least partially validate the choice of cutoff score for the modified BLEU algorithm assigned by the RTE1 development data (0.221). The revised cutoff score based only on the RTE2 development data would be 0.2580, yielding an accuracy of 61.4%, only 1% higher than the accuracy achieved with the original cutoff score. Looking over the results of the RTE1 development and test data combined with the RTE2 development data, it seems best to keep the cutoff score near 0.22.
At this point it seems appropriate to bring up the work of Pérez & Alfonseca from the first RTE challenge. Their submission consisted of an implementation of the BLEU algorithm, but I have been unable to replicate their exact results. From their pseudo-code it would seem that they implemented a variation of the BLEU algorithm that used a weighted linear mean to average the scores. However, they do not mention that they have modified the BLEU algorithm from the version proposed by Papineni et al., nor do they give any of the details of their implementation.
I experimented with a modified version of the algorithm that included the brevity factor but used the linear rather than geometric mean, hoping to match their results. I was unable to come up with the cutoff scores they reported, although I managed to obtain loosely similar accuracy values.
Below I summarize the results of Pérez & Alfonseca's BLEU implementation, my unmodified BLEU implementation, and the modified BLEU implementation. The table contains the accuracy values for these three systems, as well as the best system in RTE1 for comparison:
While the table above illustrates that the modified BLEU algorithm proposed in this study outperforms the unmodified BLEU algorithm and the BLEU variant implemented by Pérez & Alfonseca, it also points out that none of the BLEU-based systems achieve accuracies close to the best system in RTE1, and this gap is not likely to be closed. In the next section, I will discuss the role of BLEU as a baseline in RTE and look at some other promising approaches to the RTE task.
(Bayer et al. 2005), in their submission to the RTE1 challenge, rightly point out that RTE is a difficult task and that until the complex systems are able to get their many components working well together the simple systems will outperform them. They warn against trying to "climb a tree to get to the moon" (quoting Dagan). In this sense, the BLEU algorithm is a tree; it gets us part of the way towards the solution, but inevitably leads to a dead end. It may have a role within a larger system, but the future of RTE is such that a simplistic n-gram approach will not be successful on its own.
The BLEU algorithm is not meant to be anything more than a baseline for RTE, thus it is not productive to spend much time pointing out its deficiencies. An example or two will suffice to show why an n-gram model will always fail on certain types of entailment pairs.
For example, consider the case where the entire hypothesis H appears as a clause in the text T. The BLEU algorithm will assign this a score of 1, since every possible n-gram in H also appears in T. However, this does not ensure entailment. Consider the pair:
Our first reaction might be to question the somewhat arbitrary relationship we came up with earlier, treating H as the test and T as the reference in the BLEU algorithm. However, changing this assignment accomplishes nothing, since the labels T and H can similarly be reversed in the above example to yield another false entailment that achieves a BLEU score of 1.
While problems such as this clearly show that BLEU is deficient as a stand-alone algorithm for RTE, it has potential applications as a moderate baseline and possibly as a final stage in more complex systems. One could imagine, for instance, a system that generates atomic propositions from T and uses the BLEU algorithm to compare these propositions to H.
Reading through the proceedings of the first RTE challenge workshop, it is clear that there are several interesting approaches being taken towards the RTE task. Below I list a few of my favorites, giving only a general sketch of how they work.
I group these together because even though there are some basic differences, they share a similar concept. Both approaches use dependency-tree structures to represent the T and H sentences (or clauses), and then use some procedures to calculate the difference between T and H in terms of the cost required to transform one tree/graph into the other.
Minimum tree-edit distance algorithms use the basic transformations of inserting, removing, and substituting nodes within the trees to find the shortest edit path that transforms the H tree into the T tree (or vice versa). It would be interesting to see a minimum tree-edit distance algorithm for RTE that could incorporate syntactic concepts into its cost calculations: e.g. inserting a "be" verb node into apposition structures to transform them into sentences. This would be a big project in itself! However, I think that there is a lot of room for innovation in this approach and it may offer significant progress in the future. See (Kouylekov & Magnini, 2005), (Raina et al. 2005), and others.
This approach treats entailment as translation, drawing on concepts from the field of MT. T-H pairs in the training set are aligned using software such as Giza++, and "translate" the text into the entailment. (Bayer et al. 2005)'s System 2 is exactly this type of system. Even though they describe it as a "tree" in their analogy above, it achieved the best performance in the RTE1 challenge!
While these systems may fail to directly address the underlying semantic and syntactic principles that define entailment, there is certainly room for improvement, especially in the view of those who hope to merge syntactic considerations with the statistical methods that have such success in MT. See (Bayer et al. 2005), (Glickman et al. 2005), and others.
This is an interesting approach that basically predicts the entailment hypothesis from the source text. A sentence contains several atomic propositions that each could generate an independent sentence; these atomic propositions are compared to the hypothesis to see if any of them matches. See (Akhmatova, 2005).
This is a concept (not really an approach) that is an essential feature of any effective RTE system. There are many types of relatedness between words (synonymy, antynomy, hypernymy, etc.) and a RTE system must be able to use these relationships effectively when performing various comparisons and transformations between T and H. See (Budanitsky et al. 2001) and practically any of the RTE1 submissions.
In this paper I hope to have shown that the BLEU algorithm is more effective in dealing with the RTE task when it has undergone certain modifications, namely eliminating the brevity penalty and adjusting the scoring mechanism to use a weighted linear, rather than geometric, mean. The modifications to the system led to a 2-4% increase in accuracy over all test sets when compared to the unmodified BLEU algorithm.
Despite these modifications, the BLEU algorithm remains nothing more than a baseline for recognizing textual entailment, because it lacks the room to grow and accommodate further improvements. This is not to say that it is useless for the future of RTE; it may potentially serve as a baseline for evaluating other systems and components in RTE, and it may itself act as a component in a robust RTE system.
This study made use of the Perl implementation of the BLEU algorithm by Kishore Papineni (version 4/12/2002).

Vlach has a phonemic system of five vowels. However, when I was building a sound inventory in a previous project involving this language, I recorded a wide variation in the realization of these five vowels. In this project, I will use the Praat software package to perform a close analysis of the nature of some of these variations.
In keeping with the intended scope of this project, I have decided to record the following words (Vlach in IPA transcription, followed by English glosses):
These words were chosen to allow me to compare certain vowel sounds appearing in certain environments. Below I outline the vowels and environments that will be analyzed as well as the comparisons I will make.
To obtain a statically representative set of data, each of the above words was spoken ten times by a native speaker and recorded into a digital wave file. To standardize the speaker's pronunciation as much as possible, each word was recorded within a frame sentence and the list order was randomized.
After recording, the sound files were analyzed using the Praat software. Each of the fifty tokens was isolated and its duration measured.1 The frequencies of the first three formants were measured at three points separated by equally spaced intervals throughout the duration of the vowel: at 1/4, 1/2, and 3/4 of the duration. The formant measurements were obtained automatically by Praat; only in situations where Praat's formant values were clearly incongruent with the spectrogram did I measure the formant frequencies myself. In these cases, the measurement was made by subjectively locating the central area of the formant on the spectrogram in Praat.
The analysis provided ten examples of each of the five vowels being investigated, and for each example, three measurements (corresponding to the 1/4, 1/2, and offset times) of each of the first three formants. To approximate the vowel quality of each token, these three measurements of each formant were averaged together. These values are reflected in figure 1 below, which plots F1 and F2 for each token on a traditional vowel chart.
To give an approximate value for the vowel quality of each of the five vowels being investigated, the values for the three formants were averaged over the ten tokens relating to each vowel. The mean values for F1, F2, and F3 for each vowel (in Hz), as well as the standard deviation for each formant, are listed in the table below along with the mean value (in milliseconds) and standard deviation for the vowel duration.
n.b. In the tables below, all frequencies are in Hz and all times are in seconds.
The tables below outline the average values for F1, F2, and F3 at each of the recording intervals, the overall average values for F1, F2, and F3 with standard deviation, and the average vowel duration with standard deviation, for each of the five vowels.
The vowel chart below plots the F1 and F2 (averaged over 1/4, 1/2, and 3/4) for all fifty tokens:
Fig 1. Vowel chart based on average values for all vowels being discussed.
The vowel chart above clearly shows a similarity between the two realizations of [i], and noticable distinctions between the three environments of [] and []. Below I will discuss the specific data and how it relates to each of the three comparisons I am making.
Based on my transcription of these words, I expected to find that the [] in [] was a lax version of the [] in []: not quite as high and not quite as front. In fact, the analysis showed virtually the opposite result. While there is an audible difference in the sounds, it is not the same as the difference I had supposed. Consulting the tables above, the differences between the vowels are: F1 is consistently lower in [] (avg. 358 Hz) than in [] (avg. 321 Hz); and the vowel duration in [] is significantly shorter (avg. 67 ms) than in [] (avg. 93 ms). However, the vowel chart also shows a fair amount of overlap in the F1/F2 values, suggesting that the difference between the two vowel realizations is minimal.
One cause of these differences is the extreme lack of stress on the [] in []. Because the second syllable is stressed, the initial syllable in the word is barely pronounced at all; resulting in the noticeable shortness of the vowel duration (by far the shortest out of all five vowels). The lack of stress is also quite evident in the spectrogram, where the contrast between the light first syllable and the dark second syllable was striking. I think that the shortness the main reason why I transcribed the word as I did. While the final syllable of [] is similarly not stressed, it has a significantly longer duration because it occurs at the end of the word.
It is possible to suggest an explanation for the difference in the two vowels in terms of the target theory of coarticulation. The final [i] in [] shows a clear, if not especially pronounced, tendency for F1 to gradually rise over the duration of the vowel, corresponding to a lowering of the tongue. This can occur because at the end of the word there are no remaining target positions for the speaker to aim at. This shift in F1 may simply be due to a general relaxing of the mouth at the end of the word, or it may be a controlled movement toward the "ideal" location for this phoneme.
The [] in [] on the other hand, shows much less of a shift in F1, and overall a much higher F1. Both syllables examined here begin with an [l], which has assumes a high tongue position before the vowel. However, in [] the speaker anticipates another high tongue position consonant, [s] ([p] has no target for tongue position), so the tongue is not allowed to relax to a lower point in the mouth as much as in [].
The overall result here is that both vowels are clearly the same phoneme and are in fact realized in a very similar manner. The major observable differences (shorter duration and higher tongue position in in x) could be attributed to the overall relaxation of the mouth that occurs at the end of the word in [] It would be good to see measurements of this phoneme in more different environments to judge the overall range of realizations of this phoneme. It may be that there are tense/lax allophones existing in other environments, or it may be that the only changes that appear in the realization of this vowel are due to the surrounding phones.
Consulting the vowel chart above, it is clear that the [] in [] forms a cluster distinct from that of the [] in [], the [] being lower (avg. F1 683 Hz) and more back (avg. F2 1368Hz) than the [] (avg. F1 607 Hz, F2 1570 Hz). These measurements explain why I transcribed the two vowels differently when recording them, even though they should both be realizations of the final /a/ of a feminine noun or vowel.
A closer analysis of the data can help explain why this vowel is realized so differently in the two positions. Consulting the table above, it is clear that while the [] in [] maintains fairly constant values for its formants over the duration of the vowel, the [] in [] changes drastically from onset to offset. F1 and F2 both experience a rise/fall of over 200 Hz over the duration of the vowel. The resulting effect is that the [] is actually gradually becoming more like the [] over its duration. This is best illustrated by a vowel chart, where we can compare the formants of the two vowels at onset and again at offset:
Fig 2. Formant values for [] in [] and [] in [] at ¼ duration (left) and ¾ duration (right)
The chart above shows the ten values for each vowel at onset, and the ten values at offset. The change is dramatic; while the two vowels are clearly distinct at onset, the [] has shifted to overlap with the region of the [] (which remains stable) by offset.
The conclusion must be that the speaker has the same target for both vowels, but the environment of [] causes the vowel to initially be produced higher and more front/centrally than the actual target. This is consistent with the fact that the vowel is preceded by a velar stop, which we would expect to produce much sharper transitions than the bilabial stop in x. Because the vowel occurs word-finally, there are no future anticipated targets and the speaker is able to fully reach the intended target of the vowel, which is represented by the offset values in both environments.
Based on the previous analysis, it would be reasonable to expect that the first [] in [] would have very similar initial values to the [] in [] , but that the vowel would never fully reach its low, back target values due to the following []. In fact, this is very similar to what is observed, but the difference between the two vowels is much larger than expected.
Referring back again to fig. 1, the vowel chart, it is clear that the first [] in [] is a vowel that is distinct both from the [] in [] and the [] in []. Also, as expected based on the transcription, this vowel is more similar to the [] than the []. However, the values of this medial [] are significantly different than the word-final [] in [] . Even the onset values, which should be very similar since both vowels are produced immediately after a [] sound, are rather different; the medial [] has average onset values (F1 389 Hz, F2 1855 Hz) that indicate a much higher position than the final [] (F1 481 Hz, F2 1738 Hz). Furthermore, the formant frequencies of the medial [] never even approach the final values of the final []; the highest F1 recorded for the [] in [] is around 500 Hz, compared to the final value of 700 Hz for the word-final [].
While the formant values of the first [] in [] do vary over the duration of the vowel (showing an overall increase in F1 of around 100Hz, and a decrease in F2 of around 300 Hz), the vowel is generally stable. The vowel duration is short relative to the word-final [] , which may partially explain why the values do not change more.
The question of whether this vowel is the same phoneme as the [] in [] (and thus also the same phoneme as the [] in x) is difficult to answer based on this data. The difference between the formant values of this [] (in [] ) and the other [] (in []) are significant, and would support the argument that they are in fact different phonemes. It is difficult to believe that the entire difference in formant values could be due to the surrounding consonants. However, to fully answer this question, one would need to analyze the features of word-medial [] sounds, which do occur in Vlach, and also study the distribution of the environments in which these sounds occur as compared to word medial [] sounds.
The best conclusion seems to be that the final [] in [] and the [] in [] are one phoneme, with the same target values (indicated by the offset formant values of those two vowels, indicating a low, back vowel), but the first [] in [] is a different phoneme (a more central, mid vowel). The confusion arises from the preceding [] in [], which causes the low, back vowel to have more mid, central formants at the onset of the vowel. This makes the vowel sound overall more like the mid, central vowel that appears in the first syllable of [].
The results above show that the surrounding consonants do play a role in the realization of vowels in Vlach, as do the stress of the syllable and the position (e.g. word-final) of the syllable containing the vowel. While the variations that appeared in this analysis were generally able to be explained by concepts like the target model of speech production and the locus theory of vowel transitions, larger issues such as what vowels may or may not be the same phoneme, or allophones, or entirely different phonemes, cannot be answered with such a small data set. To answer these larger questions would require both acoustic analysis of more vowels in a number of similar and contrasting environments, as well as a paper analysis of the distribution of the phones. In particular, the [] / [] question could be further investigated by doing a similar analysis to the one above incorporating word-medial [] (which does appear in my word list), ideally in the same or similar environment as word-medial []. This could help explain whether my transcriptions are over-detailed, using two symbols for the same phoneme, or if these sounds are in fact distinct in Vlach.
Below is the randomized wordlist used for the recording sessions. Before the session, the native Vlach speaker and I went over the short wordlist so that he knew which words he would be producing. We also agreed on the frame sentence below:
I prompted the speaker before each sentence with the English word (e.g. "chicken") which he then would translate and pronounce in the frame sentence, (e.g. [] The wordlist was visible to him to read along with the IPA transcriptions as we progressed.
The wordlist consists of each of the five words repeated ten times, randomized / shuffled by hand. Below is the wordlist.

In this project, I comp are affricates to stops and fricatives. In the analysis, the Vlach affricate [] is compared to the stop [] and the fricative [], and the affricate [] is compared to the stop [] and the affricate []. The comparison is based primarily on the duration of the consonants: since an affricate consists of a stop followed by a fricative, the first part of the affricate will have durations that can be compared to the stop consonant (e.g. stop closure duration and stop aspiration duration, if any), and the second half of the affricate will have a duration of frication that could be compared to the duration of frication in the fricative consonant.
I expect to find that the total duration of the affricate consonant is less than the sum of the durations of the stop consonant and the fricative consonant, because phonemically they are all consonants (i.e. the affricate is itself a phoneme, not simply an adjunction of a stop phoneme and a fricative phoneme). I suspect that the overall duration of the affricate will be similar to the overall duration of the stop or the fricative; thus I expect to find that the duration measurements of the independent consonants (stop closure duration, stop aspiration duration, and frication duration) will all be shortened.
A second measurement will be made of the peak frication frequency. This should correspond to the place of articulation of the fricative. Thus I expect to find that the frication frequency for the affricate [] is the same frequency as in [], and similarly for [] and [].
The main part of the experiment will consist of looking at these stops, fricatives, and affricates in word-medial position in two-syllable words. In all cases, the consonant in question will be the beginning of the second syllable, which is unstressed, so that a controlled comparison can be made. As a secondary analysis, these results will be compared to stops, fricatives, and affricates in word-initial, stressed position. I do not expect to find any major differences between the word-initial and word-medial position occurrences, except for perhaps a slight lengthening due to stress. If lengthening occurs, this should be the same for all word-initial consonants; thus the comparison between word-initial stops, fricatives, and affricates should be valid.
The data was acquired by recording the speaker with a solid-state digital recorder (a Marantz PMD660) and a non-condenser microphone in a soundproof recording studio. All recordings were made directly to wave files on a Compact Flash memory card, and then analyzed with the Praat software.
The full wordlist is given in the appendix. It consists of the following words:
Words were chosen to have two syllables: the first beginning with a stop and the second beginning with a stop, fricative, or affricate for the word-medial measurements; and the first beginning with a stop, fricative, or affricate and the second beginning with a stop for the word-initial measurements. Vowel quality was controlled as much as possible while using real Vlach words. Similarly, the consonants were controlled as much as possible, with the notable exception of [], which contains a consonant cluster at the beginning of the second syllable. No suitable two-syllable word could be found at the time that contained the [] word-initially and a single stop at the start of the second consonant.
The careful choice of words was made to facilitate the use of relative duration measurements; in these measurements the duration of the consonant is compared to the duration of the entire word, thus helping to reduce the effects of speech rate (which can have a significant effect on the absolute duration of a word or any part of the word). In this project, both absolute and relative duration values are used.
For each token, the relevant measurements were made from the list below; non-relevant measurements (e.g. frication frequency of a stop) were not recorded. The possible measurements were:
Accordingly, each stop had three relevant measurements (word, closure, and aspiration durations); each fricative had three relevant measurements (word and frication duration, and frication frequency); and each affricate had all five relevant measurements. Each word was recorded ten times: with three fricatives at three measurements each (90 measurements), three affricates with five measurements each (150 measurements) and two stops with three measurements each (60 measurements), this gave roughly 300 individual measurements.
From the above measurements, the total duration of the consonant was calculated (frication duration alone for fricatives; closure + aspiration duration for stops; closure + aspiration + frication duration for affricates). This total duration was divided by the word duration to give the relative duration of the consonant.
Frication frequency was determined by a script1 using Praat's formant-finding capabilities; measurements were taken at two points equally spaced over the fricative duration and then averaged together.
Word duration was taken to begin at the release of the initial stop closure2 and end when the final consonant ended. The first measurement point is rather objective; there is nearly always a clear release point for the initial stop. However, determining the end of the vowel can be subjective, so certain criteria were adopted to control for this. The end of the final vowel was taken to be the point where the first formant and the higher formants begin to disappear: the second (and sometimes third and fourth) formants have a tendency to linger longer into the final aspiration that occurs as the speaker releases excess air after the word.
Frication duration was rather easily measured as starting with the onset of wide bandwidth frication noise, and ending with the disappearance of the same noise. This occasionally left a period of low-amplitude noise that followed the frication but preceded the clear onset of the following vowel, but since this was consistently not included in the measurement, the criterion seems sound.
Stop closure duration is rather easy to measure in word-medial position and does not need to be described much here. See the results section below for a discussion of measuring word-initial stop closures.
Stop aspiration duration was taken to be the period occurring after the visible release burst of the stop but prior to a clear onset of the ensuing vowel formants. This was readily observable in the stop consonant, but not very observable in the affricates. Several affricates had a period of low-amplitude noise following the apparent stop closure release but preceding the onset of high-amplitude, wide-bandwidth noise that signaled the onset of the frication. When this appeared, it was measured as stop aspiration. However, in several instances this phenomenon was not observable; in these cases the stop aspiration was taken to be zero.
The first portion of this section will deal with the results obtained from the word-medial instances of these consonants. Word-initial consonants are discussed further below. Results follow for the key measurements made: consonant duration and fricative frequency.
As expected, the frication frequency remained constant between affricates and fricatives. The table below highlights this similarity:
As the table illustrates, the peak frequency of a fricative consonant or the fricative portion of an affricate is an important measurement that can distinguish between different fricatives (e.g. between an alveolar and a post-alveolar fricative/affricate), yet is consistent between fricatives and affricates with the same place of articulation.
In the results, affricates showed a reduction in closure time relative to stops, and a reduction in frication time relative to fricatives, with a slight overall increase in total duration of the consonant (with a corresponding increase in the relative duration of the consonant). The table below lists these differences.
Below is a graph comparing the durations of the five consonants. The total duration is broken into pre-release (i.e. the closure duration) and post-release (the combined aspiration and frication durations):
The figure illustrates the fact that overall, consonant durations are roughly the same, with affricates being slightly longer than stops or fricatives. The absolute values are generally comparable with the relative values.
Note the significant reduction in closure duration when comparing a normal stop (97 ms) to an affricate (46ms or 51ms). The duration time of the stop closure in an affricate is roughly 50% that of a normal stop.
There is also a reduction in duration of frication noise, although it is not as drastic as the closure duration reduction. For the alveolar fricative/affricate, there is a reduction in frication duration from 139ms to 98ms (70%), and for the post-alveolar from 135ms to 89ms (66%).
The total duration of the affricate is longer than that of either the fricative or the stop, though not as long as the sum of the two. Because the durations of the individual components are reduced, as described above, the total duration of the affricate is only slightly longer than the duration of a fricative or stop by itself. The alveolar affricate has a total duration of 162ms, 17% longer than the alveolar fricative (139ms), and 37% longer than the alveolar stop (118ms). Similarly, the post-alveolar affricate has a total duration of 145ms, 7% longer than the post-alveolar fricative (135ms) and 23% than the stop (118ms).
Similar calculations can be made to compare the relative duration of the consonant, rather than the absolute duration. The relative duration of the alveolar affricate (38% of total word length) is 31% longer than the relative duration of the alveolar fricative (29% of total word length). Likewise, the relative duration of the post-alveolar affricate (36% of total word length) is 9% longer than the post-alveolar fricative (33% of total word length). The alveolar affricate has a 17% longer duration than the stop, and the post-alveolar affricate has a 10% longer duration than the stop.
One interesting and complicating point is the presence of aspiration after consonants and in affricates. There was a clear, though short, period of aspiration following the release burst of the stop [t]. Furthermore, there sometimes appeared to be a similar, short period of low-amplitude noise following the stop closure in the affricates and preceding the high-amplitude frication noise. However, I am unsure whether to call this aspiration or whether it is simply a brief period of time that is needed to build up enough airflow for frication noise to occur at high amplitudes. Regardless, I measured this time period when it was visible, and it does not play a major role in the analysis a) because it is so small and b) because the overall duration incorporates this duration and so is not affected. When it does appear, it is preceded by a visible burst corresponding to the release of the stop closure. However, in some instances the affricate shows neither a clear stop release nor the ensuing period of low-amplitude noise. Below are spectrograms of the affricate [] as it was produced in two different recordings of the same word:
As stated above, I do not think it is appropriate to call this aspiration (as it is labeled in the figure), but rather it seems that sometimes the burst is strong, and sometimes is weak or practically nonexistent. Thus, it does not seem that the burst following the stop release is an essential component of the affricate -- this could be something to study in a perception experiment.
A final point worth discussing is the marked difference in affricate aspiration duration between [] and [] that is obvious in table 2 above. The previous paragraph described the different realizations of [] that were observed, with either a clear burst or no burst. However, the affricate [] was consistently produced with a sort of double burst, which was measured as a stop closure, followed by aspiration, followed by frication. The figure below illustrates this phenomenon:
As the figure above illustrates, there are in fact two visible bursts: the first is taken to be the release of the stop closure, and the second is taken to be the beginning of the frication noise. This phenomenon was consistently produced for the [] affricate but not for the [] affricate.
A word of caution: the data for the word-initial consonants are much less reliable than that for the word-medial consonants. The main reason for this is that the speaker often paused before pronouncing the word, which introduces a significant amount of uncertainty into the measurement of the duration of the initial stop closure. Furthermore, since the initial stop closure was not included in the word duration measurements (see the methods section above), this complicated the matter of calculating relative durations of the initial stop closure.
Due to this difficulty, a partial analysis that ignores the effects of stop closure duration, focusing solely on frication, is given below. In this analysis, I use the same criteria as for word-medial consonants, measuring the word duration as beginning at the point where the initial stop closure is released. The frication data, unaffected by the initial stop closure, is sound. At the end of this section, an analysis including the stop closure data is given, although with the caveat that the data may be corrupted.
Because only the post-alveolar fricative/affricate was measured word-initially, a comparative analysis of alveolar frication to post-alveolar frication can not be carried out. However, the results show a strong correlation between fricative and affricate frequency, and are comparable to the results observed in section 1 above:
Compared to the results obtained for word-medial consonants, the post-alveolar fricatives in word-initial position have a slightly higher mean frequency (by about 150Hz). The standard deviation is also significantly higher than in section 1; since the standard deviation is greater than the difference in mean frequency between word-initial and word-medial fricatives/affricates, not too much should be made of this observation. It may be that the increase in frequency is due to the difference in stressed/unstressed positions, but such a hypothesis would need further data to bear it out (incorporating more than one fricative/affricate and looking at stressed/unstressed positions both word-initially and word-medially).
The table below illustrates the absolute duration of the frication only in the two consonants. Relative values are not included for two reasons: first, relative values were not calculated in section 1 (relative values were calculated only for total consonant duration in the affricate, not for the frication duration independently), so there would be no basis for comparison. Also, the two target words used here were [] and []; the consonant cluster in the second word can be expected to have a longer duration than the single stop in the first word, potentially corrupting any empirical value of the relative duration measurements.
The result here is clearly comparable the result observed in section 1: the frication duration is decreased in the affricate compared to the fricative. Here, the duration of frication in the affricate (85ms) is reduced to 65% that of the affricate (130ms). Recall that the post-alveolar frication duration was reduced similarly to 66% (from 135ms to 89ms) in the word-medial position. Thus it would seem that word position and stress have little effect on the duration of frication in post-alveolar fricatives and affricates.
For the reasons mentioned above, this data should be considered unreliable. However, it is included here for completeness. One set of data with an especially egregious pause was removed prior to calculation of these values, but even for the data which are presented here, problems remain. Below is a table illustrating the stop closure duration and aspiration duration in word-initial stops and affricates:
Below is a figure that illustrates the differences in duration of the three consonants:
This figure shows a similar trend as figure 1(the duration values for word-medial consonants), although here the stop closure measurements must be considered unreliable, resulting in an overall longer length for the [t] values. Notice, however, that the stop aspiration duration is comparable to that observed in results section 1 above; this is not significant for the analysis, but it is encouraging to see consistency where we expect to see it, even if the stop closure measurements are corrupted.
Next, consider the total duration (and total relative duration) measurements. Similarly to the previous section, all of the consonants have a similar duration, and the fricative is slightly longer than the affricate (140ms rather than 130ms). This 8% increase is very comparable to the 9% increase seen in results section 1 for the word-medial consonant. Unexpected is the fact that the total stop duration (150ms) is 7% longer than the total affricate duration (140ms). Quite the opposite result was seen above, where the same comparison showed the affricate duration 23% longer than the stop duration. I suspect that this has to do with the excessively long stop closure of the word-initial stops, described elsewhere in this paper. However, I cannot explain why this lengthening should apply to the stop consonant but not to the affricate. The stop closure duration here word-initially is 127ms, compared to 97ms for the same duration word-medially, a 31% increase. However, the stop closure duration in the affricate word-initially is 55ms, compared to 51ms in the word-medial measurements, only an 8% increase. This is somewhat puzzling, but I suspect it is at least partly due to the inconsistent inter-word pausing that the speaker displayed.
Looking beyond these inconsistencies, the word-initial analysis is quite similar to the word-medial analysis. Further recordings, with special emphasis on avoiding the inter-word pauses, could help reveal to what extent, if any, the lengthening of the stop closure in the stop consonant is a valid feature of word-initial, stressed consonants and not simply due to pauses between words. This might also help explain why this lengthening occurs only for the initial stops, and not the initial affricates.
I would identify three major points of difficulty in this project. One has to do with the recording, one with the measurements, and one with the analysis.
First of all, I feel that the recordings made for this project were less than perfect, although, with the exception of the word-initial stops, the results of the experiment seem to be fairly sound. Nevertheless, during the recording session, there were several points where the speaker stumbled over his words and mispronounced the target words (e.g. saying [] for [] in multiple instances). I attribute this to many factors, including the repetitive nature of the word list and the high degree of similarity in the target words. However, I also think that the printed list I used to prompt the speaker was flawed: I should have used a phonemic transcription rather than a phonetic transcription, in order to mask the underlying nature of the affricates. Furthermore, I used the random number function in Excel to randomize my wordlist; I feel that this was actually worse than a pseudo-random wordlist. It seemed that there were too many instances of the same word being repeated twice or even three times sequentially, and these were exactly the places where many of the speaker's mistakes occurred. Furthermore, the list concentrated some words heavily near the end and others near the beginning of the list; thus, the words were not uniformly distributed over the recording session and factors such as fatigue may have played a role in the results. In future projects I will use a pseudo-random or locally-randomized wordlist.
A second complication had to do with measuring word-initial stop closures. This was discussed above, and I think the best solution is to have a frame sentence that will highlight the distinction between the previous sound and the stop closure (in fact, this was not a problem with my frame sentence), and also to encourage the speaker to say the entire frame sentence at a constant pace. The speaker in this experiment had a tendency to pause before and after the target words so as to highlight it; this resulted in exceptionally long silence before the target word which made it difficult to measure the initial stop closure. Even with a constant pacing throughout the sentence, though, there will still be a slight additional pause between words.
The final complication also had to do with the issue of word-initial stops. The point of release of the word-initial stop closure was chosen as a very identifiable point to measure the beginning of the word, specifically to avoid the problem of the pre-release closure and inter-word pauses. However, this led to difficulties when trying to measure the relative duration of word-initial stop closures: if the stop closure is not considered part of the word duration, then the relative duration calculations are meaningless (in one instance, the relative duration of the closure was over 100%: it was longer than the duration of the entire word! This was of course due to the speaker's pause before pronouncing the target word).
These last two difficulties could have been anticipated ahead of time, and in fact they were: my original conception of the experiment did not include the word-initial consonants for exactly the reasons above. However, I decided to add them to give an additional dimension to the analysis and to have more tokens to include in the data. In fact, I am not sure this was necessary and ultimately it may have added unnecessary confusion to the analysis.
The data in this experiment overall bore out the hypothesis regarding affricates, stops and fricatives. As hypothesized, the affricate was seen to consist of elements of the stop consonant (specifically, a stop closure followed by a release burst) and elements of a fricative consonant, and the duration of these elements was noticeably decreased in the affricate consonant, giving the affricate a total duration roughly equivalent to the total duration of the stop and fricative consonants.
The peak frication frequency in each affricate (alveolar and post-alveolar) was statistically identical to the peak frication frequency in the corresponding fricatives. There was a slight, nearly insignificant increase in fricative frequency of the word-initial, stressed instances of [] and [] ([s] and [ts] were not measured word-initially) compared to the word-medial, unstressed instances. The increased frequency may be due to some aspect of stressing in Vlach, but this needs further analysis, as outlined above in the results section.
Another area that warrants further analysis is the nature of the stop release in these affricates. It was seen that the stop release burst for [] is sometimes very pronounced and sometimes completely invisible. In most cases, the release was prominent, and it would be worth investigating whether the burst is preferred or necessary for perception, as well as what factors contribute to its production (fatigue may be a factor, since it seems that most of these non-burst affricates occurred near the end of the recording session). Furthermore, the double burst phenomenon in the [ts] affricate is interesting in itself, and could also be investigated as a perceptual experiment.

For this project, I will look at measurements of pitch, intensity, duration and vowel quality to analyze stress in Meglan Vlach, which I hypothesize is similar to English stress. Thus, I expect to find that pitch, intensity, and duration of a syllable is increased when the syllable is stressed, and reduced when the syllable is not stressed. It is also likely that vowel quality will be reduced (towards a mid-central vowel) in the unstressed syllables. By measuring the values mentioned above, I hope to confirm that pitch, intensity, duration, and vowel quality are indeed factors in stress in Vlach, and furthermore I hope to quantify these effects to some extent.
Similar to past experiments, the native speaker produced words from a randomized wordlist, which consisted of six instances of each of the following four words:
As can be seen, these four disyllabic words constitute two minimal pairs which differ only in the placement of stress. (Such minimal pairs occur often due to the conjugation of Vlach verbs, which results in pairs such as [] / [], distinguishing present from past tense.) The full wordlist, and the frame sentence in which the words were pronounced, are included in the appendix. To help avoid confusion (due to the similarity of the words in the list), the stressed syllable was underlined and the English gloss was printed alongside each Vlach word. Also, I used a masking guide so that the speaker only saw one line from the wordlist at a time, limiting the distraction of other words in the list.
The words were recorded using a solid-state digital recorder (Marantz PMD660) and a non-condenser microphone in a soundproof recording studio. All recordings were made directly to wave files on a Compact Flash memory card, and then analyzed with the Praat software. A Praat script (included in the appendix) was used to gather the various measurements, as described below.
All files were annotated to denote the start and end of each syllable as well as the start and end of the vowel portion of the syllable. The full syllable was used to measure syllable duration, while the vowel portion was used to measure intensity, pitch, and formant frequency. This was necessary to eliminate any artificial reduction in intensity or pitch due the non-sonorant portions of the syllable (e.g. stop closures). Values for pitch, intensity, and formant frequency were all extracted using Praat built-in functions. See the script for more details.
The built-in functions in Praat were effective for extracting most measurements, but the data needed a minor amount of hand-correction after execution of the script. This included manually gathering some pitch measurements which could not be measured automatically by Praat (perhaps due to the low pitch level in the second syllable), and correcting for some halving in the pitch measurements (several unstressed second-syllable measurements were recorded at roughly 40Hz when they clearly should have been at 80Hz).
The sections below summarize the results obtained for the four features hypothesized to be related to stress: duration, intensity, pitch, and formant frequency.
There was a visible trend relating stress to syllable duration lengthening. The data for the four syllables are summarized in the table below:
The data clearly show that stressed syllables are roughly 10-30% longer than their unstressed counterparts. Interestingly, the magnitude of the lengthening effect varies between word-pairs: the [] pairs show a 35% lengthening effect for both syllables, while the [] pairs show a roughly 10% effect, which is slightly more pronounced for the second syllable than for the first.
Intensity measurements also showed a positive correlation to stress. The data are summarized in the table below:
These measurements show that stressed syllables have a significant increase in amplitude compared to unstressed syllables. For all cases, the increase in dB was around 10%; the word-final syllables [] and [] showed a somewhat more significant level of amplification (16% and 12%) compared to the word-initial syllables (both 10%). This may be related to the fact that word-final syllables naturally have an overall lower amplitude than word-initial syllables, and stressing the final syllable compensates for this effect as well as raising the intensity of the syllable.
The table below summarizes the results for peak pitch. Mean pitch was also measured, but these values closely resemble the peak values and do not offer additional insight.
Clearly, pitch is a significant factor in marking stress, with marked increases for all stressed syllables. The effect is more pronounced on the second syllable (38% and 46% increases) than on the first syllable (19% and 20% increases). This effect can be attributed to the significantly lower pitch of unstressed second syllables compared to unstressed first syllables (note that first and second syllable pitch is roughly comparable in the stressed cases). Thus a possible explanation may be that the speaker naturally has a decrease in pitch throughout the production of the word, but this natural effect is countered when the second syllable is stressed, in a similar manner as was seen in the intensity values.
The four tables below illustrate the effects of stress on the values of the formant frequencies in the four syllables. The trend is to reduce the vowel quality towards a more centralized sound in unstressed syllables; thus the frequency will either increase or decrease depending on the quality of the vowel (a high vowel will be lowered, whereas a low vowel will be raised). This is reflected in the positive and negative values for percent change in the tables below:
The tables above show that each vowel has a slightly different quality when produced in stressed versus unstressed positions. The vowel [] is the most constant, changing its formant frequencies by only a few percent. The vowel [u] in the [] syllable shows the most regular and noticeable change, and the vowel [] in the syllables [] and [] also shows a significant difference between stressed and unstressed realizations. While the tables above show the quantity of the changes in terms of percentages, the figure below helps illustrate the quality of these changes, which all have the effect of minimizing the vowel quality:
Fig 1: Formant chart showing stressed and unstressed vowels.
In the figure above, all instances of the recorded vowels are plotted, and these instances are grouped together with ellipses to illustrate the centralizing effect. The effect is seen most clearly on the [] vowel in the [] / [] pair: the stressed, tense realization forms a distinct group than the lax, unstressed, and centralized realization (with one outlying instance).
The [i] vowels have a less clear distinction between stressed and unstressed realizations: while the unstressed instances tend to be less front than the stressed instances, there is a high degree of overlap between the two groups.
Finally, the [x] vowels show an apparent distinction between stressed and unstressed realizations, but there is a certain amount of inconsistency in their production. While the centralized variant has a significantly lower F1 in most cases, a few examples of the unstressed [] can be seen residing well within the group defined by the stressed instances. Additionally, one instance of the stressed [] lies within the group defined by the unstressed instances of the vowel. Thus, while there is a visible trend to reduce the vowel quality in unstressed syllables, this trend is not always followed, and may not be a strict condition for stress.
The results of this experiment strongly support the hypothesis that stress in Vlach is produced as a conglomerate of effects that include increasing the stress, intensity, and duration of the syllable, and reducing the quality of the vowel towards mid-central values. The strongest of these effects is pitch; values for peak pitch in stressed syllables were between 20-45% higher than values for unstressed syllables. Duration values also showed significant changes: the stressed syllables [] and [] were 35% longer than their unstressed counterparts, and the stressed syllables [] and [] were 9% and 13% longer, respectively, than their unstressed counterparts. Intensity also increased, roughly 10%, for stressed syllables.
The effects on vowels were much less consistent, but clearly vowel reduction does occur for unstressed syllables both in initial and final position. The initial [] in the [] / [] pair showed the least amount of reduction, while the final [] in the [] / [] pair, and all instances of the [] vowels showed clear contrasts between reduced (unstressed) and non-reduced (stressed) variants. However, the [] vowels showed several examples of crossover between groups, which suggests that the vowel quality is not a restrictive feature of stress production; stress can still be produced even if the vowel quality is not changed in the usual way.

This experiment builds upon my previous project, which described the various factors involved in the production of stress in Vlach. This previous project indicated that stressed syllables in Vlach were distinguished by a combination of factors including vowel quality, intensity, pitch and duration of the syllable. For this project, I performed a perceptual experiment that aimed to determine whether it was possible to shift the perceived stress in a disyllabic word by modifying the pitch alone and controlling for the other factors of vowel quality, intensity, and duration. The hypothesis was that by starting with a sample that was neutral in terms of these three factors, the pitch on each syllable could be adjusted to determine which syllable was perceived to be stressed. However, the experiment failed, with the subject identifying only 15 of 290 tokens as having word-initial stress. To understand why this failure occurred, one must consider two factors: the experimental design and the nature of the sole participant in the experiment. This paper is an attempt to find the weakness in this experiment so that future experiments might be carried out with better success.
The motivation behind this experiment was to quantify the role of various factors involved in the perception of stress in disyllabic words in Vlach. Since it appears that at least four factors (pitch, intensity, duration, and vowel quality) are involved in the production of stress, all four of these factors must be somehow accounted for in the experiment. This experiment focuses on the role of pitch, and it was conceived as if it were to be one part of a four-part experiment: the other three parts of this experiment, if carried out, would focus on the three other factors involved in stress.
A major obstacle lies in the task of measuring one of these factors (or variables) in isolation from the others. One of the assumptions of this experiment, which may be flawed, is that is possible to measure the effects of changes in one variable in isolation from the other variables. The assumption is that there exists (in principle) a token that is neutral in terms of stress for all variables. This neutral token, if it were heard by a native speaker, would be perceived as ambiguous. Furthermore, we might expect that if it were repeated several times and the speaker forced to judge whether it had first-syllable stress or second-syllable stress, the speaker's judgments would be evenly distributed between the two choices.
The first step in the design of this experiment, then, was to find a token that was neutral for all stress variables. The second step was to modify this neutral token to create a number of tokens with gradated values of pitch for both the first and second syllables. Finally, the modified tokens, along with several control tokens, were played to a native speaker in a forced-choice identification experiment in which the participant had to identify whether the stress was on the first or second syllable of the word.
For reasons described below, one word was chosen to be used in the experiment, a combination of the words []" he enters", and []" he entered". The first and second syllables were modified over a range of five pitch values, which combined to produce twenty-five tokens with modified pitch. Additionally, unmodified tokens of [] and [] were included as controls. Two additional control tokens were included: one was the neutral token with its original pitch contour; the other was the neutral token with a flat pitch contour. These twenty-nine tokens were repeated ten times each to obtain 290 total responses.
Since it is difficult to modify formant frequencies in Praat, the vowel quality differences between stressed and unstressed syllables could pose a major problem to the design of an experiment such as this one. However, it had been observed in my previous project that the vowel quality does not necessarily change significantly between stressed and unstressed syllables in certain words. Most notably, the final vowel of the word [] was produced either as a low-back vowel or sometimes as a slightly more mid-central vowel, with no apparent effect on the stress. Thus, it was possible to find instances of the minimal pair [] / [] where the vowel quality was independent of stress.
Below is a chart showing the vowel formants from the first and second syllables of these words, as recorded in the previous project on Vlach stress. While there is a visible difference between the vowel quality of unstressed and stressed vowels (both [] and []), there is overlap between the groups. The arrows indicate the values for two tokens identified as having relatively ambiguous vowel quality: token 09 (an instance of []) and token 16 (an instance of []) from the past project.
Due to their neutral vowel quality, these tokens were used as the basis for generating the neutral token that formed the basis of this experiment. (Both token 09 and token 16 were included unmodified as control tokens in this experiment, and both were correctly identified every time. This confirms that they are acceptable examples of both first-syllable and second-syllable stress, despite the lack of any significant vowel reduction. This would seem to justify their use in this experiment.)
Intensity is a significant factor in stress production (and presumably perception), and in order to create a neutral token, the intensity of the two syllables must be relatively equivalent. However, it turns out that it is very difficult to increase the intensity of an unstressed syllable to the level of a stressed syllable because it is so quiet to begin with that the amplification introduces a significant amount of noise.
Therefore, the decision was made to create an artificial token consisting of the stressed first syllable of token 16 and the stressed second syllable of token 09. This would solve the amplification problem and would not introduce any vowel quality problems, as can be seen in the figure above both tokens have very similar formant values for both syllables. Also, this artificial token should include less inherent bias than a token that was produced as an actual instance of first-syllable or second-syllable stress.
The final variable to control for is duration, which was modified using Praat's duration manipulation feature. The duration values were chosen to be midway between the stressed and unstressed duration for the syllable in question. Thus, using tokens 09 and 16 as references, the first-syllable duration was modified to be equal to 185ms (midway between 160ms and 211ms), and the final syllable was left unmodified at 261ms, as the difference between the two final-syllable durations (278ms and 261ms) was deemed to be statistically negligible.1
The duration modifications may have been a weak point in the experiment, as they were based only on the two tokens mentioned above, not on the whole of the data from Project 4 which shows the full range and average values of the durations of these syllables. If the full Project 4 dataset had been used to calculate mean midpoint values for duration, the first-syllable duration would have been 205ms and the second-syllable duration would have been 278ms.
After visually inspecting the pitch contours of the first-syllable-stressed token and the second-syllable-stressed token, the following design was chosen to modify the pitch contours. The first syllable would have fixed start and endpoints, with a midpoint that would vary over a range of frequencies. The second syllable would have a fixed endpoint and a start point that would vary over a range of frequencies. This design is summarized in the figure below:
As can be seen from figure 2, the design produced 25 tokens representing the various combinations of each syllables 5 different pitch values. Values 2 and 4 (and b and d) were based on the actual pitch values in tokens 09 and 16, with additional values added below, above, and between these values to create a gradient. Thus, modified token 2d is very similar in pitch to token 09 and modified token 4b is very similar in pitch to token 16. Thus, one would expect to see similar judgments for those pairs of unmodified / modified tokens.
The two figures below demonstrate the similarity of the pitch contours of these tokens:
This design expects token 2d to be identified as first-syllable stress by comparison to token 16, and for token 4b to be identified as second-syllable stress by comparison to token 09. The other tokens between 1a and 5b would be expected to receive judgments based on, perhaps, the relative pitch of the first and second syllables.
The results for this experiment were indicative of some type of experimental failure. Of 290 tokens, only 15 (including all 10 instances of the control token 16) were identified as having first-syllable stress. All others were identified as having second-syllable stress.
Of the remaining 5, these included the first instances of 4b, 5b, 5c and 3b, as well as a late instance of 2a (likely an error). Tokens 4b, 5b, 5c, and 3b are all tokens that would have been hypothesized to be judged as first-syllable stress by the experimental design. Thus, the experiment seemed to be working as planned up to a point. However, once token 16 was played to the listener, he never again identified any token other than 16 (and the late instance of 2a) as first-syllable stress.
Perhaps the most insightful result is that the unmodified base token, which was presumed to be neutral in terms of stress, was consistently identified as having second-syllable stress. This is a strong indicator that the "neutral" token on which all of the modified tokens were based was not, in fact, neutral.
Some of the comments made by the experimental participant may also be insightful. During the experiment he made some comments: first, he asked how he should respond if the word had stress on both syllables; later, he indicated that he had decided to just always choose the second-syllable option in the ambiguous cases. After the experiment had ended, he indicated his suspicion that some of the recordings had been made by splicing a stressed first syllable and a stressed second syllable, although in a later comment he revealed that he was not certain whether this was the case or whether he had in fact produced the doubly-stressed token himself in the previous recording session.
In his critique of the experiment, he stated that although the various tokens were "moving the stress" from the second syllable to the first, they never fully did so in his opinion. This indicates that the pitch alterations did have some effect on his perception of stress, but that the changes were not enough to fully shift the stress to another syllable. Thus, we should not assume that pitch is irrelevant to his perception of stress.
However, it may be that since the tokens were still not fully natural, he sought another indicator of stress on which to base his decision. In his own words, this indicator was the "length" of the final vowel, by which I presume he means duration rather than vowel quality, although I am not entirely sure. This certainly is a result of using the stressed second-syllable in the creation of the neutral token, and it may suggest that the second syllable duration needed to be shortened more. It is unclear why the second-syllable was perceived as more stressed than the first, since both recordings were in the stressed position.
It is also possible that by "length" the participant meant vowel quality. This is a possible interpretation, since the final vowel was of the non-reduced variety. However, the vowel quality was very similar to that of the [] control token, where it did not seem to affect the perception of stress. Nevertheless, it is possible that the participant chose to focus on vowel quality in the ambiguous, modified tokens, and that in token 16 the vowel quality could be neglected due to the presence of other indicators of stress.
The participant also had questions about whether the experiment recorded his response time to answer the question. This, along with his other observations, indicates that he was actively trying to see through the purpose and design of the experiment, and the results must be considered at least somewhat distorted as a result of this.
To be entirely honest, this experiment may have had design flaws that arose from its hasty preparation. The experiment could have been more robust by including modifications of other factors than pitch, but this was considered too complicated for one project. The flaws of this experiment could be corrected for in future experiments, but this would require more time and probably more than one speaker.
A naturalness judgment option was not included in this experiment, but one might have been helpful. From the participant's comments, it seems likely that all of the modified tokens would have been identified as unnatural to some extent.
One problem with the experiment might be that the intensity of both syllables was left unchanged. While this was done based on the assumption that it is only relative intensity, and not absolute intensity, that matters for stress perception, it would have been a much better idea to reduce the intensity of both syllables to a more neutral value. It may be that the high intensity of the second syllable is what cued the listener to place the stress on the second syllable. Although the first syllable had similar intensity, the intensity may have been perceived as higher for the second syllable by virtue of the fact that the latter part of a word will tend to have lower intensity than the first when no other factors are present.
One conclusion that can be drawn about the perception of stress in Vlach is that there are many factors involved, and modifying only one of these factors results in an unclear stress pattern. In the absence of other factors (i.e. if the control tokens had been absent) it may be that stress alone is enough to shift the stress of a word. This seems to be supported by the very early responses in the experiment, but cannot be confirmed due to the disturbed results for the majority of the experiment.
While one might conclude that this experiment shows that pitch is not a significant factor in the perception of stress in Vlach, I am not too quick to agree with that conclusion. In my opinion, the experiment was flawed and I would like to see the results of using these same tokens, without (or in a separate session from) the control tokens, and using Vlach speakers other than the one in this experiment.
Each token was surrounded by a target sentence, which was the same as in the previous project:
In the list of responses below, the sequence number, prompted token, and response are listed. A response of 1 indicates first-syllable stress, a response of 2 second-syllable stress. The stimulus "unmod" represents the neutral token with its original pitch contour, and "flat" is the neutral token with a flat pitch contour.

Statements concerning the stress pattern of Hawaiian date back to the mid 1800's, when missionaries began documenting the language in order to translate religious texts. Since that time, the conventional wisdom about stress placement was that main stress falls on the penult, with secondary stress iterating every second syllable from the main stress up to the beginning of the word; additionally, any heavy syllables always receive stress. This notion is essentially what appears in Newbrand (1951), the only comprehensive study of Hawaiian phonology.
However, many words of five or greater syllables defy this pattern. In the case of words with five short syllables, two stress patterns are observed, one that follows the description above (main stress on penult, secondary on the second syllable from the beginning), the other with secondary stress on the initial syllable. Schütz (1981) was the first to treat this inconsistency in detail, and provides a descriptive system that works. However, the system he proposes entails that stress placement is irregular, and must be specified for each entry in the lexicon.
Given that stress is non-contrastive in Hawaiian, the stress pattern would be expected to behave with some sort of regularity. This paper seeks to find this pattern, recasting the forms formerly regarded as "irregular" as regular, with deviations from the pattern falling out from an analysis of the morphological/prosodic structure of Hawaiian words. A system is developed which correctly predicts the stress pattern of Hawaiian in a vast majority of cases, using the theoretical framework of Optimality Theory (Prince and Smolensky, 1993/2004; see Kager, 1999, for overview). This paper begins with a description of the phenomena in question, followed by a discussion of the way in which the morphological structure interacts with the prosodic structure. Finally, an OT analysis will be given, using a standard constraint set with little modification.
The description given above, that stress iterates on every other syllable starting with the penult works for words with four or fewer short syllables, and such descriptions are given in much of the older literature on Hawaiian as well as in treatments of related Polynesian languages (Hayes, 1995, Blevins, 1994). Furthermore, heavy syllables are taken to be always accented. For Schütz (1981), a syllable is counted as heavy when it has two mora. Bimoraic syllables include those with long vowels and diphthongs (both long and short diphthongs are understood to have two morae). Diphthongs are any sequence of two vowels with a fall in sonority, plus iu, a so-called "even" diphthong. Schütz' characterization of the moraic status of Hawaiian segments is adopted straightforwardly here. Also, because consonants are disallowed in coda position, there is no "length-by-position" effect in Hawaiian.
Given these two generalizations, that accent iterates on every other syllable starting with the penult and the necessity of stress marking on heavy syllables, stress accent as in (1) is predicted and, in fact, observed.1
a. two light syllables
b. one heavy syllable
c. two syllables, one short diphthong
d. two syllables, one long diphthong
e. three light syllables
f. four light syllables
g. six light syllables
Although the examples in (1) do not exhaust the predictive power of the system described above, they serve to demonstrate the general patterns. The analysis given here assumes that feet are universally bimoraic trochees, without giving recourse to trimoraic feet (cp. Schütz' 1999 analysis of Fijian). Instead of allowing degenerate feet, the grammar of Hawaiian will simply not foot an isolated syllable (e.g. ka(náka) ), instead of applying epenthesis, truncation, or other processes. As seen in (1g), the system as described also accounts for longer forms with an even number of light syllables.
However, the system breaks down in words with five light syllables. The description of this type of stress pattern follows that of Schütz (1981), who also describes similar patterns in Fijian (1999) and Tongan (2001). Under the pattern assumed previous to Schütz' account of Hawaiian, exceptions to the rules are abundant. Five syllable words obeying the pattern are also observed, as shown in (2).
a. "irregular" stress pattern
b. "regular" stress pattern
Clearly, the challenge offered by these data is to account for the "irregular" forms, while maintaining a system that correctly predicts the "regular" forms. As it stands, the data in (2) present an outright contradiction. However, this situation may be salvageable given a different perspective on the regular pattern of stress and an understanding of the way in which morphology interacts with the prosodic structure of the word.
Informally speaking, suppose that the regular pattern of stress placement in Hawaiian is bidirectional, with main stress assigned from the right and secondary stress assigned iteratively from the left.2 Such systems are not uncommon among the languages of the world (e.g. Garawa, Piro, Indonesian; see Kager (1999), ch. 4, for analysis). Now, the words formerly characterized as irregular may be redefined as regular. Given the strict requirements concerning foot structure and stress on heavy syllables, all of the data in (1) are still accounted for.
Now, of course, the data in (2b) go unexplained. A solution presents itself given certain assumptions about how morphology interacts with prosodic structure. Only in certain morphological environments, to be explained below, will the stress pattern in (2b) arise; furthermore, even words with the "regular" stress pattern sometimes have their stress not due to the default process, but also because of morphological structure. In effect, the system proposed here makes a clear prediction concerning words which have five light syllables; the stress pattern will always be as in (2a) whenever the word is composed of a single stem and nothing else.
In the account given below, a "word" or "grammatical word" is defined as a structure composed of minimally one stem, which may optionally contain multiple stems plus affixes and reduplicated structure. Each word in this sense has one and only one main stress. Note that this definition is roughly equivalent to the traditional conception of "word." A prosodic word is defined as a freestanding stress domain, which may or may not have main stress, and may or may not be contained in a larger structure.
The proposal above, that Hawaiian has a bidirectional stress system, applies to all prosodic words, with the assumption that prosodic word structure may be recursive, such that the maximal prosodic word may dominate multiple, word-internal prosodic words.3 Compound words offer the clearest example of this type of structure, although reduplication and affixes will be examined in light of this proposal as well. While an account of stress patterns based in part on morphological structure is promising, care must be taken not to construct a circular argument of the type which Schütz warns against, such that "accent defines the word." Because there is no good etymological dictionary of Hawaiian, claims about internal structure must be made with caution, although there are many clear-cut cases.
With these considerations in mind, two examples below demonstrate how a system that treats each member of a compound as it's own prosodic word simplifies an account of stress. In (3), two five-syllable words with different stress patterns are given.
Although the examples in (3) differ in their stress patterns, their phonetic realization is expected given the assumptions about recursive prosodic structure detailed above. One outstanding problem concerns the placement of main stress versus secondary stress; this issue will be treated below.
Because Hawaiian grammar strictly enforces a foot structure of bimoraic trochees, stress that is assigned from the left edge of the word will go unrealized in a prosodic word of three syllables or less. In each of the cases in (3), stress is assigned from the right in all word-internal prosodic words. However, as is expected, only the rightmost accent in each grammatical word get main stress, even though right edges are always marked by a foot when possible. Put another way, the right edge of the entire word gets main stress, although the right edge of every prosodic word is footed. Although this system may seem complex, such a pattern naturally falls out of standard constraints within Optimality Theory, as shown below. Note that the two processes that mark right edges -- one that foots right edges and the other that assigns main stress to right edges -- guarantee that the right edge of a prosodic word will be footed whenever possible (i.e. whenever the penultimate syllable is not heavy).
In addition to compounds, affixes play an important role in the prosodic structure. Consider the following examples, in which reduplicated structure is treated as a prefix.
The system of stress assignment outlined will account for the varied data above given certain assumptions about the prosodic status of affixes. In the case of suffixes, such as -na in (4c), the affix appears to combine with the stem to form a prosodic word; therefore, main stress falls on the penult despite the presence of the suffix. Prefixes, including reduplicated structure, are treated differently. These combine to form a stress domain. In a case such as (4d), both "prefixes," the prefix -u and the reduplicated material, form an internal prosodic word. The same generalization holds for (4a), in which the reduplicated 'eke is treated as an internal prosodic word, although a prefix in the traditional sense is absent. In the case of (4b), the reduplicated syllable 'a may be treated as it's own prosodic word that is too small to be footed, or as adjoined to the maximal prosodic word; the difference may have import when issues of minimal words are concerned, but the distinction will not be explored here, where the later case (adjoined to the maximal prosodic word) is assumed.
The examples in (4) will, then, have the structures depicted in (4').
Having outlined the way in which morphological and prosodic structure interact, a formal account follows that strives to explain the multiple processes at play, while maintaining empirical coverage of the data.
The rest of this paper shows that the data above is quite amenable to the framework of Optimality Theory (OT). After examining a set of constraints that model the cases in which the structure of the prosodic word is not recursive, examples such as those in (4) will be considered. Since the constraint set postulated within OT is considered to be universal, it is a positive result that the following account only employs constraints that are standard in the literature. All of the constraints considered below are discussed in Prince and Smolensky (1993/2004) and McCarthy and Prince (1993), although many of these have antecedents in previous literature (see references above for overview). Only the domain of application of one constraint will have to be altered from the usual form in order to account for recursive prosodic words.
The first constraints to be discussed account for stress patterns in non-recursive prosodic words that contain light or heavy syllables. The important observations, noted above, are the following: a bimoraic foot structure that is strictly enforced (with no truncation or epenthesis), trochaic foot structure, right edge main stress, heavy syllables always stressed, and secondary stress iterating from the left.
The first constraints necessary for this account are those which enforce bimoraic foot structure and left-headedness, as well as a constraint that ensures the rightmost syllable gets main stress. The standard constraints for this account are defined below.
Additionally, a further constraint is needed to ensure that non-parsing of syllables is minimal.
Since Hawaiian always enforces a trochaic structure, I take RH-TYPE-T to be undominated. Also, the data in (7) show that a constraint such as *CLASH, which militates against consecutive syllables with stress, is very low ranked. Therefore, these constraints will be omitted from the tableaux below, for ease of exposition.
Given that Hawaiian is well documented to strictly enforce bimoraic trochees, while also marking the right edge of the PrWd with a foot, the ranking in (7) is expected.
The following tableaux bear this prediction out.
No ranking argument can be constructed between PASRE-SYL and ALL-WD-RIGHT. Furthermore, it is well attested that the final foot in any word gets main stress, so RIGHTMOST may be assumed to be undominated as well. A final constraint that may be assumed to be undominated appears in (9), since heavy syllables are always stressed. With the constraints discussed above accounted for, the grammar now has the ranking shown in (10), again omitting RH-TYPE-T and *CLASH.
While the grammar in (10) correctly predicts the stress rhythm in any word with less than three syllables, a further constraint must be introduced to account for longer forms. The alignment constraint in (11) serves this purpose; note that this is a gradient constraint, for which any foot removed from the left edge will occur a violation equal to the number of syllables that separate it from the left edge.
This constraint determines the direction of footing in any long prosodic word, while ALL-WD-R(IGTH) only forces one foot to appear on the right edge. ALL-FT-L is dominated by ALL-WD-R, as (12) demonstrates.
Before continuing with longer prosodic words with recursive structure, some words are in order concerning the current state of the grammar, which appears in (13).
Although the interaction between these constraints and candidate forms is completely mechanic, the constraints themselves achieve targets that are "natural" and common among the world's languages. As has been said before, some of these constraints simply impose a foot system based on the bimoraic trochee. The high ranking of these constraints ensures that this foot structure is never violated for any reason. The constraints WSP and RMOST give prominence to heavy syllables and (in a trochaic system) the penult, both common properties among the world's languages. Finally, the alignment constraints enforce the demarcative and rhythmic properties of stress. While ALL-FT-L enforces a rhythmic system of stress, iterating from the left edge of a prosodic word, it is not so important in this grammar as ALL-WD-R, which demarks the right edge of the prosodic word. The tableaux in (14) show that these constraints, with the ranking assigned in (13), select the correct candidate in the cases of pùlelehúa (butterfly) and 'ài:na (land).
The constraints as they have been defined so far allow the grammar to globally evaluate grammatical words with recursive prosodic word structure with almost no change. Since each prosodic word in a recursive structure has exactly the same status, and since the alignment constraints refer to prosodic words as their category of application, the grammar will select the candidate with the observed foot structure as optimal.
The only problem concerns the assignment of main stress. Up to this point, RMOST has ensured that the rightmost foot in the prosodic words gets main stress. Since the grammar will now be faced with words that have multiple prosodic words, something must be changed in order to assign the correct main stress. The domain of application of RMOST will have to be changed to either apply to the "maximal" prosodic word, looking at the morphological structure top down, or will have to apply to the grammatical word. Although the choice may be trivial, the second option will be pursued here. Now, instead of RMOST, the grammar will have RMOST', which is defined as in (15). Note that the addition of RMOST' is used merely as a label for the familiar constraint for the sake of convenience; the constraint has not changed, only the domain of application.
With our modified constraint set, observed candidates are selected as optimal even for long words with complex morphology, when the assumptions concerning the relationship between morphological structure and prosodic structure are adopted. The following tableaux demonstrate this for some representative examples. In each case, the assumed morphological analysis appears above the tableaux; within the tableaux, vertical lines and spaces separate prosodic words that occur within grammatical words.
The tableaux above and in (14) show that the grammar proposed in (13) accounts for a wide range of data that have superficially different stress patterns.4 This result shows that a fuller account of Hawaiian stress can be made when taking the morphological structure of words under consideration. At the same time, the proposal above does not define morphological structure in terms of observed stress patterns, but instead relies upon fairly straightforward analyses of word structure. The critical assumption, that prefixes (including reduplicated structure) and compounds create their own prosodic words within a maximal prosodic word seems not too radical either, when one considers that grammars often use stress to mark morphological boundaries. In effect, the grammar of Hawaiian is one that emphasizes the demarcative and quantity-sensitive properties as opposed to the rhythmic property of stress.

In this project, I explored German fricatives, a sub-class of obstruents, as produced by a native German speaker from Chemnitz, Germany. This paper discusses three main topics regarding the data collected from the speaker. First, I talk about what I expected to find based on a sampling of the literature regarding fricatives in German, including what phonemes the language includes and my data in comparison to those expectations. Second, I discuss important allophonic alternation of palatal and velar fricatives, which are represented in my data as predicted. Last, I discuss a phonemic/allophonic relationship that the literature was not coherent about, initial /r/, and the phonetic realizations of that /r/ in my data.
The literature on German is conclusive about seven distinct fricative phonemes: labiodental /f/ and /v/, alveolar /s/ and /z/, post-alveolar /ß/ and /Ω/, and glottal /h/. Though each of these is considered distinctive and not allophonic, some sounds occur only in certain environments. Namely, there is a fortition rule in German such that voiced obstruents lose voicing when in final position; in other words, the phonemic opposition is neutralized in this phonetic environment (Benware 1986: 22-27, 64-65). Thus, no voiced sounds will occur word-finally; so, the voiced /v/, /z/, and /Ω/ are represented only initially and medially in my word list. Additionally, the voiced post-alveolar fricative /Ω/ occurs only in borrowed words (often from French), so I did not attempt to find minimal pairs of it and other sounds.
My data exhibit each of these seven sounds with typical fricative characteristics: high-frequency intensity compared to other obstruents or vowels, decreasing frequency of high intensity as articulation moves farther back in the oral cavity, and visible formant transitions out of and into flanking vowels-particularly the "velar pinch" evident in velar fricatives where the F3 locus is relatively high and the F2 locus is relatively low. For the most part these were as expected, though in a few instances, the speaker produced voiceless fricatives where I expected voicing to be present. This was not entirely surprising, given that research on German is ambivalent (in my sources) as to whether there is a categorical qualitative phonation differentiation in obstruents. For the voiceless and voiced labiodental, alveolar, and post-alveolar sounds, some authors describe the primary difference between pairs at the same point of articulation as between fortis and lenis, rather than voiceless and voiced. That is, the distinguishing feature between the phonemes is taken to be the amount of respiratory energy used to produce airflow, instead of the activity of the vocal cords. In these cases, what are typically classified as "voiced" fricatives in German are actually considered "lenis," and voicing may or may not be present in a lenis segment (Benware 1986). Because of the discrepancies in the literature, for my project I elicited only what were considered "voiced" fricatives, without attempting to elicit both "voiced" and "voiceless" lenis fricatives; this is consistent with the approach that most authors seem to take, which classifies by phonation rather than respiratory energy (Kohler 1990: 48-49; Ladefoged & Maddieson 1996: 95-99; Moulton 1962: 21-23).
While my speaker's tokens of voiceless fricatives were as expected, several that I anticipated to be voiced were in fact produced without voicing. Namely, the speaker's production of Satz, where initial S is generally voiced [z] (according to the literature, which indicates that voiceless alveolar fricatives rarely occur word-initially), included a voiceless initial alveolar fricative. At first it was unclear whether this was a lenis voiceless or a fortis voiceless fricative. To try to determine which was the case, I took the initial alveolar in Satz and compared it to the medial voiceless and voiced alveolars in hasse ([s]) and reisen ([z]). (I did not include a word with the intended elicitation being voiceless initial [s], because the speaker objected to the single word in any of the literature (Satin) that included initial voiceless [s], saying that it would be no different from Satz. It is especially curious, then, that his articulation of initial s did not include voicing.)
As Fig. 1 shows, the spectrogram for Satz shows no voicing (there is no low-frequency intensity corresponding to a "voice bar"), yet it does have less intensity throughout its duration than does the medial [s] of hasse, which is also characteristic of voiced fricatives as compared to voiceless. And, its intensity follows a similar track as the voiced alveolar [z] in reisen. It also has slightly lower intensity than the final voiceless [s] in Reis. This may suggest that this is a lenis fricative, which most authors would lump into the category with voiced fricatives; however, I do not have a voiced alveolar fricative in initial position with which to compare.
A similar issue arose with the voiced post-alveolar fricative, which the speaker produced without voicing in Rage, as shown below in Fig. 2. Note that this medial fricative has a spectrogram almost precisely similar to the medial voiceless [ß] in Rauschen. He does have a voiced post-alveolar fricative initially in Jalousie; however, he commented that in casual everyday speech, he would likely have pronounced it as de-voiced. Although I can't make generalizations based on this data, it seems that my speaker does not produce voiced alveolar or post-alveolar fricatives consistently.
In addition to the seven fricatives mentioned above, German has a voiceless palatal and voiceless velar fricative that are in complementary distribution. In the literature regarding German phonetics and phonology, the phoneme is usually taken to be the voiceless velar fricative /x/, and the allophone is the palatal [ç].1 The palatal occurs following front vowels and consonants, whereas the velar occurs following back vowels. According to the literature, the velar also does not occur in initial position, though in my data it does occur in what seems to be a variant of /r/ (see discussion below). Hence, the speaker produces the palatal in Chemie where it is initial (despite the voiceless palatal being rare initially, according to Benware [41]), and reichen and reich where it follows a front vowel; he produces the velar in rauchen and Rauch, where it follows a back vowel.
Finally, the most complex aspect of German fricatives in this project was regarding variation in the sound represented in orthography by r, and according to the literature these are variants of the phoneme alveolar trill /r/. Kohler reports that the voiced uvular fricative /Ë/ is a phoneme and can be heard in words such as Rasse; however, the other sources I consulted claimed that the voiced uvular fricative is just one of several possible variants for the German /r/, not a phoneme itself (thus, I did not attempt to elicit it as a distinct phoneme). Other possible variants discussed are the alveolar trill and voiced velar fricative (Benware 1986: 44-45 and 68-9; Russ 1994: 147-149). Benware claims that variation is not phonologically conditioned for the most part and depends instead on dialect differences. Moulton, however, offers a lengthy discussion of /r/, where he says that when prevocalic it is generally a voiced uvular fricative [], but sometimes an alveolar trill [r]. He also discusses alternation in postvocalic non-prevocalic contexts, but I did not have any examples of this context in my data, so I will not discuss it here. I prepared my word list with several initial and medial /r/ tokens in order to explore what my speaker produced in these instances; however, by coincidence, my list also included many more initial /r/ words, so I was able to look at 15 tokens of initial /r/ in a five different following vowel contexts ([o][a][a¨][ˆ][aˆ]), along with five tokens of medial /r/.
Each of the medial /r/ tokens was produced as a velar, and while fahren and Waren are voiceless [], irre and führe are voiced []. The differences are apparent in voice bars in the spectrograms of the latter two, as well as a strong perceptual difference. The medial /r/ context spectrograms (for fahren1, fahren2, Waren, irre, führe) are shown below in Fig. 3.
In initial position, my speaker never produced the alveolar trill [r] (or a trill of any sort), nor did he produce a uvular []; both of these were variants said to be common in the literature. Rather, he always produced a velar fricative, though distinguishing between whether these were voiced or voiceless was often difficult. Some difficulties arose in determining voice quality via my own perception, and there was also heavy seeming coarticulation from preceding vowels often affecting phonation mid-segment. Voiced fricatives usually have either a low-frequency F1 "voice bar," less intensity than their voiceless counterparts, and/or visible vertical striations indicating vocal fold vibration. This was not clearly evident in many of the sounds, even ones that often sounded voiced. This might have something to do with their being prevocalic, or it might be that the lenis/fortis distinction is more relevant here than phonation.
The words whose spectrograms do show a voice bar are shown below in Fig. 4. These include reisen, reif, and Reis. In these sounds, you can see the low-frequency voice bar as well as vertical striations, which are fairly constant throughout the fricative.
In opposition to the above voiced fricatives, most realizations of initial /r/ were voiceless; however, there is wide variety in duration of frication, as well as the amount of voicing present within the fricative. That is, in most cases, the fricative began without voicing -- which is clear on the spectrographic information in that there is no low-frequency energy -- yet some amount of voicing occurred within the latter part of the fricative, evident in the voice bar and vertical striations. For example, in Rasse, total duration of the fricative is about 111 ms, and the last 53 ms of it are with vocal cord vibration -- more than half the total duration of the fricative. Nonetheless, the overall percept is voiceless. We might attribute this to coarticulation due to anticipatory voicing for the following vowel. By way of contrast, the initial [] in rauschen is about 128 ms, but it is only voiced for about 26 ms. This is just one example of the variety in phonation, shown below in Fig. 5.
The only initial /r/ in which at least some anticipatory voicing did not happen is rot, where there is absolutely no voicing preceding the vowel; the difference between it and other tokens is particularly striking and may be compounded by an articulation further front than many of the other velars, so that it has none of the trilling that can sometimes occur in velars farther
back (or in uvulars). The lack of voicing may in fact be an indication of articulation further front, when we consider that the fricatives produced further front seem more resistant to coarticulation from voicing of the following vowel. That is, initial [s] in Satz (which I had in fact expected to be voiced) and [ß] in Schatz, and medial [s] in Jalousie and hasse, for instance, show almost no voicing at all, as shown in Fig. 6 below. This is the case with other tokens of the voiceless alveolar and post-alveolar fricatives; although the palatal [ç] shows a fair amount of voicing in transitions into and out of it in, for example, reichen. So, the tendency for voicing to happen sooner in velar fricatives may be related to proximity to the glottis during articulation; where here, voicing starts sooner in the fricative the closer it is to the glottis. Or, in general, a fricative will be more resistant to coarticulation involving phonation if it is farther from the glottis in production. This makes sense considering that back closures cause a faster pressure drop above the glottis than more front closures (because air escapes the oral cavity sooner), which enables vocal cord vibration.
In sum, I have discussed three aspects of German fricatives as I elicited them from a native German speaker. First, the speaker's realizations of seven of the fricative phonemes were fairly regular, though I found that he did not produce voiced alveolar or post-alveolar fricatives in a few expected places. Second, the speaker's alternation between the voiceless palatal and the voiceless velar fricative was as expected, demonstrating the allophonic variation oft-discussed in the German phonemics literature. Third, in exploring the phoneme /r/, I found that the speaker only produced two variants out of at least twice that many possibilities, both of which were velar fricatives (the voiced and voiceless). His consistent use of the voiceless velar in the initial /r/ position is particularly interesting, given that none of the sources I have listed [] as a sound occurring initially, even as a variant of /r/. A follow-up project would take this as its main focal point, systematically eliciting a variety of phonetic contexts for /r/ to determine whether the speaker does produce [r] or [] in contexts other than what I elicited, or whether his dialect/idiolect consistently realizes [] or [].

The goal of this investigation is to provide evidence towards a universal theory of syllable structure as formulated by Duanmu (2002) following Borowksy (1989). The proposal that medial position syllabic rime is restricted to two slots maximally was demonstrated to be a tenable view in Borowsky (1989). In a departure from the more traditional viewpoint that onset clusters are constrained by principles of sonority, Dunamu (2002) proposes that complex onset clusters in English and Chinese are composed of one slot. Together, the two theories posit a CVX structure for syllable structure. The question remains as to whether this claim can be shown to hold for languages other than English and Chinese. This paper investigates the extent to which standard Dutch con be shown to conform to CVX theory. In section 2, I introduce VX theory as formulated by Borowsky (1989). In section 3, I introduce Dunamu (2002) and the extension of the theory to CVX.
In section 4, I present both sides of the tense/lax versus length vowel debate for Dutch, a pertinent issue in the consideration of our theories application. In section 5, I detail the methodology used in this study. Finally in section 6, I present concluding remarks.
Borowsky (1989) considers the composition of the syllable rime in English, noting that there exists an asymetrical distribution between rimes consisting of two slots and rimes consisting of more than two slots. This asymmetry can be explained, following Siegel (1974), by positing the existence of two levels of morphological affixation, level 1 and level 2. Under the Level Ordering Hypothesis, class 1 affixes, which trigger and undergo phonological processes, undergo affixation at level 1and can attach to free as well as bound morphemes. This type of affixation occurs first. Class 2 affixes, which are phonologically inert, undergo affixation at level 2 and thus can only attach to free morphemes (derived or un-derived words). Below are examples of English affixes classified accordingly (Spencer 1991):
1) Examples of English Affix Classification:
Medial syllables of the form VVC and VCC in un-derived mono-morphemic words and before the attachment of level 1 affixes are very rare. Borowsky proposes that those with more than two slots are limited to word edges, indicating a strict constraint on the syllable rime structure in English at level 1. The strongest evidence in support of this theory is that in English, vowels in medial positions shorten at level 1:
This observation assumes that long vowels take up two slots in English, which, as is discussed below, will not be the assumption made in this investigation of Dutch. The important principle we are testing is that, regardless of what parameter a language takes in defining what constitutes a filled slot, the number of available slots remains universal and constantly V(X), with V being a vowel and X being a variable consonant or vowel.
Borowsky (1989) states the Principle of Structure Preservation:
3) Structure Preservation: language-particular structural constraints holding for underlying representation hold also for derived representation, and vice versa.
This enforces conformity with the Coda Condition. After Level 1 Structure preservation is inactive and syllable structure less restrictive, allowing longer codas and making vowel shortening unnecessary. Thus, only the phonology of level 1 is to be taken as structure preserving.
(Dunamu 2002) extends the Borosky (1989) analysis of medial rime constraints though an investigation of the possible constituents of onset clusters. Traditional accounts of onset clusters are reliant upon the sonority scale. Duanmu notes the following problems with such an account (for English): Clusters which appear to violate the MSD are allowed in English i.e. [lj], English allows clusters composed of sounds in the same place of articulation i.e. [tr] [dr], and many sounds that satisfy the MSD don't appear in English.
Duanmu posits a single slot analysis of onset clusters in which occurring clusters are complex single sounds. Necessary to this are two assumptions: first that words around a syllable need not be a proper part of it (extra-metricality), and second that if a cluster is a single sound it is a good sound, and single sounds must adhere to the No Contour Principle (Duanmu 1994) stated in (4):
Example (4) demonstrates that for a complex sound to be a good sound no singlearticulator can simultaneously produce opposing values of the same feature. In (5), [schr], or [chr] with extrasyllabic [s], is treated as a complex onset occupying one slot only, [aa] is (crucially, for this study) treated as a single slot in the nucleus, and [l] is the coda.
Building on Borowsky's V(X) model, Duanmu thus proposes an articulator based feature theory of syllable structure in which non-final syllables are maximally of the form CVX.
The question remains as to whether such a theory can be proven to hold universally, which is the underlying goal of this study.
As noted above, in order for CVX theory to hold for Dutch, we must have some account of how vowels are to be represented moraically. Discussion of this matter has polarized in two directions. The first supports the view that they are to be represented in terms of tenseness and the second that they are to be represented in terms of length. Both views are discussed below, but for the purpose of this investigation, the tense/lax view is assumed to be correct.
In Standard Dutch, phonetic length coincides with phonetic tenseness to a large degree. It has been a issue of debate as to whether the distinction that both seemingly describe is to be attributed to the feature [+tense] or to length as represented by a geminate moraic structure. Van Oostendorp (2000) and Swets (2004) claim that laxness is the phonological feature underlying the contrast between phonetically long tense and short lax vowels. The most persuasive argument for this account relies upon the distribution of stress in the Dutch stress system. a length based analysis incorrectly allows CVV syllables to remain light while CVC are counted as heavy, which is in contrast to a widely held belief that when there exists a heavy light contrast, CVV counts as heavy.
Van Oostendorp (2000) concludes that a branching rime must be headed by a lax vowel.
Lax vowels do not occur syllable finally, as the vowel would then occur in a nonbranching rime. A branching rime can never be headed b a tense vowel, thus we never see a tense vowel in a CVC-closed rime:
Booij (1995, 2002) holds that systematic opposition between short and long vowels in
Dutch (except for high vowels) can be represented in structural terms rather than via binary feature (such as [+tense]). In a syllable, short vowels can be followed by at most 2 Cs i.e. V(short)CC, and after long vowels only one C can occur i.e. V(long)C (VVC).
Syllable structure is thus held to be more consonant with a theory of phonological length. Under this account, the binary nature of the rime, which consists of exactly two positions, accounts for the distribution of vowels in Dutch.
Example (7) demonstrates that in accordance with an exactly two-slot restriction in the rime a long/tense vowel cannot be followed by CC in its coda as this would necessarily result in three slots. Booij proposes that vowel length is not a purely phonetic property and that long vowels are represented as sequences of two identical [-consonant] segments/phonological units/moras. A long vowel, under this analysis, is a single feature bundle linked to two similar abstract representations.
With strong supporting evidence for both theories, we may conclude that at worst, the issue leans favorably towards both sides and is unresolved, and at best it is clearly in favor of there being one vowel representation, which occupies one slot and which varies in the [+tense] feature. On these grounds we can take the important step of justifying the removal of all VV occurrences in the lemma which are non-diphthongal and do not precede a CC+. Both of these qualifications can be taken up for consideration in the final stages of the study.
The corpus used in this investigation into the conformity of Dutch to CVX theory was a lemma obtained from the CELEX online database of standard Dutch. The lemma represents headwords in non-reducible forms. As stated in the release notes:
The following categories (Table 1) were utilized in informing the reduction of apparent CVX violations:
The original 124,136 items in the lemma were then broken down into workable files and lines missing information were identified and labeled as "no sound."
Compound words may be excluded from analysis. The composition of the lemma is such that it lists, in theory, every non-productive word in the Dutch language. Thus, we may expect that if a word is identified as a compound its compositional parts have been accounted for already. CELEX identifies compounds though the use of both hyphens (-) and word boundaries (#) in their transcriptions. Compound words that somehow escaped CELEX identification require manual identification and removal, with the assumption that their composite parts have also been accounted for in a the lemma.
In addition, there were 2,934 items for which no description existed in the lemma. These were excluded from analysis as no-sounds items, though they deserve further examination.
Working with the entire unreduced lemma, all no sounds and CELEX identified compounds were removed; compounds being identified as an occurrence of + or # in the phonological transcription. After removal of these items 63,152 items remain in the lemma.
The next important step is to identify all potential violators of CVX theory, manifested as all possible combinations of VXX super-heavy syllables in column: PhonStCVBr (stem CV). All instances of VXX are indicated in table 5.3.1, however many of these occurred within the same word. Total lines or items containing at least one CVX violation are listed in Table 5.3.2.
Within the 18, 471 potential violators of CVX theory we will be able to exclude many on certain grounds. For native speaker judgments, I enlisted the assistance of two native Dutch Speakers, currently residing in Amsterdam. The speakers were David Lingerak, age 35 and Martine Brinksma, age 33. Both were raised in West-Friesland (Noord-Holland) and are unaware of their particular dialect. the reduction proceeded as follows:
Hyphenated words are removed, ass shown in Table 5.4.1, as they represent non-CELEX identified compounds. 17, 936 words remain.
Level 2 affixes may be excluded, as they are phonologically inert and do not represent free morphemes. A potential confound may be the inappropriate removal of words with level one affixes. The classification of levels is certainly different in Dutch than in English and has not been examined in this essay. However, I believe the majority will be appropriate by the same reasoning as was applied to compounds. In my first reduction attempt I utilized a list of affixes derived from Booij (2002). This proved useful only in assessing a hypothetical number as I had to rely on statistics due to the error rate during my removal process. The method was abandoned in favor of one that yielded more concrete and tenable results. Searching re-occurring strings of five and six letters at the word edges we are able to reduce the lemma in a conservative yet productive way. Table 5.4.2 shows that after affix removal, only 1,151 words remain as potential violations of CVX theory.
By the same reasoning detailed above, compounds that were not CELEX identified, but were identified by the native speakers are removed.
Foreign words borrowed by Dutch may, in many cases be excluded, as their composition is purportedly not reducible in Dutch in the same way as in the original source language. for example, item 4008 /airconditioning/ is not reducible to /air/ and /conditioning/ in Dutch. I must acknowledge some degree of error in this removal as it is dangerous to assume that all borrowings are of such a nature and that there may well be overlap in simplest morphologically-free forms.
Borowksy attributes counterexamples found in proper names to the fact that they constitute a deviant subsystem with respect to many phonological phenomena. Assuming that most of them appear to be compounds or foreign, we can deem them derivations of the level 2 variety and exclude them from our list of CVX violators.
Of the remaining 413 words in the lemma, 278 were identified as containing long vowels or diphthongs.
These were marked for closer scrutiny, turning first to the case of long vowels. Assuming that differences in length can be explained by a tense/lax account, we extract all VV that are non-Diphthongal and that do not constitute any further violation of the rime (Non VVCC][ or VVCCC][ (marked with an X)). VV that meet these two criteria are removable under a theory which assumes long vowels to actually be identical to short with the exception of the feature [+tense].
Under Dunamu (2002) we can eliminate non-word initial diphthongs, yet word onset diphthongs may still present a problem as there is no way of attributing the initial vowel sound to a complex onset. An example from Chinese follows below:
Following this theory, all non-violating diphthongs are now removed (where a violation consists of non-initial diphthongs and VVCC+ violations) , as shown in Table 5.4.7.
For the remaining 76 words, a manual lookup was conducted to determine if any further reduction to the lemma could be made. From this 30 words were determined to be compounds, 13 had homorganic nasals which could be taken to constitute a long V and thus together with the vowel only one slot. Finally, 18 were excluded for various reasons examples of which are given below:
Exclusions similar to example (9) are excluded on the grounds that they contains homorganic nasals: a nasal followed by a consonant at the same place of articulation, in this case alveolar. In this case, the nasal can thus be assimilated into the vowel sound leaving the second slot in the rime for /t/. Example (10) illustrates a group of words that were extracted on the basis that /ex-/ constitutes a prefix. This may be a slightly contentious point, however it is assumed to hold here. Example (11) represents a class of words that we can exclude if we re-syllabify so that the offending C is relocated to the onset of the final syllable i.e. [bre:d][UIt] [bre:][dUIt], thus removing the problem of a diphthongal rime (VV). Fifteen violating words now remain, presented in table 5.4.8.
Of the remaining 15 some [VNC] rhymes that could be analyzed as [V~C]. einsel and punctum' may be homorganic, though the /n/ in punctum is not velar and einsel would continue to have a diphthong in its rime with no complex onset to attach to. 'Rucksichtslos' is probably 'reckless', but it has not been confirmed by my speakers.
Aside from a few unresolved exceptions, this study has shown that, if we assume a tense/lax and not length distinction, Dutch conforms to CVX theory. Many of these exceptions could most likely be shown to be legitimate exclusions though given current resources I have left them in as violations. The results would also be drastically different, and could be said to not hold true under a different account of vowel length. there would in fact be an additional 275 words to account for. However, given the unresolved state of the data, we have been just as justified in choosing the tense/lax account for the investigation. What remains to be proved is that the same holds true for other, less related languages than those for which similar studies have been conducted.

Word segmentation is to find word boundaries not marked by any delimiters in texts. It is the first step of text processing in languages without spaces as delimiters such as Chinese, Japanese and Thai. The fact that a sequence of characters can be grouped in several ways makes the segmentation task difficult. There is a sizable literature dealing with word segmentation. For example, Chinese word segmentation has been studied for decades with varieties of methods (Fan and Tsai, 1988; Sproat et al., 1996; Wu,2003).
Even for those languages with delimiters, word segmentation is also a necessary step in text processing. In Korean, though spaces are delimiters of Eojeol1 boundaries, automatic spacing is required in sentences with spacing errors in order to increase the readability and communication accuracy. Spacing errors cause misinterpretation to readers. For example, if (once in a while) is written as (to go once in a while), both its meaning and part-of-speech change. Spacing errors are common in Korean. It is hard to get correct word spacing even for human because people tend to use morphemes incorrectly. Consider (whole family). (whole) is an adjective and it should be detached from (family), but people often misuse as a noun, and they either attach or detach to. 2 In the literature, several methods have been used to deal with spacing (Kang et al., 2001; Lee et al., 2003). The task of word spacing can be taken as the task of word segmentation (Lee et al., 2003). In order to space a text, all the spaces are eliminated first and then the text is segmented into Eojeols delimited with correct spaces.
In this paper, we built a multilingual segmenter for Chinese word segmentation task and Korean spacing problem. We applied Viterbi algorithm (Viterbi, 1967), inword probability (Chen, 2003) and automatic linguistic rules as a plus.
Viterbi algorithm is a dynamic programming algorithm to find the best path through a probabilistic network given observed evidences. In word segmentation task, given a string of characters
ready, the algorithm then searches backwards through words to return the best probability path. For words not in the dictionary, we used add-one smoothing by adding 1 to frequencies of all entries and increasing total frequency N accordingly.
For words not in the dictionary, Viterbi algorithm prefers the longest fragment. If 1 u , 2 u , and 2 1u u are all unknown words, Viterbi algorithm segments the string into
In the second step of our system, we applied inword probability to combine a sequence of single characters into words. The in-word probability of a character is the probability that the character occurs in a word whose length is more than one, as in (3).
We built up an inword probability hash table for every character in the training data. Consecutive single characters are combined into a word if the inword probability of each character is over the threshold. According to our experiment over training data, we set 0.84 for Chinese inword probability threshold and 0.90 for Korean. Take a string of two single Chinese characters (family) (banquet) as an example. Our dictionary has no entry for, but the inword probability of is 0.87 and of is 0.93. So the two single characters are segmented as one word.
We extended inword probability to the recognition of numeric type compounds, including number compounds and time compounds. Since ASCII numbers are not included in our Chinese dictionary, the segmentation of numbers becomes the task of new words recognition. We combined the consecutive single numbers, including both digital numbers and Chinese character numbers together as one single word. We set inword probability for numbers as 1.0 if it is preceded or followed by another single numeric character or a certain suffix with inword probability assigned as 1.0, such as %. If the string is 1 2 %, then the inword probability will combine the three single characters together as one word 12% because all the inword probabilities of the three single characters are 1.0, above the threshold. If the compound of numbers is followed by a time unit, such as (year), (month), (day), the inword probability of the time unit is also assigned to 1.0. In this way, date and time compounds are combined into one word. For example, 2003 ? is segmented as 2003 ? (the year of 2003).
In Korean Eojeol spacing, inword probability helps to combine unknown transliterated names such as (carpet), (Persian). In , the two syllables3 and have inword probability above 0.98. A syllable has much higher inword probability when it is specifically used for pronunciation of a foreign character, because foreign characters often have unusual combinations of consonants and vowels.
In Chinese segmentation task, we applied linguistic knowledge as the final procedure to recognize unknown words after the implementation of in-word probability. First, we collected 50 suffixes from training data by implementing simple suffix extractor. The set of suffixes covers district units such as (country), (province), geographic suffixes such as (river), (mountain), road suffixes such as (road), (lane), and other suffixes such as (prize), (team). We attached a suffix to the previous word of two characters. Secondly, we extracted 100 family names from the training data. In the PKU training data, family names are separated from given names. If A is a family name in a sequence of single characters A B C, B and C are combined together as a given name only if C is not a family name and C does not belong to a small set of context words, such as (say), (and). The first restriction on C avoids the wrong segmentation of concatenated person names. In the sequence since the third character is also a family name, the given name segmentation does not combine and, because the latter could be the family name of another person name followed by.
As mentioned in the introduction section, Korean Eojeols can consist of more than one word. In the type of Eojeols consisting of a noun and a postposition, a certain noun can be attached by any postposition. For instance, the noun (lecturer) can be combined with different postpositions, and thus different Eojeols and meanings are generated. To list a few: is direct objective postposition), (of the lecturer), (to the lecturer), and (with the lecturer). This type of arbitrary combinations undoubtedly
yields some Eojeols not in the dictionary. We extracted a set of postpositions and built up the postposition attachment rule to solve this problem. If C in the segmented output A/BC after the second step is a postposition, the Eojeol A is combined with the Eojeol BC only if ) (AB P is higher than )
While resolving this problem, we followed the same procedure as the Chinese suffix extraction to maintain the consistency of our system. We collected set of postpositions from training data. Those postpositions are used to mark subject, direct object, indirect object, possession, location, direction, means, and groupings.
Both the training data and test data are from PKU corpora used in first international Chinese segmentation bakeoff4. The training data has 1.1M words and the test data has 17K words. The encoding of the corpora is simplified GBK. First, we made a unigram dictionary with distribution probability from the PKU training corpus. We did not include number digits and English letters in the GBK code, nor did we collect ASCII sequences. We also built up an inword probability list for each character in the training data. We did three steps in Chinese word segmentation. First, we applied Viterbi Algorithm. Secondly, we combined sequence of single unknown characters using inword probability. Finally we applied automatic rules of suffixes attachment and person names. Table 2 shows the recall, precision and Fmeasure after each step.
The performance of our system is promising compared to the first International Chinese segmentation bakeoff (Sproat et al., 2003). Table 3 shows the baseline, average and the highest scores of the bakeoff.
Among the errors our system produced, a small portion was caused by the inconsistent examples found in annotated segmentation between the training and test data, and the major errors came from our system.
The performance of the segmenter increased 4.9% after we implemented the inword probability algorithm. However, we could not avoid creating some segmentation errors. For example, the sequence of (cat) (winter) was combined incorrectly together as a single word because both of them have high inword probabilities. In the third step, segmentation errors appeared due to overgeneration and undergeneration of linguistic rules. The suffix attachment rule can be overgenerated when a suffix has ambiguous meanings. has two meanings, one means festival, used as a suffix, and the other means phase, used as a common noun. We did not make use of any context clues to distinguish the two meanings of. As a result, we attached in some wrong cases. The system segmented (the first phase), but the correct segmentation should be. As for segmentation of person names, we restricted that the third character could not be a family name. This rule can undergenerate some given names because characters used for family names can be used in given names also. In the name string, the last character is a family name, so this string was not recognized as a person name in our system. Some other errors were from segmentation of transliterated person names.
When evaluating the Korean spacing, both syllable based precision and Eojeol based precision
can be used. Syllable based precision is the ratio of the number of correctly spaced syllables over total number of syllables. Eojeol based precision evaluates the ratio of the correctly spaced Eojeols over the Eojeols from the system output. We adopted Eojeol based precision to maintain the consistency with Chinese segmentation domain.
In the evaluation of Korean spacing, a compound noun can be treated either as a whole or separate nouns. Thus we relaxed the definition of a compound noun to either case, and did the evaluation again. For a compound noun with three nouns (high-speed internet), and are also counted as the correct segmentations. Table 5 shows the improvement with the relaxation.
In this paper, we built a multi-lingual segmenter for both Chinese segmentation and Korean spacing task by implementing Viterbi algorithm and supplementing it with inword probability and automatic linguistic rules. It is the first try to segment languages with word boundaries and without boundaries in one segmenter. Experimental results show the efficiency of the multipurpose system.

Your company trains heating, ventilation and air conditioning (HVAC) technicians to install and optimize refrigeration and heating systems. After training, you test them on their ability to find a system's best operating condition but you have been receiving complaints that this test is unfair due to the uncertainties in the vapor compression cycle (VCC) training carts used. Thus, you have provided our company with the VCC cart used for training and requested that we quantify the coefficient of performance using compressor frequencies of 30 Hz, 45 Hz and 60 Hz and show the results on a temperature-entropy diagram. Additionally, you have asked for any other properties to consider when determining a unit's ability to heat or cool efficiently, and if they should also be used to test your technicians. We have completed these tasks. The purpose of this report is to present our procedure, findings, conclusions, recommendations and supporting documents.
We determined the values of the coefficient of performance shown in Table 1 below. We also constructed a temperature-entropy diagram (Fig. 2 on p. 3) from our results. Our results show that the coefficient of performance decreases as the compressor frequency increases, and that the values at each frequency are distinct even with uncertainties. The clear distinction in these values leads us to conclude that your testing is fair and that the uncertainties should not create any confusion as to which compressor speed produces the best coefficient of performance. We recommend that in addition to training your technicians on optimizing the coefficient of performance that you also train them to understand the minimum cooling and heating capacities needed for the building the system is used on. We observed the cooling and heating capacities (also shown in Table 1) decreased as the compressor speed increases, the opposite trend of the coefficient of performance. If the cooling and heating capacities are too low with respect to the volume of building they operate on, the system will not be able to produce enough heat transfer to cool or heat the building to a desired temperature.
This section details the equipment setup and the methodology we used for testing.
Your company provided us with a Hampden Model H-CRT-1 Refrigeration Trainer cart as well as a computer controlled data acquisition system to record data. The cart's working fluid was R-134a refrigerant. A simplified schematic of the cart can be seen in Figure 1 which shows the path of the fluid and the points where digital transducers measured temperature and pressure. The schematic omits additional elements (such as an oil separator for the compressor) and extra transducers because they were not used in our analysis. We have defined the following points on the schematic, which will be used later in reference to the vapor compression cycle: point 1 is at the entrance to the compressor, point 2 is at the exit of the compressor, point 3 is at the exit of the condenser, and point 4 is at the entrance to the evaporator.
We conducted our tests in a laboratory with ambient air temperature of 295.9±0.5 K and ambient pressure of 97.8±0.1 kPa. First, we turned on the fans inside the condenser and evaporator. Then, we set the speed controller to 30 Hz. Using LabView, we monitored the temperature and pressure through all of the transducers as well as the compressor input power and the flow rate into the throttling valve. We waited for readings to reach steady state, at which time their values were recorded five times at 10 second intervals. We repeated this process twice more with speed controller values of 45 Hz and 59 Hz.
This section outlines each process in the ideal vapor compression cycle and the expectations for each process in reality. It also presents the requested temperature-entropy diagram, coefficients of performance and all relevant derivations.
Each process in the vapor compression cycle occurs as the fluid passes through the compressor, condenser, throttling valve or evaporator. We assumed that the fluid does not undergo any thermodynamic changes in the tubes from one device to another.
The specific entropy at points 1, 2, and 3 were found in thermodynamic tables[1] using their measured temperature and absolute pressure. The specific entropy at point 2 during the 30 Hz test corresponded to a compressed liquid, which we know is not possible. This would mean the compressor was more than 100% efficient. We observed that the specific entropy value is sensitive to pressure changes, so we hypothesized that the pressure gauge at point 2 may not be measuring accurately. The specific entropy of a saturated vapor at the same temperature was used for this point.
The specific entropy at point 4 was determined using a different procedure due to a lack of a pressure transducer there. It was determined using the assumption that the process of fluid passing through the throttling valve was adiabatic and that the enthalpy remained constant. To find the specific entropy in the tables, we needed to know a pressure and specific enthalpy, so we used the pressure of a saturated liquid at the measured temperature and the enthalpy at point 3 as read from tables.
As requested, we made a temperature-entropy diagram using our results and plotted it on top of the R-134a saturation dome, as shown in Fig. 2. When looking at the process from point 1 to point 2, it can be seen that the cycle is not quite the ideal vapor compression cycle as the entropy does not remain constant. We observed that the entropy decreased through the compressor, contrary to what we expected. Also contrary to what we expected, we observed that the temperature and pressure increased through the evaporator at 45 and 59 Hz.
The values for the coefficient of performance (COP) for cooling and heating can be found in Table 2 as well the cooling capacity, heating capacity and power input to the compressor. Both values of the COP decrease as the compressor speed and power input to the system increase, and the values at each operating speed are distinct. These values do not come close to one another even at the far ends uncertainty. The values of the cooling and heating capacities increase as the compressor speed and power input to the system increase.
The coefficient of performance (β) in a VCC is defined as the heat energy sought divided by the power input (compressor power) into the system[2]. The heat energy sought in a refrigeration cycle is the cooling capacity from the evaporator and the heat energy sought in a heating cycle is the heating capacity from the condenser. These values are determined by the states of the fluid entering and exiting each device and represent the total amount of cooling or heating the system can do. The cooling capacity was calculated using Eq. 1 and the heating capacity was calculated using Eq. 2 where
We found the values of the specific entropy for each point in the VCC and plotted them on a temperature-entropy diagram in Fig. 2. Additionally, we determined the values of the COP for each compressor frequency as shown in Table 2. We observed that the values for both cooling and heating COP were distinct from one another with uncertainties. The clear distinction in these values leads us to conclude that your testing is fair and that the uncertainties should not create any confusion as to which compressor speed produces the best COP.
We recommend that in addition to training your technicians in optimizing the COP, you also train them to understand the minimum cooling and heating capacities needed for the building the system is used on. Our results showed that the COP was highest at the lowest operating speed, which also corresponded to the lower value in the cooling and heating capacities. If the cooling and heating capacities are too low with respect to the volume of building they operate on, the system won't be able to produce enough heat transfer to cool or heat the building to a desired temperature.

In the average internal combustion engine-driven automobile, only 25% of the energy generated from combustion can be used by the vehicle for mobility and accessories. The rest of the combustion energy is wasted, including 40% that is lost to exhaust gas [1]. Various methods have been developed to try to recover some of this lost energy, including turbogenerators, Rankine Cycle recovery systems, thermochemical recuperation, and thermoelectric generators (TEGs) [2]. Additionally, some hybrid cars including the Toyota Prius use regenerative braking to recover some of the kinetic energy lost when stopping the vehicle [3].
Thermoelectric generators are attractive potential waste heat recovery systems because they are relatively inexpensive, have no moving parts (and thus produce no noise and no vibrations), and are highly reliable [4]. Previous studies have attempted to develop TEG systems for waste energy recovery in light trucks [5][6][7], but these studies have not considered lighter cars with hybrid engines such as the Prius. In addition, previous researchers have not specifically taken into account the driving habits of university students.
In this study, we investigated the possibility of developing a waste heat recovery system mounted on the exhaust system of the Toyota Prius as driven by college students using TEGs coupled with heat sinks mounted on the exhaust system of the vehicle. Specifically our goals for this study were as follows:
All variables used throughout this report have been defined in Table 1, below.
We considered the effects of heat sink size, pin shape, pin height, and pin density on the voltage output of a thermoelectric generator. In order to determine the effects of these factors with a minimal number of experiments, we used a fractional factorial DOE methodology and analyzed the results with an analysis of variance (ANOVA). We then predicted the optimum heat sink configuration for our application based on the ANOVA and design considerations. This configuration was then tested under various wind speeds and temperatures to extrapolate the
TEG's performance at typical driving conditions as determined from a survey of college students.
The results of the fractional factorial analysis were used to determine the significant factors in TEG voltage output using an ANOVA statistical analysis. The ANOVA and power data from the initial tests were used to determine the best heat sink geometry.
A fan was placed to flow across the heat sink to simulate the air flow under a moving car. The fan was approximately 15cm from the TEG and was placed at approximately the same height as the base of the heat sink. The fan speed was kept constant at 2.7 ± 0.5 m/s for the initial set of tests.
For each test defined in the DOE table, we placed the corresponding heat sink on top of the TEG, turned on the hotplate, and recorded the temperatures and voltage as the hotplate temperature increased to steady state. For our tests the steady state temperature was approximately
190±10°C. However, this was difficult to control due to high uncertainty and uneven temperature distribution produced by the hotplate.
The thermoelectric figure of merit, ZT, under our test conditions was found using the following plots illustrated in Fig. 2, below. We evaluated the ZT value for a Bismuth Telluride (Bi2Te3) material, taking the average of the pand n-type values, at a temperature equal to the mean temperature of the test (~140°C). The resulting ZT value was approximately 0.7 for this case.
We then used the mechanical efficiency defined as the ratio of the electrical power generated to the thermal power into the device, given by Eqs. (2) and (3). This allowed us to determine the constant K for the TEG, which we assumed to be independent of temperature.
In these equations, the constant K (W/K) represents the lumped thermal conductivity of the TEG device, assuming it to be a semi-infinite slab according to heat transfer analysis. This constant incorporates the thermal conductivity, k, cross-sectional area, A, and height, L, of the TEG. The Voltage is given by V and the resistance is defined by R, assuming a value of 4.0 Ohms according to manufacturer specifications [1].
Since a gradient of temperature exists between the base of the heat sink, TL (where we measured), and the cold side of the TEG, we used the thermal conductivity of the TEG to predict the actual value by solving for TC using Eq. 4, below, which was determined by combining Eq. 2 and 3:
A heat transfer analysis using a conservation of energy approach for this setup resulted in Eq. 5 below. In this equation, the heat flux QH into the system is balanced by the convective heat transfer Q-convected out of the system and the power generated by the device. Equation 6, below, defines the convective heat transfer, where hA (W/K) is a measure of the convective heat transfer to the ambient.
Using the results of the optimal heat sink tests, we determined a relationship between the convective heat transfer coefficient, hA and the air velocity.
We used the survey results to estimate TH at various points in the exhaust system (Fig. 7 on page 10). Combining equations (2) – (6) yielded Eq. (7), below. This equation was solved explicitly in terms of TC to estimate the cold side temperature of the TEG for the estimated TH, taking into account the higher convective heat transfer with a moving automobile.
We estimated the ambient temperature as 10˚C, which was determined to be an estimate for the average yearly temperature in Ann Arbor, MI [9]. We used an iterative process to estimate the ZT value for various TE materials optimized for the calculated mean temperature and find Tc. This Tc value is then used in Eq. 4 to determine the output power. Since the TEG material we tested cannot withstand sustained temperatures greater than 250˚C [1], Fig. 4, on page 8, was used to estimate the figure of merit for various TE materials.
where ∆FE is the fuel efficiency increase in mpg, P is the electrical power generated in Watts and W is the additional weight of the system in lbs. Additionally, assuming a gas a price of $3.20/gallon and a car lifetime of 150,000 miles, the amount of money saved in fuel consumption over the lifetime of the car is given in terms of P, W, and the original fuel economy FE0 by Eq. 9. The EPA's estimate for the average fuel economy of the 2007 Toyota Prius is 46 mpg [11].
For an electrical generation system to be practical to implement, it should save the consumer more money in gas than it costs in additional vehicle price. Similarly, since one gallon of gas produces 9 kg of CO2 gas in the average car [12], and the Prius' CO2 emissions are about half of that [13], the reduction of CO2 emissions (in kg) over the lifetime of the car is given by:
We used the conducted survey to approximate the exhaust temperatures of the Toyota Prius at various component locations under the car. Using the dimensions of the exhaust, we then approximated the useable area for TEG implementation. Thorough analysis of the tested heat sinks yielded an optimal configuration taking into account power, cost, and added weight of the system. We predicted the thermal constants associated with the TEG and optimal heat sink at design temperatures. An Estimation of the performance and cost of the proposed system with current technology is then presented.
Table 3 on page 10 shows that the average time per trip is about 15 minutes and the average driving time per day is about 25 minutes. Additionally, the average time spent towing a trailer, letting the car idle, and driving on dirt or poorly paved roads is negligible for the purpose of this analysis. Finally, 27.7% of college students' driving time is spent on the highway, and college drivers drive aggressively 17.9% of the time. Both of these activities significantly increase the load experienced by the car.
Since the average student drives about 25.4 minutes per day, 72.3% city driving (approximately 30 mph) and 27.7% highway driving (approximately 70 mph), the average distance driven per day is 17 miles/day, so the average college student's car is driven about 6000 miles/year.
Figure 7 shows the exhaust system component temperatures at partial and full loads for a BMW 318i sedan.
Assuming that the Prius has a similar exhaust system, we determined the typical component temperatures for city and highway driving. City driving is approximated as driving at 30mph, and the component temperatures are approximated as the temperature partial load plus 25% of the difference between the full and partial loads. This estimate takes into account the transient behavior of the car as it warms up, driver aggressiveness, and the temperature fluctuation due to the unique engine behavior of the Prius (see Discussion Section). Highway driving is
approximated as the partial load plus 75% of the difference between the full and partial loads. This estimate takes into account vehicle transient behavior and driver aggressiveness. Table 4, below, summarizes these exhaust system temperatures with the corresponding useable area for mounting the TEGs.
Table 6, below, summarizes the results of our ANOVA analysis. The full ANOVA results outputted from MATLAB can be found in Appendix B. We examined the effect of various factors related to the heat sink geometry on both the power output of the TEG and the temperature difference across the device, ignoring interactions between the factors. Using a 90% confidence interval, we determined the only significant factor was pin height.
Using the ANOVA analysis and the power per cost ratio from Table 5, p.11, we determined that the best heat sink for this application is the Alpha Novatech PN S153020W.
Figure 8 shows that there is a linear relationship between the convective heat transfer coefficient, hA, and air velocity.
The hA values for city and highway driving were determined from the relationship shown in Fig.
8. For city driving (30mph), hA=0.28 W/K, and for highway driving (70mph), hA=0.62.
To maximize the power output of the system, the TEGs placed on the exhaust manifold and the exhaust pipe are filled skutterudite TEGs while the TEGs on the catalyst, the center muffler, and the rear muffler are Bi2Te3 TEGs (see Fig. 9). This configuration was chosen to maximize the ZT value at each component based on Fig. 4, p.8. It should be noted that HiZ 2 TEGs that we tested in the laboratory would not be acceptable for this application, as they cannot be exposed to sustained temperature of more than 250˚C, however more robust Bi2Te3 TEGs could be used. The performance of this system is summarized in Table 8, below. The filled skutterudite TEGs are assumed to have similar geometrical, mass, conductivity properties, and costs as the Bi2Te3 TEGs. The system weight is estimated as the weight of the TEGs and heat sinks, plus approximately 5lbs (2.3kg) for installation hardware.
Table 7. Summary of performance of TEG heat recovery system using current technology.
In order to draw conclusions about our data, we needed to assess the validity and implications of our results. We then also further investigated the characteristics of the Toyota Prius, and current and future TEG technologies.
While a small fan mounted on top of the heat sink may have increased the convective heat transfer from the heat sink, we chose not to propose the use of a fan for several reasons. The fans would take power from the system, add weight to the car, and add a degree of complexity to the system due to moving parts. Since the fans were only able to generate a maximum of about 3 m/s (6.7mph) while using about 1 watt of power, the increased convection due to the fan would not outweigh the energy cost of using the fan.
First, the hotplate had a very uneven temperature distribution. If the thermocouple used to measure the hotplate temperature was moved even slightly, the temperature reading would change by up to 20°C. In addition, the set point of the hotplate was not consistent. Setting the hotplate to 260°C resulted in hotplate temperatures of between 150°C and 210°C, varying from test to test. While we attempted to compensate for these problems by changing the set point to achieve a consistent temperature, and trying to place the thermocouple in a consistent spot, the temporal and spatial fluctuations made the hotplate temperature extremely difficult to measure accurately. A more precise heating element would have greatly improved our temperature reading accuracy, and thus improve our performance predictions.
Second, the contact resistance of the setup did not seem to be consistent. While we tried to use a consistent amount of thermal grease at each contact, other factors may have affected this resistance. For example, contact resistance decreases with increasing contact pressure [18]. However, we used heat sinks of different weights, so the contact pressure was never consistent. Additionally, to measure the heat sink surface temperature, we had to put some pressure on the heat sink with the thermocouple. While we attempted to keep this pressure consistent, we had to hold the thermocouple by hand, and the pressure may have changed from test to test. Our results would be more accurate if the contact pressure could be kept constant by using a clamp to hold down the heat sink and take temperature measurements. Additionally, the thermal grease seemed to clump over time and create air pockets that would increase the contact resistance. This could be remedied by using a different kind of thermal grease or by reapplying thermal grease between each test.
Finally, the resistor used to simulate a load across the TEG was attached very close to the TEG, so the resistor heated up during the tests. This temperature change may have changed the resistance, which would affect our voltage measurements. If the resistor had been placed in parallel with the TEG with longer wires, the resistor could have been kept closer to the ambient temperature, and thus maintained a more consistent resistance.
These laboratory testing problems probably affected our results for our ANOVA analysis and our extrapolation to real-world driving conditions. However, since the results of our system analysis show that the necessary TEG technology is an order of magnitude higher than that which is available today, our recommendations are not highly affected by our laboratory problems.
The Prius also uses fuel-saving technology other than the hybrid engine. The Prius' fuel efficiency is increased by the car's aerodynamic shape, which is due in part to its flat underside designed at for smoother air flow beneath the car (see Fig. 11, below). The Prius also uses a weight-saving design, using lightweight components as much as possible [3]. Any proposed changes to the Prius design should be made with these factors in mind. In our air-cooled system the TEGs and heat sinks would add both weight and drag beneath the car.
Figure 11. The underside of the Prius is flat to make the underbody air flow smoother and reduce drag. [3].
Fig. 4, p.8. These materials have lower ZT values than the materials listed in Table 8, so they were not considered for this application.Table 8. Comparison of characteristics for recommended TEG Materials.
The goal of several US Department of Energy programs investigating waste heat recovery is a fuel economy increase of 10% [14]. In the Prius, this corresponds to a fuel economy increase of
4.6 mpg. Neglecting the TEG system weight, Eq. 8, p.8 implies that this could be achieved with a TEG power generation of 1150 W. In order for this to be possible with the system proposed in the Results Section above, our models show that TEGs with a ZT near 3 would need to be developed. However, the cost of the system would still be a major hurdle before implementation could be realistic.
In order to estimate the requirements for a TEG system to be feasible on the Toyota Prius, an economic evaluation was performed to determine the point at which a TEG system could pay for itself over the lifetime of the car (the break-even point). One way to reduce cost would be to reduce the number of TEGs needed. By only mounting TEGs on the three highest-temperature elements (the exhaust manifold, exhaust pipe, and catalyst), the number of TEGs could be reduced to 155.
Figure 12 p. 18 shows the amount of fuel economy savings with respect to time and the figure of merit ZT. The plot shows that with a TEG cost reduction of 85% and a ZT of 4, the system will exactly pay for itself at the end of the car's life cycle (150,000 miles and 25 years). Figure 12 also shows the break-even points for other combinations of cost reduction and figure of merit ZT.
In order to increase the savings achieved with a TEG without increasing the number of TEGs, the figure of merit of the individual TEGs must be increased. Figure 13 illustrates that increasing ZT would lead to increased fuel efficiency. The figure also shows that there is a limit to how much the ZT can be increased before it does not significantly affect the fuel economy. This occurs around a ZT value of 20. For high ZT values, the factor limiting power output shifts from the material properties to the Carnot efficiency.
than that of the Bi2Te3 TEGs. Development of technology for automated fabrication should further decrease the cost of quantum well TEGs. In addition, quantum well TEGs are predicted to have very high efficiencies compared to the TEGs available today and can also be utilized in higher temperature ranges [8]. Figure 14 shows the relationship between efficiency and cost of future TEG modules with respect to temperature.
The temperature of the gas that flows through the exhaust system is higher than the temperature on the outer shell of the exhaust system. Since the TEG is mounted on this outer shell, maximizing this temperature would increase the TEG power output. To achieve this, the exhaust system could be constructed with a less thermally resistive material, or the exhaust gas could be forced to have turbulent flow with the help of spiraled fins inside the exhaust system [17].
In addition, a reduction in thermal resistance of the insulating wafer that is placed between the exhaust system and the TEG and also between the TEG and heat sink could also improve the performance [17]. Similarly, an increased thermal conductivity of the thermal paste would increase heat flux through the TEG system and thus improve performance.
Many studies of waste heat recovery systems in automobiles have used coolant from the car's engine to cool the cold side of the TEG instead of flowing ambient air [5][6][7][17]. Use of such a coolant system would increase the temperature difference across the TEG and thus increase our power output.
We have investigated the possibility of implementing an air-cooled TEG waste heat recovery system mounted on the exhaust system of a Toyota Prius driven by college students. Our conclusions are as follows:
While our laboratory tests had a high level of uncertainty, it is clear that the current TEG technology is far below the necessary level to be feasibly implemented. Assuming gas prices of $3.20/gallon, an average ZT of 4 and an 85% reduction in TEG system price would be necessary for the system to pay for itself in saved fuel costs over the lifetime of the car.
While the implementation of a TEG waste heat recovery system in the Toyota Prius is not practical using today's technology, future TEG materials may make such a system a viable option. Specifically, when ZT values approach 4 and TEG costs are reduced by 85% (a realistic target based on the prediction of quantum well TEG technologies), the system should be reconsidered.
The following recommendations should be considered when investigating a TEG waste heat recovery system in the future:

The Powertrain Division of EKA-KK Inc. has observed a low-frequency resonance on the drive shaft of the current prototype vehicle. Due to this resonance, passengers clearly sense the switching on and off of the DC motor, a major vibration problem. Thus, Systems Group has been contracted to identify the cause of the drive shaft vibration problem and to recommend four possible design modifications. Systems Group is to develop a motor/drive shaft model, perform computer simulations to validate the model, and come up with four design changes. All of the requested work has been completed, with the purpose of this report to provide results, conclusions, and supporting documentations for the drive shaft test and design alterations.
Our experiments have allowed us to create a mathematical model of the drive shaft and flywheel system. The cause of the vibration problem in the drive shaft was determined to be the drive shaft itself, in which initial assumptions of drive shaft rigidity were incorrect. Through sensitivity analysis we identified that the diameter of the flywheel, Dflywheel, the resistance of the motor, Rm, the motor constant, Km, and the damping of the motor, Bm, had the most significant effect on the magnitude of the resonant response. Table 1, below, shows how much each parameter needs to be changed individually to reach a 30% reduction in resonance magnitude. Additionally, there are four design options that combine changes in multiple parameters in order to reach the 30% reduction goal. We feel that proposed Design 4 will best suit your needs as it minimizes the amount of change to each variable.
This section highlights the procedures used during testing and data collection. The test setup consisted of a drive shaft with two flywheels, Figure 1 on page 2. On the right side of the drive shaft is a DC motor (Aerotech 1000 DC Permanent Magnet), which also can operate as a tachometer, and on the left is a tachometer (Servo-Tek SA-740B-1A). Both the motor and the tachometer are connected to an oscilloscope (Hewlett Packard 54602B) and the motor was driven by a function generator (Hewlett Packard 33120A).
With the system given in Figure 2, above, the damping coefficients of the bearing, Bb, drive shaft, Bs, and motor, Bm, could not be obtained individually. The system was separated into components and a system of equations was used to solve for all of the coefficients simultaneously. The combined damping of the bearing and shaft was obtained by locking Flywheel 1, applying a small force to Flywheel 2 to initiate rotation, and applying Equation 5 on page 3. An oscilloscope was used to measure the output angular velocity from the tachometer which is attached just beyond Flywheel 2. To determine the combined damping of the motor and shaft, the same procedure as above was used, with the exception that Flywheel 2 was locked, a small force was applied to Flywheel 1, the oscilloscope read the voltage from the motor, and Equation 6 on page 3 was used. We found the third equation by locking Flywheel 1, restraining the drive shaft so that only half of it rotated, applying a small force to Flywheel 2, and using Equation 5 on page 3.
To measure frequency response, an amplifier (Techron 7520) attached to a function generator applied an output signal at 1Hz to the motor of the drive shaft. The amplifier gain was then increased to 4V. The frequency response was measured for input frequencies between 1 and 12Hz in intervals of 0.2Hz between 5 and 6 Hz and intervals of 1Hz everywhere else along the given range.
The motor constant and resistance are related to each other through a function of the motor's voltage, current, and angular velocity; see Equation 9 on page 4. To find the motor resistance, Rm, we subjected the motor to a range of high frequencies, 20 to 30 Hz, and recorded the motor's voltage and current for each frequency. The motor constant, Km, was found by applying a steady DC voltage and recording the motor voltage, motor current, and tachometer voltage.
This section highlights the results of the variables calculated, the verification and improvement of the test model through the use of Bode plots, the cost function and sensitivity analysis, and the proposed design modifications to reduce the resonance peak of the drive shaft. To find an accurate mathematical model for this system, we needed to determine all of the parameters of the system's transfer function, Equation 1 below. This model takes into account that the model components are not rigid, as previously thought; a possible reason for the drive shaft vibrations. Once the parameter values were calculated, we performed a cost function and sensitivity analysis to identify which parameters should be changed to reduce the magnitude of the transfer function by 30%.
In order to determine the damping coefficients of our system, we isolated different combinations of the damping coefficients. We then used a system of equations to solve for the motor damping, Bm=9.56·10-3 ±7·10-4, shaft damping, Bs=2.06·10-3 ±6·10-4, and bearing damping, Bb=1.45·10-3 ±6·10-4, individually.
By drawing a free body diagram of the shaft and second flywheel we found the governing equation of motion, Equation 2 below. This can also be rewritten to include variables such as the natural frequency, ωn, and the damping ratio, ζ, as seen in Equation 3 below.
Btr, the damping coefficient of the shaft and bearing, was calculated using ζ, which was determined from Equation 4, below. After measuring the amplitudes of two peaks, x1 and x2, as well as the period, t, between those peaks of the damped response, we calculated the value of ζ and set it equal to Equation 3 above to solve for Btr, Equation 5 below, where Jf is the moment of inertia of the flywheel, and K is the spring constant of the shaft. An example of how x1, x2, and t were measured is seen in Figure 3 below.
Btl, the damping coefficient of the shaft and motor, was calculated with the same procedure as that to find Btr, with the exception that the inertia of the motor was a factor in the calculation. Thus, Btl was calculated with Equations 6-7 below, where Jm is the moment of inertia of the flywheel.
Finally, Btr2 was calculated by reducing the shaft length by 50% and using the same procedure as for Btr. The individual damping coefficients were calculated using a Gaussian distribution, Equation 8 below.
Error in the damping coefficients primarily came from the precision and resolution error of reading measurements from the oscilloscope, as well as the statistical error associated with having multiple trials.
Determining Motor Parameters Km and Rm
To verify or possibly improve the original system model, we experimentally determined the motor parameters Rm (2.458 ±0.1 ohms) and Km (0.056 ±0.03 V/(rad/sec)) using Equation 9, below.
When we gathered data for calculating Rm, we used the assumption that if high frequencies were applied to the system there would be a negligible amount of rotation and thus
After performing all the experiments, we gathered all the parameter values associated with our mathematical model. Table 2, below, gives a value for each parameter and any error associated with it.
Figure 5a, below, shows the frequency response of the system for the mathematical models and experimental data. In order to verify that we improved the original model by calculating the motor constant and internal resistance, we plotted the original model, our new model, and the experimental data together. As is shown, using the calculated values for Rm and Km shifts the improved mathematical model so that it has a better fit with our experimental data. To mathematically prove this graphical analysis, a root-mean-square analysis, as shown in Equation 10 below, was performed between the magnitudes of the experimental data and the two different mathematical models. This analysis indicates the variation, or error, between the test data and the mathematical models. From this analysis, we found the error of the original model and improved model, σ, to be ± 0.58 rad/s and ± 0.21 rad/s, respectively. The improved model effectively reduces the error between the mathematical model and test data by 36%. Additionally, the error is small enough in magnitude that we can conclude it is acceptable to use the improved mathematical model to simulate the design modifications to reduce the resonant frequency.
Figure 5b, above, shows a Bode phase plot to determine the phase shift present in the system at various frequencies. The phase shift in angular velocity changes from-90 º to-270º around the resonant frequency of 6.0 Hz. The original model already had strong correlation with the experimental results, to which the improved model further adds.
A cost function and sensitivity analysis was performed to determine which system parameters have the largest effect on the resonant peak magnitude. Calculating these parameters allows for minimal changes to the system while maximizing the reduction in the resonant peak magnitude. This was achieved by developing a cost function that measures the amount of perturbation that a parameter has on the resonant peak magnitude. Equation 11, below, shows the cost function used. This cost function looks at the area under the magnitude frequency response curve and compares it against the same curve when a parameter has been altered by ±1%. The area measured is the area under the resonant peak plus a 1Hz wide section on either side. The percentage difference in area corresponds with how sensitive the system is to that particular variable. The greater the cost function percentage, the more sensitive the system is to changes of that parameter.
[2] Equation 11
Using this cost function, all of the variables of the system were evaluated, shown in Table 3 below. The analysis found the diameter of the flywheel, Dflywheel, the motor resistance, Rm, motor constant, Km, and the damping coefficient of the motor, Bm, to be the most sensitive values to reduce the resonant peak. These variables will be the focus for reducing the resonant peak by 30% in later design modifications.
To determine possible design changes, the four variables Dflywheel, Rm, Km, and Bm were altered to find a resonant magnitude reduction of at least 30%. These variables were chosen from the sensitivity analysis results, as they produced the largest changes in the cost function. Table 4, below, shows the percent change needed for a single variable to reduce the resonant peak by at least 30%. The percent change was calculated by finding the difference between the resonant peak magnitudes of the original and reduced curves. The reduction in resonant peak magnitude can be achieved by increasing Dflywheel and Rm, and by decreasing Km and Bm, respectively. Figure 6, page 7, shows the simulated frequency response resulting from an increased Rm of 50.5%, while Figure 7, page 7, shows the simulation for a decreased Km by 34.5%. Both of these parameters alone can reasonably provide a frequency response that reduces the resonant magnitude by greater than 30%.
The cost function and sensitivity analysis was performed by analyzing the percentage change of the system output, regardless of whether there was a change in resonant peak (vertical shift), or change in resonant frequency (horizontal shift). Therefore, some variables not only reduce the magnitude of the resonant peak, but also shift the resonant frequency. This leads to a more significant change in resonant frequency than in reduction of resonant peak magnitude. This is specifically noticed with the parameters Dflywheel and Bm where a 30% reduction in the resonant peak could not be reasonably achieved by these variables alone. Furthermore, other less sensitive variables tested yielded the same results.
While three of the four parameters were able to reduce the resonant peak by the desired amount, such large changes on a single variable may be costly, and impractical given the physical limitations of the components and their interactions with other parts of the system. A solution for reducing the resonant peak would be more viable as a combination of changes on two or more of the most sensitive parameters.
Four feasible solutions are described below that will reduce the resonant frequency magnitude by at least 30%. With these solutions, relatively smaller changes can be made to multiple parameters in order to achieve the desired reduction of resonant peak magnitude, shown in Table 5, below.
The first design modification involves altering only Rm and Km; doing this reduces the resonant peak without changing the resonant frequency. This choice of modification allows for only one component of the system to be altered, the motor. This may be a costly change, however, if the motor specifications needed cannot be achieved. Alternatively, the second design modification allows for less change to the motor parameters but includes altering the damping coefficient of the motor, Bm.
The third and fourth design modifications involve balancing the system alterations between all four of the sensitive parameters. Design 3 focuses on using Dflywheel and Bm to reduce the resonant peak. Design 4, however, minimizes the alteration of Bm relative to Designs 2 and 3, a difficult parameter to reduce given material constraints of the motor. Additionally, it reduces Rm and Km relative to Design 1. This minimization leads us to suggest Design 4 as our recommended solution. Minimizing design parameter alterations makes accomplishing a 30% reduction in resonance peak more feasible and less costly. Using the parameters defined in our model, the Design 4 alterations would result in a Km of 0.045 ± 0.03 V/(rad/sec), a Rm of 2.93 ±0.01 Ohms , a Dflywheel of 0.143 m, and a Bm 9.08·10-3 ±7·10-4 kg· m/sec.
To demonstrate the feasibility of the Design 4 modifications, a replacement DC motor was found that meets the motor specifications. This DC motor, Model 14201S003 from Pittman as shown in Appendix A, would perform near the desired specifications, and would exceed the resonant peak magnitude reduction of 30%. Estimations show that this motor would achieve upwards of 60% reduction in resonant peak magnitude when used in conjunction with an increased Dflywheel of 5%.
In analyzing the system provided, experimental data was used to create a mathematical model of the drive shaft system. The linear mathematical model used proved to be an accurate approximation of the real system, in which the bode plots generated from the linear mathematical model closely match those of the output of the system measured experimentally. The vibration problem indeed was determined to be the erroneous assumption that the drive shaft was rigid. In order to reduce the generated vibration by 30%, it is recommended that the motor constant, Km, be reduced and the motor resistance, Rm, be increased by 19.5%. Furthermore, Dflywheel must be increased 5%, with a reduction in Bm by 5%. In increasing the motor resistance, however, one also must take into account the increased energy consumption required to run the system, to which metrics such as fuel economy must be recalculated. One must also note the shift in resonant frequency from 6 Hz to 5.4 Hz, to which external effects at this frequency on the system must be taken into account. Increases in the flywheel diameter must also be tested for geometric constraints of the car design as well.
While the mathematical model derived from the experimental data proved sufficient for the desired objective, it is most likely not as suitable for tests of high precision. In the mathematical model, the shaft moment of inertia, winding inductance, and non-linear factors were neglected. Parameters such as damping coefficients are also susceptible to change over time, a factor not taken into consideration in the model. The influence of these parameters not taken into account is unknown, and may require the development of a different model when testing other aspects of the system. Overall the model created has proven quite accurate in modeling the system given. This model confirms the recommended changes as reducing peak vibrations by at least 30%.

In 2005 a study completed by the Center for Disease Control found that 5,800 people 65 and older died from injuries related to unintentional falls and another 1.8 million received emergency room care. Of those treated, 433,000 were hospitalized for long term care [1]. Seniors who live alone may suffer from an unintentional fall and are often not found for hours or days. Long waits for medical care exacerbate their injuries and increase their risk of death or permanent hospitalization. However, fast emergency response to a fall reduces the risk of hospitalization by 26% and death by 80% [3]. The problem with seniors not receiving immediate attention needs to be addressed.
A National University of Singapore study researched and developed a garment-based 3-axis MEMS accelerometer designed as an alert system for senior citizen falls by recording an impact [2]. The system was to be worn by seniors in a pouch attached to the shoulder which contained the accelerometer. The power supply and blue-tooth wireless system to transmit an alert signal was located in a pouch attached at the waist. The chip itself was designed to record a heavy impact of magnitude consistent with a fall situation. When a fall was detected, the system would transmit a signal to the wearer's cell phone, which would signal an emergency response team and the person's family.
We have found several flaws in the system developed at the University of Singapore. Since the accelerometer measures impact, if it were to break during the fall it would not function properly and emergency response would not be alerted. In addition, a number of daily motion activities could cause g-force readings consistent with that of a fall, which would trigger a false fall alert and cause unnecessary emergency response action. If there were an emergency response unit which measured the fall itself and not the impact, the possible break would not be an issue and false alarms would not occur.
Our objective is to develop an emergency response system to detect unintentional falls of senior citizens. This system would be triggered by a characteristic acceleration response associated only with falling and would be accurate enough to not register false falls. In addition, we aim to use the device as a static orientation system that would be able to correctly measure the wearer's angle from vertical, as well as body orientation (i.e. face down, on left side, etc.) We have completed this work. In this report we will cover:
In order to reach our final goal of characterizing free fall several experiments were performed. The accelerometer ADXL203EB was first calibrated, and then used to record data for static orientation, fixed axis free fall, and daily human activities. Voltage input to the accelerometer was provided by the HP 33120A function generator. Voltage outputs were observed and recorded using the HP 5460213 oscilloscope. From there Microsoft Excel and Matlab were used to analyze data.
In order to interpret readings from the accelerometer we needed to determine a relationship between voltage and acceleration. The accelerometer was rotated to angles and orientations of known acceleration and the voltage output recorded. Using this data we were able to then know the acceleration of the accelerometer given a voltage at any point in time.
To gather experimental data for the orientation of the accelerometer in space we performed experiments holding the accelerometer in static orientations. The accelerometer was placed at the end of a pivot arm as shown in Fig. 1, below, and the arm was held at 0, 30, 45, 60 and 90 degrees from vertical. Output voltages were recorded at each angle. From there the accelerometer was rotated about its z-axis, which is depicted in Figure 2 on page 4. The accelerometer was rotated to 45, 90 and 135 degrees while the pivot arm was moved through the previously described static positions. Data was recorded at every orientation.
Once static orientation had been performed we experimented with free fall in a two dimensional plane. The accelerometer was reattached to the end of the pivot arm as shown in Figure 1, page 3, so that the accelerometer recorded data in the plane of motion. This meant that that analysis was only done in two dimensions to ensure that we were able to accurately measure the radial and tangential acceleration. The orientation of the accelerometer can be seen in Figure 3, below. The pivot arm was then dropped from vertical and data was recorded.
In order to compare data collected for fixed axis free fall motion to other motions we recorded data performing a variety of activities. The accelerometer was attached to the experimenters' waist and the subject walked, jumped, sat down and laid down. Data was recorded for every action.
During testing we were able to accurately calibrate the accelerometer and predict static orientation. In addition, we developed a theoretical model for falling, and gathered data for fixed axis falling and other daily activities.
During the calibration, numerous voltages were recorded for known accelerations and plotted against each other. This can be seen in Figure 4 on page 3. We found that there was a positive linear trend between the measured voltage and known acceleration. This relationship was used to calculate the acceleration of the accelerometer given the output voltages for the rest of the lab.
Logic was derived to use both the x and y axis data in conjunctions with the calibration data to determine the orientation of the chip which could be located on a person. It was able to accurately predict the angle from vertical within an error of ±2 degrees as described in Figure 5 below. It was also able to predict the rotation about the vertical axis of a person within an error of ±3 degrees as described in Figure 6 below. Combining these two angular outputs the orientation of a stable fallen person can be accurately determined.
In order to analyze a fall situation a theoretical model first needed to be derived as a comparison to real world data. A schematic of the setup can be seen in Figure 7 below. The chip was oriented so that the y-axis of the chip read the radial acceleration and the x-axis read the tangential acceleration. We simplified the problem assuming a frictionless pivot at the base of the arm and the force of gravity acting at the center of the arm. The shaft also had length l. By performing static and kinematic analysis we were able to predict both the theoretical x and y-axis acceleration and they can be seen in Figure 8 below. More information on the calculation for the theoretical model can be seen in Appendix A.
To verify our theoretical model it was compared to experimental data from the fixed axis free fall experiment. Our experimental data can be seen in Figure 9 below. There are results from three free fall tests plotted together in Figure 9, and the results are extremely similar from one test to another. The experimental data had results that were expected.
Other daily activities needed to be investigated to ensure that their results were not similar to those seen in the free fall situation data. Walking, jumping, sitting and lying down were investigated and their results can be seen in Figures 10-11 below and 12-13 on page 8 respectively.
To further investigate free falling we must compare the theoretical model to the experimentally collected data for free fall. Radial and tangential acceleration for three trials as compared to our theoretical model are shown in Figure 14 below. Note that experimental data does not exactly follow the theoretical model. The tangential acceleration has a very similar output but the radial acceleration seems to have a time delay. This could be due to a delay in the response of the accelerometer or a delay in the data collection of the electrical system. Further investigation of this discrepancy needs to be completed.
Assuming that the time delay can be identified and then predicted we can accurately model fixed axis free fall. Using the validated model we can define parameters to analyze data and sense if a fall situation occurs. One method of doing this would be to create bands around the validated theoretical model and detect if a majority of the data being collected was within the bands on both channels. If the data did fall within both channel margins it would signal a fall and actuate an alarm. The theoretical model with bands is shown in Figure 15 below.
In addition to investigating free fall situations we had to determine if the falling model was similar to any other daily activities. To have an accurate system, we had to ensure that there would be no false falling alarms. After comparing our theoretical model to typical daily motion activities in Figures 10-13 on pages 7 and 8 previously, it is clear that falling is not consistent with any of these plots. Therefore, the system will be able to distinguish between falls and any other daily motion activity and there will be no false falls.
We were able to use a MEMS accelerometer to characterize a free fall response and observe body orientation. Through this, we were able to develop a theoretical model consistent only with falling and not any other daily motion activity. This model could be used as trigger parameters for an emergency response system for senior citizens who experience unintentional falls. If widely used, this system could greatly decrease hospitalization and death as a result of slow emergency response and better many lives.
After completing the calibration we were able to accurately determine the static orientation of a person. Using our logic we could accurately determine someone's angle from vertical within 2 degrees as described by Figure 5 page 5 and rotation about the vertical axis within 3 degrees as described by Figure 6 on page 5.
Next we were able to create a theoretical model using kinematic analysis to predict what the free fall acceleration response would be shown in Figure 8 on page 6. This was then validated using experimental data and the only discrepancy was a time shift, which is shown in Figure 14 on page 8. Using the theoretical model we were able to design parameters to sense a fall as described in Figure 15 on page 9. We then were able to determine that there would be no false alarms due to other daily activities by comparing normal daily activities including walking, jumping, sitting, and lying down to the parameters used to sense falling.
Through this analysis we were able to use a MEMS accelerometer device to sense motion of the human body specifically in a free fall situation. This has many benefits to an elderly user. Even if the chip is damaged on impact, a fall is still recorded by the system and emergency response is alerted. Voltage characteristics consistent only with a fall situation eliminate false fall alerts that were present in the impact-based system. As discussed earlier in this report, faster emergency response leads to decrease in hospitalization by 26% and death by 80%. Therefore, we hope to drastically reduce the emergency response time through the use of this system and greatly improve countless lives.
We recommend further testing be conducted with a 3-axis MEMS accelerometer in order to have a better 3-dimensioanl analysis of human motion. Such analysis would be more advantageous than using the 2-dimensional analysis conducted in our experimentation. Also we believe that more full scale testing should be conducted. We also recommend generating models for other modes of falling. Since falling is not always likely to occur in a fixed axis position there are many different ways in which a person may fall. Further testing could analyze and characterize many falling different falling scenarios.
The next step includes development of a computer program that has the ability to recognize the data response consistent with falling. Such a program would then trigger an alert for emergency response to hospitals or family members. Also it is necessary to design the device with the accelerometer to be worn by the individual. Such a device would ideally be small so it would not disrupt normal activities. We recommend the device be attached to a garment on the individual's shoulder. The device must also be capable to wirelessly transmit data to a central computer in the home that would monitor for falling.

There are approximately 35 million people living in the U.S. who are over the age of 65 years (U.S. Census Bureau 2003). An injurious fall in an elderly individual can be devastating. Indeed, more elderly die from falls than die from motor vehicle accidents each year (CDC 1999). More than one-third of adults ages 65 years and older fall each year (Hornbrook 1994; Hausdorff 2001). Older adults are hospitalized for fall-related injuries five times more often than they are for injuries from other causes (Alexander 1992). The most costly fall-related injury is a hip fracture because it carries the risk for serious sequelae, including bone infection and pneumonia, both of which can be fatal. Other sequelae include loss of strength and self confidence, which can limit mobility and willingness to take part in social activities outside the home. A rise in serious head injuries resulting from elderly who fall has also been noted (Kannus et al. 1999). Not every fall results in injury. Roughly 5% of falls result in serious injury requiring medical attention (CDC 2003; U.S. Census Bureau 2003).
Common sense informs us that one can reduce the number of fall-related injuries in two ways: (a) reduce the number of falls by intervening on the risk factors for falls (for example, Weerdestyn et al. 2006), and (b) when a fall happens, reduce the risk of injury from that fall (for example, DeGoede & Ashton-Miller 2002 & 2003, Groen et al. 2005, Lo 2006). As far as the first approach is concerned, many extrinsic and intrinsic risk factors for falls have been identified (for example, Tinetti et al. 1994) and several types of interventions have been developed to address the most important of these factors. However, the number of falls each year remains high and the probability of ever reducing the number of falls to zero is non-existent. Furthermore, sooner or later everyone falls unintentionally, regardless of their age. So, the second approach leads us to want to find out what people need to know a priori and what they need to do during a fall so that they can avoid injury when they do suffer the inevitable fall.
It is known that when a fall results in the greater trochanter directly impacting the ground, then the risk of hip injury is 30 times higher that when the greater trochanter does not strike the ground (Nevitt et al. 1993, Hayes et al. 1993, Schwartz et al. 1998). The underlying message from these studies is that if an elderly person falls, "don't, ever, land on your greater trochanter".
The objective of this study was to estimate whether it is feasible for individuals to twist their pelvis during the ongoing fall in order to avoid landing on their greater trochanter. Do they have the hip external rotator strength that is needed to rotate the hip within the time it takes their pelvis to hit the ground? How do factors like age, gender, body mass, and obesity affect this calculation. Because, actual falls carry a risk for injury, we instead used literature values for muscle strength, our own experimental measurements of hip muscle strength in two individuals, and computer simulations to answer the question.
The technical question we wanted to answer is how long (in msec) it takes a healthy person to volitionally twist their pelvis through a set angle (in order to present the posterolateral part of their thigh/buttocks, rather than the greater trochanter, to the landing surface). In Feldman and Robinovitch (2007) the average axial rotation of the pelvis/hip upon impact from an unexpected lateral fall was 8 degrees in a posterolateral direction. However, from their Figure 2b, Appendix A, we see that an axial rotation angle of 20 degrees would suffice (a) to land on the maxim depth of muscular "padding" over the bony pelvis, and (b) to land on the aspect of the pelvis that does not include the greater trochanter. In other words, subjects need to axially rotate their pelvis at least 12 degree more than normal and ideally 22 degrees more than normal. We also chose to find out how long it takes to twist the pelvis through more than enough rotational angle, i.e., 30 degrees, given unilateral stance and full foot-floor frictional contact conditions. Finally, we need to find out how much this latency is affected by advancing age, increasing body mass, and decreasing hip muscle strength, and obesity.
A rough calculation for this time can be made by knowing the reaction time for the onset of muscle activity (~60-166 msec) (Ashton-Miller, Thelen 1996) and then adding the time required for muscle to develop enough contractile force and torque to rotate the hip externally 30 degrees, as well as counter rotate what was the stance leg in an internal hip rotation direction through 30 degrees in the opposite direction, thereby rotating the greater trochanter away from the impact site. This second rotation would require the hips to rotate 3° in the opposite direction relative to the first turn, and the leg to rotate 30°. If this time is less than the mean 626 ms (SD =40) (Feldman, et al. 2007) showed that it takes to fall sideways, then this calculation provides the theoretical basis for expecting that there is time for both young and elderly to present the "correct" posterolateral part of the pelvis (i.e., buttock) for impact with the ground in a sideways fall.
Two male subjects-A: 21 years old, 180 cm tall, and 72 kg, and B: 60 years old, 190 cm tall, and 84 kg, participated in the study. Each subject wore a belt around the top portion of their iliac crest (waist). A set of three infrared light-emitting diode markers was attached to the belt. Using an Optotrak Cetrus system each marker location could be measured in 3-D space and the change in hip angle during the course of a volitional axial turn of the pelvis could be calculated. The experiment began with the subject having one foot planted on top of an AMTI OR-6 force plate and the other foot lifted off the ground behind the individual. The subject would then twist their pelvis as quickly and as far as possible three times in either a clockwise or counterclockwise direction of rotation, while keeping their planted foot stationary. The peak torques, degree of turns, and time to turn was then calculated and descriptive statistics calculated.
The isometric torque values were recorded by having one foot planted on the force plate while the subject held a stationary ladder in front of them. The subject would then apply a torque to their foot while keeping their hips and foot stationary.
A model was created in Adams to simulate the motion of the hip, thigh, shank, and foot (Appendix K). One model, "fixed", was created which had the foot and leg had fixed to the ground which only allowed rotational motion of the hips via a torque source at the "hip". The angle of turn between the pelvis and ground, and the hip torque input was computed. For simplicity, a second model, "free", was created which represents the second part of the fall-when the foot has lost contact with the ground and a counter torque reaction is required at the hip. This counter torque moves the greater trochanter "away" from the impact area so that the posterior buttock becomes exposed to the impact. The values of inertia and dimensional values used for the hip, thigh, and shank were taken from Anthropometric Source Book (NASA, 1978).
The moment of inertia for the whole body was based on the results of David Carrier's article, 'Influence of Increased Rotational Inertia on the Turning Performance of Humans', for varying whole-body masses (Appendix B). These were extrapolated from the range of body masses of the subjects were used to the average masses of males and females for the young adults (age 20-29 years), heaviest age bracket, mid age, (age 40-49 years), and the old (age 60-74 years) (U.S. Department of Health and Human Services). The decrease in external hip muscle torque between 20 and 70 years was scaled from the maximum voluntary ankle dorsiflexor strength data reported by Darryl G. Thelen et al. in their article 'Effects of Age on Rapid Ankle Torque Development", Table 2 (Appendix D, E). We made the assumption that the hip internal and external hip rotator muscles have identical maximum torque-time characteristics to the ankle dorsiflexors. We made this assumption because we could find no data in the literature on age and gender effects on hip internal and external rotator muscle strengths, and because the volume of muscle is approximately similar.
Sample plots of the experimental results showing the angle of turn, torque, and angular velocity against time can be seen in Appendices F-J. The "best" hip rotator strength test results came from the trials which involved turning clockwise for both the right and left foot planted-which correlated to the internal and external rotation muscles respectively. The peak torque values were taken at the second peak, at which point the angle had the largest magnitude. The change in time for the angle was taken as the time for the angle to reach 90% of its maximum value from 10% of its baseline value at rest. Table 1 below, shows the averaged results of these trials with precision error.
Table 1: Maximum volitional internal and external hip rotator muscle strength and turn test results
These results were input into the Adams simulation along with the extrapolated values from the methods section. The results of these trials can be seen in Appendix N. All trials that did not complete the second rotation of turning the leg 30° could also not complete the internal hip rotation of 3° either. It was found that for the average inertia, 1.12 kgm2, if the time was 100 ms for the free leg, subject A at 50% of its strength and subject B did not complete the required angle of 30°, as seen in Figure 1 below. For the fixed leg simulation, only subject A at 50% of his strength was under the 30° for 400 ms. When running the simulation with subject A and B's experimentally determined torque and extrapolated inertias respectively, Figures 2 and 3 below, subject A met all requirements while subject B did not meet the internal goal at 100 ms and external requirement at 350 ms. When looking at the results for the extrapolated inertias and torques based on the averaged weights and loss of muscle strength for the young, middle aged, and old males and females, no females were able to make the required 30° external rotation at 100 ms while all males succeeded. For the internal rotation, all males could meet the requirements at 350 ms and above, while middle-aged females could not meet it at 350 ms, and old females could not meet it at 400 ms. In the extreme case for males and females 45 years old and above, who are of the upper 95 percentile of their weight bracket, none could meet the internal rotation requirement at 100 ms as seen in Figure 6. As for the external rotation, no male could meet the angle requirement by 400 ms, middle aged female by 450 ms, and old female by 500 ms.
The minimum required torques to complete a 3° turn for the internal rotation of the hip and 30° turn for the external rotation for different times can be seen in Table 2, below. The inertia values were extrapolated based on the average weight for males and females of ages 45 (mid) and 65 (old). In Table 3 the maximum allowable inertia and extrapolated mass was calculated for set average maximal torque values to complete the same turn angles. The average torque values came from the extrapolated average strength loss based on age and gender found by Thelen et al.
Table 2: Minimum torques to reach set angle of turn for average weighted people
Table 3: Maximum Inertia values to reach set angle of turn for average strength people
Based on the results, one can conclude that an individual's inertia and strength has a marked effect on their ability to rotate their pelvis and protect their hip from impact in a fall. Assuming that an angle of 30° is needed for the initial external rotation, 3° for the second internal rotation of the hip, 30° for the second rotation of the leg, a response time of 100 ms, and a time to fall of around 626 ms, those most at risk of not being able to exercise the proper fall technique would be elderly females, while the middle aged female would also be at a risk. This is due to the lower available strength in women in comparison to men. For the extreme case of having a weight in the upper 95% percentile, all are at risk of not being able to complete a fall with the correct technique. However due to increasing obesity in the population, one would have to look further into a scan of the pelvis region to see if an angle of 30° is required, or if there is enough excess tissue to supply enough cushion for the greater trochanter in a fall if one rotates the pelvis less.
The second turn completed by using the internal rotator muscles, was completed by all tests in less than 150 ms and therefore is not a bottleneck for the fall process. This is due to the leg having significantly smaller rotational inertia than the torso. The initial phase of external pelvic rotation holds the most significance. Based on the experimental results for maximal angular pelvic velocity (approximately 100 degrees/sec) and the knowledge that the normalized torque occurs at the same time no matter an individual's age or strength (Thelen), all turns seem feasible to complete in the required time. However, not all turns in the experiment were completed past 30°. This could be a flexibility issue which is a separate issue. Women would be expected to be more flexible than men, so lack of flexibility may not be a problem for them.
Limitations of the study are the assumption that maximum voluntary hip external and internal rotator muscle torques are similar to maximum voluntary ankle dorsiflexor muscle torques. In addition, our estimates of single leg rotational inertia were only approximate and need to be improved. The experimental hip torque data was measured with one foot planted on the ground while the subject anticipated the turn and started from a balanced stance. In a real life situation a loss/lack of friction under an individual's feet would cause an imbalance by surprise. In addition, when looking at the graphs for the experimental torque, there was often a high torque value in the opposite direction before the maximum angle of turn. This suggests a preparatory muscle tension in the experimental trials which would not be available in a surprise fall. This makes the experimental values an upper limit and with a short reaction time. This can also be seen when comparing the isometric torque values, Appendix O, with the experimental ones -- which are higher. Finally, we measured hip isometric strength and rotational performance data on only two males. More data are needed on men as well as women of different ages.
1) These calculations suggest that all healthy individuals should be capable of axially rotating the pelvis through an angle of 20° in order to avoid presenting the greater trochanter to the ground in a fall.
2) If a full 30° turn angle is required to be completed, then older individuals, and particularly females and obese individuals, over the ages of 45 years may not have sufficient strength to achieve the avoidance maneuver.
3) To avoid injury it is important to retain hip internal and external rotation flexibility, and for those at risk for hip fractures to increase their hip rotator muscle strength.
4) Further hip muscle strength and performance testing should be completed in order to obtain a better representation of the capacities of both genders of different weights and ages.
5) Further research should involve actual fall tests to see if the required neuromuscular coordination for the greater trochanter impact avoidance maneuver is in fact available during an actual fall to the side.

Current padding systems used for wood flooring are insufficient to dampen the impact vibrations and sound vibrations that carry through the floor to the room below. Sound vibrations in homes cause sleep loss, emotional and physical response, annoyance and activity disturbance. Sound vibrations have been studied using sound equipment; however, this is expensive. The equipment is large and bulky and has a limited dB level. Impact vibrations data collection and analysis is less costly and requires a simpler technique. Damping these vibrations leads to a better quality of life. It is the objective of this project to record impact vibrations using a Precision ±1.7 g Single-/Dual-Axis i MEMS® Accelerometer ADXL103/ADXL203, analyze the data, conduct evaluations of damping material based on the data collected and determine the best damping material, and relate impact vibration damping to sound vibration damping.
A: Total absorption
In order to simulate an actual residential environment, a particle board and joist system was constructed to replicate a flooring platform. A tough and groove wood flooring that was constructed using Brazilian cherry wood was clamped to the platform. The model MEMS accelerometer was attached using tape on the top surface of the wood flooring at the far end of the platform. A basketball was then dropped from a prescribed height of 0.762 m on to the center of the platform. This experiment setup is shown in Appendix A. Output voltages from the MEMS accelerometer were then collected using an oscilloscope, shown in Appendix B. Trials were repeated placing various damping materials between the platform and wood flooring. Five trials were conducted for each damping material. The experiment was then repeated using a softball as the impact object from a height of 0.864 m. Data was then collected with the MEMS accelerometer positioned on the underside of the platform as shown in Appendix C. Six different damping material configurations were analyzed in the experiment: no damping material, polystyrene, blue PVC vinyl foam, white vinyl foam (current industry standard), fleece and a combination of fleece and the blue PVC. The damping materials are illustrated in Appendix E.
The flooring system can be modeled as a mass/spring/damper theoretical model setup and is pictured in Appendix D. It is assumed that the platform is a rigid body, the Brazilian cherry wood acts as a mass and spring and the material acts as a damping system. By using this theoretical model's vibration dynamic equations in Equations 1 and 2 below, we can find the dynamic response.
The material properties for the Brazilian cherry wood are outlined below in Table 1.
These material properties can be used in Equation 3 to calculate the spring constant. This spring constant along with the mass of the wood is used to calculate the natural frequency in Equation 4.
A sample impact vibration recorded by the oscilloscope is shown in Appendix F. The magnitude of the first wave length X1, the magnitude of the consecutive wave length X2 and the period were collected from each test trial. This data was then used to calculate the peak to peak ratio in Equation 5 and finally the damping ratio in Equation 6 for each trial, shown below.
The average damping ratio was calculated for four cases: a basketball dropped with the MEMS accelerometer on the top of the floorboard system; a softball dropped, MEMS accelerometer on top; a basketball dropped, MEMS accelerometer on bottom; and a softball dropped, MEMS accelerometer on bottom. Each case study varied the configurations of the damping materials when measuring the oscilloscope voltage output from the MEMS accelerometer. From the four cases, an average damping ratio was then calculated for each damping material. The uncertainty was calculated by taking two times the standard deviation.
Table 2 on page 6 gives the averaged results of each damping material for the four case studies and their corresponding five damping material test trials we performed. Because the resolution error of the equipment was small, the error in the damping ratio was calculated from its precision error for each of the five tests trials we ran in a case. As a result of the high noise and inconsistent peaks in the data (sample graphs shown in Appendix F and E), X1 and X2 were difficult to measure and accounted for the majority of damping ratio error. In particular, the data using the fleece configuration damped in a very short time and left very few peaks to choose suitable measurement values for X1 and X2, which is why its error is so high. Table 3 shown on page 6, was created to show an overall summary of all of our trials and is an average of Table 2 values.
The MEMS accelerometer test data shows that the vibrations in the floor board are those of a damped harmonic oscillator. The initial research on the subject of vibrations and floor boards led to the conclusion that there should be some coefficient β, shown in Equation 21 on page 11, which relates radiated sound power to the peak vibration. Using this argument the highest damping value for the vibrations was tested for, since this will logically produce the least sound. From Table 2 an overall trend can be observed: damping ratio is higher for a bottom accelerometer position rather than for a top one. This occurs because the surface vibrations are more reliant on the material properties of the wood to damp most of the vibration, and the bottom vibrations have the additional damping of the test material and the joist. The difference in damping values could also be resulting from the difference in location of the MEMS accelerometer on the floorboard plane. The top position is located at the far end of the floor board as shown in Appendix A. The bottom position is located directly under the impact area secured between the cross wood supports, as shown in Appendix C, which allowed for easier attachment. The individual damping ratio values were averaged to determine the best material overall in all sound insulating conditions simulated. From Table 3, the PVC blue foam – fleece combination had the highest value at 15.15x10-5±6.66x10-5. The order for combination (either blue foam on fleece, or fleece on blue foam) did not matter for damping value with in error. Tests with combinations of materials showed an increase in damping values; however, laboratory time did not permit further testing of all configurations of current damping materials. To experiment with achieving a higher damping value, a vibration test for the combination of polystyrene and fleece should be conducted. The best individual insulating configuration is the fleece with a damping ratio of 14.28x10-5±12.8x10-5. The high error of the damping ratio is attributed to the inconsistency of the impact force. Shifting of the position of the accelerometer and its tape during impact contributed to additional error.
Noises in households are created from vibrations propagating through the floors and walls. It is possible to use MEMS accelerometers to determine the damping coefficient of wooden floor boards. The vibrations are identical to the case of damped harmonic oscillators, where higher damping ratio equals less vibration. We were able to determine the damping ratio for our test floor that was padded with sound insulating damping material. The damping ratio had unusually high error, which is attributed to the inconsistency with the impact method and accelerometer placement.
The test material with the highest damping ratio was the combination of blue foam on top of fleece. The best choice for commercial use would be the fleece only for several reasons. This material had the second highest damping ratio, is inexpensive, thin, and has limited deterioration over time.
More tests need to be done in the future to reduce experimental uncertainty and find better methods of reducing the propagation of sound waves from impacts. We could use a standard tapping machine for constant input vibrations to prevent human error in the drop force. Additional test trials can also be done with more materials such as composites, cork, foam rubber, and so on, to find the best insulator make-up. The effect of geometry on the insulating volume sound muffling abilities should be examined. For large-scale damping, we would like to investigate the effects of using vibration reduction devices, such as a shock absorber or tuned mass damper systems.
We would like to conduct further testing to determine if reducing the time and amplitudes of upper room impact vibrations using materials with increased damping constants, in fact, reduces the noise levels transferred to rooms below. We can also test the vibration response of the joist-setup to determine the system's natural frequency and model a differential equation (and its solution) describing the impact vibration response.
In order to reduce the error in the damping ratio that we found by dropping a basketball or softball, a more consistent force input method is required and was formulated. Appendix H shows the proposed force vibration experiment set-up. The test procedure is as follows: the DC motor rotates a mass connected to the floorboard at its midpoint; a linear variable differential transducer (LVDT) measures the vibration response; the resulting signal demonstrating floorboard deflection versus time is captured by an oscilloscope; the motor speed is then to be increased until the LVDT measures a local maximum in the deflection data; at this speed, the vibration dynamic period can be procured from the time for 10 cycles to pass at steady-state. The fundamental natural frequency of the floorboard in bending would occur at this maximum displacement, and is calculated as follows in Equation 7:
However, error can occur when assuming that this maximum displacement is completely a result of bending, as torsion could be identified incorrectly as bending by the LVDT. Our earlier force input method of dropping a basketball or softball could be used to simulate free vibration and verify the LVDT set-up's determination of the fundamental natural frequency, helping to reduce uncertainty about the bending mode of the floorboard.
Floorboard stiffness is a material property of the wood, and has been found to greatly influence the impact vibration response. There is much variation in the material structure of Brazilian cherry wood from piece to piece, so to find our floorboard set-up's stiffness, we would conduct static load testing by placing a point load at the middle position of the joist making sure the load was distributed uniformly across its width. The deflection would then be measured using a dial indicator. The stiffness is calculated from load and deflection information shown in Equation 8 below. It can be validated by Equation 9 using the fundamental natural frequency found from the above test set-up. The boundary condition parameter, k, can be found from previous experimental data for our joist (a pin-pin support structure) to be 2.46. Finally, we can find the natural frequency for the floorboard bending mode, shown in Equation 10.
The damping response behaves viscously – that is, where the damping force is proportional to the displacement and velocity of the floorboard vibrating. Therefore, a modification representing energy loss' contribution to the vibration response can be included in our predictive equations. Using strain gauges and force transducers, the strain and stress of the system can be recorded in the LVDT set-up. The loss factor, or the ratio of average sound energy loss per radian to the peak strain energy in harmonic oscillation, can be calculated. The loss factor is related to the tangent of the ratio of phase shifts between the stress and strain, shown in Equation 11 below.
Given that we displace our mass (the floorboard) and let it vibrate freely at is damped natural frequency (Equation 12), according to our characteristic equation (Equation 2 on Page 4), its homogeneous solution to is displacement as a function of time is shown in Equation 13.
With this equation, the initial conditions, and the experimentally determined natural frequency and damping ratio, we can know the under-damped vibration as a function of time, and, thus, the exact behavior of the floorboard. Using the loss factor of the floorboard, we can get the values for A and φ, as shown in Equations 14 and 15.
We can then put forth this relation using different damping materials to find out how quickly the vibration energy dampens out to a convergent value. Appendix I shows a sample under-damped response to be calculated from damping test trials.
To determine if increasing the damping ratio in the floorboard set-up actually reduces the noise level in the lower room, when there is impact vibration in the upper room (or vice versa), we can conduct an experiment comparing sound intensity. Sample experimental set-ups are shown in Appendix J.
Using a sound intensity probe and a portable analyzer, we can measure Ia and Ii of the source room, which is the origin of the sound. We can gather data about the source and receiving rooms' sound qualities (absorption coefficient, total absorption, and source room constant) using Equations 16 to 18, shown below.
Using a microphone and sound intensity probe, we can measure sound pressure and wave velocity, and, thus, the acoustic impedance of Brazilian cherry wood, as shown in Equation 19 below.
In order to validate our hypothesis that states that with less, more damped vibration there is less radiated sound, we must first relate the drop force to sound power radiated in Watts from the impact, shown in Equation 20 on page 11 and in Appendix K.
We can also find the effective radiated sound power, or the power experienced through a certain surface area, using Equation 21 on page 11. This can be related to our MEMS accelerometer voltage output levels, by multiplying the amplitudes by some coefficient, β. This value can be found by using the amplitude at the highest peak of the oscilloscope output to describe the initially loudest stage of an impact, where sound measurements are taken.
Given all of this information, we can find the transmittivity constant, which tells us the ratio of sound power experienced in the source room to that of the receiving room, shown in Equation 22.
The impact sound level (in dB) can then be found from Equation 23 below.
This value should be shown to decrease from Room 1 (upper source) to Room 2 (lower receiving) as more damping material is added. Using this equation, we can relate the oscilloscope output voltage from the MEMS accelerometer readings, and relate it to the impact sound level transferred from the upper source to the lower receiving room. This will to provide information on the effect of adding specific damping materials on reducing impact vibrations and noise levels in separate rooms of households.

For project 4, our team must evaluate the patented design suggested by TYR for their swimsuits. For part a, we had to calculate the natural flow without tripping around the sphere using Fluent. We than had to calculate the natural flow of the same flow tripped prematurely into turbulence. We evaluated the results of laminar and turbulent flow. For part b, we had to do the same as part a except model the whole body of the swimmer, rather than just the head. Next, we commented on the claims made by TYR's website and suggested some improvements on their design. The parameters used to find the speed of the Olympic swimmer and properties of the water are shown in table 1 below. For the laminar cases, we found that using steady or unsteady time resulted in similar data. Unsteady vortex shedding occurred for both laminar and turbulent cases. For the turbulent sphere case, unsteady 2nd order implicit time was used and for the turbulent body case, steady time was used because it resulted in the most accurate data.
Using Gambit, we created the mesh as was described in the problem statement. For part a, the mesh is shown in figure 1. We modeled a person's head as a sphere with a diameter shown in table 2. For part b, the mesh is shown in figure 2, and we modeled the whole person's body using body dimensions for the average human being also shown in table 2. For both parts, we used a tri pave face mesh and a tetrahedral/hybrid TGrid volume mesh. This mesh seemed to work best especially when we modeled the whole body of the swimmer due to the varying dimensions. For the mesh around the sphere/body we modeled it similar to project 2, only revolved it 180° and labeled the flat plane as a symmetry boundary condition. The total height and length from the sphere for part a was 10*diameter of the sphere, and 20*length of the sphere. For part b, a height of 7.5*chest diameter and length of 30*chest diameter was used. The meshes were then imported into Fluent where the calculations began.
Once the mesh was created in Gambit, we added the boundary layer thickness in TGrid for the second parts of a and b when turbulence was being tested. We found the location of the first grid point and boundary layer by using equations 1-5. L is the distance of the arc length of the top left quadrant of the sphere for the sphere, or half the total length of the body for the body, is the kinematic viscosity, Cf is the skin coefficient, is the friction velocity, and is the dynamic viscosity. Using prisms and the nominals pointing outward from the sphere/body (see figure 2) we set the first heights (BL/10 shown in table 3) with 10 layers, a constant growth method, uniform offset method, and weight of 1. New domains were made for the tri mesh, with the exception of the sphere/body, and then auto meshed. No boundary layer was created for the laminar cases. The boundary layer conditions can also be seen in figure 3.
Once the sphere was created and meshed in Gambit, we began by running tests in Fluent with fluid speeds equal to that of an Olympic swimmer with a Reynolds number approximately 403,000. By comparing our case with the coefficient of drag against Reynolds number for a sphere, as shown in figure 4, we concluded that due to the flat laminar region, we could run the trial at a lower Reynolds number and get the same coefficient of drag with more accurate results. We used a Re of 1584 and found the velocity to be 0.008 m/s; which was then inputted in Fluent to find the drag coefficient. In Fluent, the residuals were changed to 1E-4 to increase the accuracy of our results. The trial was initialized with zero initial conditions and the material and boundary conditions stated above were used.
The equation used to find the Drag coefficient is shown in equation 6. The frontal area used is half the cross-sectional area of the sphere since the mesh was created as a half sphere, πr2/2 with symmetry conditions. FDrag is the drag force obtained in Fluent (N), ρ is the density (kg/m3), u is the flow stream velocity (m/s), and A is the frontal area (m2). The total force, along with the breakdown of the pressure and viscous forces, and calculated Cd is shown in table 4 below. Pressure drag accounts for 69.6% and viscous drag accounts for 31.4% of the total Cd. According to [1], the Cd is approximately 0.4 for the Re that we ran it at, therefore, our results match fairly well with the reference. The velocity field, contour plot of pressure, and contour plot of streamlines are shown in figure 5, figure 6, and figure 7 respectively for Re equal to 1584 for laminar flow around the sphere. One can see that backflow occurs in the near wake region for the sphere in laminar flow.
For the sphere in turbulent flow, we used the same mesh as the one for laminar flow except we added a boundary layer thickness. We used a Re equal to 403,000 which was calculated using the average velocity of an Olympic swimmer using equation 1, where L is the diameter of the head. We made sure there was at least 10 grid points within the boundary layer when we doubled the mesh.
Using the parameters in table 1 above, the tests were run in Fluent. The k-epsilon model under viscous model was used with the default model constants. Realizable and non-equilibrium wall functions were used because we found from Project 3 that using those options gave us the most accurate results. The residuals were changed to 1E-4 for all to increase the accuracy of our results. The boundary condition of the velocity inlet was set to 2.0408 m/s and the model was initialized with zero initial conditions. We ran the tests in Fluent using a Hydraulic Diameter of 0.1783 m which is the diameter of the swimmer's head. We used 0.1% for the turbulence intensity.
Using equation 6, we found Cd for this model. Pressure drag accounts for 77.3% and viscous drag accounts for 22.7% of the total Cd. According to [1], the Cd is .08 for the Re that we ran it at, therefore, our results match fairly well with the reference. The velocity field, contour plot of pressure, and contour plot of streamlines are shown in figure 8, figure 9, and figure 10 respectively for Re equal to 403,000 for turbulent flow around the sphere. The amount of backflow and the Cd was greatly reduced from the laminar to the turbulent case for the sphere.
Shown in figure 11 below is the mesh used for the body in laminar flow. The same velocity used for the laminar sphere was used for the body with laminar flow. The total force, along with the breakdown of the pressure and viscous forces, and the calculated Cd is shown in table 6 below. Pressure drag accounts for 33.7% and viscous drag accounts for 65.6% of the total Cd. Our Cd for the body was similar to that of the sphere according to [1].The velocity field, contour plot of pressure, and contour plot of streamlines are shown in figure 12, figure 13, and figure 14 respectively for Re equal to 1584 for laminar flow around the body. One can see that backflow occurs in the near wake region for the body in laminar flow.
The total force, along with the breakdown of the pressure and viscous forces, and the calculated Cd is shown in table 7 below. Pressure drag accounts for 70.6% and viscous drag accounts for 29.4% of the total Cd. The velocity field, contour plot of pressure, and contour plot of streamlines are shown in figure 15, figure 16, and figure 17 respectively for Re equal to 403000 for turbulent flow around the body. When the flow is prematurely tripped into turbulence, the amount of backflow and Cd is greatly reduced as expected.
In order to help reduce the drag, we would recommend that TYR try a few additional techniques. Similar to the trip wire causing the flow to switch from laminar to turbulent, we would also recommend that the suit becomes porous. By becoming porous, it would increase the surface roughness and enhance turbulence. In addition to this, having a porous material may enhance the wall suction/blowing while the swimmer is moving. As the fluid particles get close to the wall (the suit), they lose their kinetic energy near the separation point. By replacing these particles with ones with higher energy, either by sucking them into the suit and allowing those with high kinetic energy to move down, or by pushing higher energy particles out of the suit, turbulence can be tripped. Another suggestion would be to decrease the friction between the water and the swimsuit by making the surface slippery. This could be done by applying a slippery liquid to the suit by either having it rubbed on before a race, or by adding a chemical when washing the suit.
Another suggestion would be to change the entire shape and thickness of the swimsuit. Looking at figures 13 and 16, one can see that the pressure around the swimmer's shoulders is relatively high. This is due to the fact that there is a sharp transition in shape from the swimmer's neck to their body. Separation arises from adverse pressure gradients. These must be removed or decreased if one wishes to decrease the drag coefficient. One way to decrease the drag coefficient and to decrease the pressure around the shoulders is to make the transition from the neck to the shoulders smoother. This can be done by using pads just above the shoulders or around the neck assuming it does not interfere with the motion of the swimmer.
In conclusion we found that our drag coefficient results for the sphere were similar to that of other studies [1]. It followed the trend that by tripping the flow from laminar to turbulent, the overall drag coefficient could be reduced. There was a significant loss of separation in the backflow region behind the sphere in our results as well as those claimed by TYR [2], figure 18 below.
TYR claims to be able to decrease their pressure drag by 18% [3]. According to our results, an accurate conclusion based on this claim cannot be made. We feel the geometry of the body greatly influences the separation formation. This in turn will affect the pressure forces that are exerted on the body. We do feel however that the decrease in Cd from laminar to turbulent is significant enough to justify the suit. Also, this proves that our results are accurate, just not in the sense of pressure and viscous forces. As shown in figure 18 from TYR, the flow separation region is greatly reduced in the turbulent case; the same is true with our laminar and turbulent models, shown in figures 5 and 8 respectively.

Our team recreated the experimental setup shown in the project 2 description and shown in figure 1 in Braza et al. We created two different meshes, shown in figures 2 and 3 below, to check for grid independence. The team used a uniform quad mesh. The meshes were then imported into Fluent where the calculations began. We doubled the resolution, until our results were very close to each other which indicated that the solution we obtained was grid independent.
Our first task was to show the vector plots of the velocity field in the wake region at each Reynolds number (Re) and this can be seen in figure 6 on page 5. Next, we had to show contour plots of pressure and streamlines in the wake region at each Re number. Our fourth task was to show a plot of the re-attachment length versus time for Re=40 and compare it to figure 4 in Braza et al; this is shown in figure 9 on page 8.
Next, we show a plot of the pressure distribution on the cylinder wall as a function of θ at Re=40 and compare that to figure 5 in Braza et al; this is shown in figure 10 on page 9. Our sixth task was to plot drag coefficients and separation angles as a function of Re and compare it to figures 6 and 9 in Braza et al; this is shown in figures 11 and 12 on pages 9 and 10. Next, we plotted the time history of pressure at a selected point in the near wake and used this to calculate the Strouhal number; this is shown in figure 13 on page 10. Our last and final task was to plot the Strouhal number as a function of Re and compare it to figure 9 in Braza et al; this is shown in figure 14 on page 12.
In Fluent, we used air at 273K with a kinematic viscosity (νk) of 1.32E-5 m2/s and an inlet velocity determined by equation 1. The same mesh was used for all Reynolds numbers (Re). The density of the fluid (air) used was 1.292 kg/m3 and the dynamic viscosity (νd) used was 1.71e-05 kg/m*s. We first scaled our mesh in Fluent to convert from cm to m. We solved with an unsteady time and 2nd order implicit unsteady formulation. The momentum was changed to second order upwind and the absolute criteria of the residuals were changed to 1E-5 to increase the accuracy of our results. The boundary conditions of the velocity inlets were set to have an x-velocity shown in the table below and the model was initialized with zero initial conditions. From figure 9a in Braza et al, we were able to find an approximate Strouhal number and estimate the period for each Reynolds number using equation 2 below. We divided the period by 20 to find an appropriate time step size while iterating. The max iterations per a time step was set to 100 to make sure that the solution would reach the residuals and converge each cycle. For Re values of 100, 200, and 400, the model first needed to be manually triggered to achieve a periodic steady-state solution represented by vortex shedding from alternate sides of the back of the cylinder. This was done by setting the bottom velocity inlet to twice the U velocity. The trigger was allowed to run until the iteration plot showed a fine steady line under the set residual. We used a time step size 100 times less than the predicted time step size while triggering. The pressure was plotted at a point in the wake region 0.03 m above and 0.15 m to the right of the cylinder while the model was iterated. From here we could see when the solution produced a steady frequency of at least five cycles at which point we took our data measurements over five different times.
Using Gambit, we created a mesh based on the experimental setup shown in figure 1 and tried to recreate the mesh shown in the project description. Using Gambit, many different meshes were created and tested and the best single mesh is shown in figure 2. The type of mesh used was a uniform quad mesh.
In order to verify that we had mesh independence, we compared the values of reattachment length, drag coefficient, Strouhal Number, and separation angles for the two meshes. After creating the single mesh, we doubled it and calculated the four variables we were looking for. After realizing they were not as close as we would have like them to be, we went ahead and halved the single mesh we had and calculated the four variables again. We believe the results obtained, shown in table 2 for the three different meshes, are sufficient enough for us to use the single mesh. We showed our mesh independence for Re=400 based on 2nd-order steady flow.
The boundary layers can be seen in figure 4 on page 5. We created two velocity inlets. The first one was the 2nd quadrant of the large circle attached to the top horizontal line of the rectangular box and the other was the 3rd quadrant of the large circle attached to the bottom horizontal line of the rectangular box. This was done because Fluent cannot naturally predict periodic unsteady flow. Also, an outflow was created at the end of the rectangle and both the top and bottom halves of the smaller circle were set as walls to model the cylinder.
As the Re becomes greater than 40, asymmetrical eddy patterns occur seen in c. and d. below. This is shown as the alternating separation of the vortices which have been diffused from the cylinder; these are known as the Karman vortex paths.
Using our single mesh, we obtained a plot of the reattachment length vs. time for a Re=40 as shown in figure 9 below. Our data analysis is shown in table 3. For Re=40, figure 6a on page 5, one can see that there are two attached vortices behind the cylinder. The flow reaches steady state at approximately 16 when looking at our experimental compared to 15 when looking at figure 4 in Braza et al. Our figure for reattachment length closely matches figure 4 in Braza et al. Equation 3 was used to make time (t) dimensionless. We obtained a dimensionless reattachment length by dividing it by the radius.
(Eqn. 3)
We were able to calculate Cp by using equation 4 below where P represents the total pressure and Po represents the initial pressure. Our values showed a similar curve to that of Braza et al, but were slightly lower than Braza's Re=40 values and more closely match Braza's Re=20. This can be seen in figure 10 below.
Cp=(P-P0+.5*ρ*U2)/( .5*ρ*U2) (Eq. 4)
To solve for the Drag Coefficient (Cd), equation 5 was used. In Fluent, we ran 5 trials for each Re and found the Drag Force. Then using density (), velocity, and the frontal area (A), we are able to produce figure 11 that shows Cd versus Re. This graph compares nicely to the one shown in figure 6 in Braza et al with our values being just slightly higher which shows that our data agrees. The area consisted of the height (diameter) of the cylinder and the width was assumed to be of unit length meter.
(Eqn. 5)
To calculate the separation angle (Ѳd), we ran 5 trials for each Re and took the average Ѳd. The results are shown in table 4 and in figure 12 below. One can see that our figure compares very nicely to figure 6 in Braza et al.
For each Re not including 40, we ran five trials and found the period. Then we calculated the Strouhal Number (SH) using equation 2 below. D is for diameter and u, the uniform-flow velocity, was calculated from each Re. Figure 14 a) below shows the Strouhal number for each Re which compares nicely to the reference b).
After running many simulations in Fluent, we noticed that at low Re values around 40, the flow was steady state with two separation bubbles as shown in figure 6a. As the Re values became higher there was vortex shedding behind the cylinder. In conclusion, we found that our calculations very closely match that in the reference Braza et al. The values for separation angle, reattachment length, Strouhal number, and drag coefficient are all within 7% for the single and double mesh. The coefficient of drag and wall pressure were the most different compared to the Braza et al., with our values leveling out around 1.5-1.6 and Braza's near 1.2 for the coefficient of drag and our Cp closer to Braza's Re=20 instead of 40.

Well-modeled heat transfer models are required to prevent microprocessor failure. To find how a microchip's heat transfer and resistance vary with changes in temperature, we conducted experiments that simulate microprocessor heating. The purpose of this report is to find both theoretical and experimental values of the thermal coefficient of our chip, the time constant to reach steady state temperature, the chip-to-ambient resistance (and its components), and then to develop a heat transfer model to predict the resistance of a chip to ambient air as a function of air velocity and fin length. Lastly, using our data and knowledge of heat transfer, we would like to recommend different approaches to allow better cooling of the system.
(see Appendix A on p. 4)
In the first experiment, we attempted to calculate the thermal coefficient of resistance of our microprocessor chip (shown in Appendix M, p. 9) by calibrating the electrical resistance of the sensor on the chip as a function of surface temperature. The chip was fixed to a hot plate using thermal grease and electrical resistance was measured using the '4-point probe method'. Surface temperature was measured using an Omega HHI2 thermocouple, placed on the resistor pattern by the researchers. Initial chip resistance was found after applying a voltage of VDC ~ 100 mV. The resistance was then measured at a temperature range of 30 °C to 120 °C, since we did not want to reach 150 °C, the estimated failure temperature of the chip. Because of the unsatisfactory results, we redesigned our test procedures.
Our improved test setup used an integrated circuit packaging which had mechanical support, electrical shielding, and permanent connection of leads for robustness. Appendix K on p. 9 shows a photo of the setup and equipment used. We repeated the procedure in Experiment 1with a smaller range of 22 °C and a smaller maximum temperature to avoid damaging the chip.
In Experiment 3, we applied voltages to the on-chip resistor pattern ranging from 5 to 25V in increments of 5V and determined the surface temperature of the chip by measuring its current draw. The heat-sink temperature was measured using our thermocouple. We collected data from three trials.
In the last experiment, we tested our chip with an Alpha Novatech S-1530 20W heat-sink (cut in quarters) in a model wind tunnel (Appendix J, p. 8). We measured different flow rates using an anemometer by varying the voltage, from 6V to 12V in increments of 2V, supplied to the fan and measured corresponding current. We then theoretically estimated the chip temperature, Tchip using results from Experiment 2 when the chip was held at voltages of 9.71, 14.55 and 19.41V. We calibrated the air velocity V∞ as a function of power input to the cooling fan.
From Experiment 1 we assumed a proportional fractional change in resistance to the temperature change by a coefficient, α, as shown in Eq. 1.
Using Eq. 1 our calculated α had large errors and inconsistencies between data sets, and was considered to be skewed. The results of Experiment 1 are shown in appendix C on p. 6.
From Experiment 2, with the ceramic wire-bonded chip packaging, our initial resistance value was 291.78 ± 0.02 Ω at 22 °C and α was 0.00283 ± 0.00035 1/°C. Using Eq. 2, where i represents each trial and α is the mean of all the αi, we found α = 0.003437 ± 0.00085 1/°C. The plot of R vs. T is shown in Appendix D on p. 6.
Heat transfer and the resistance from the chip to the heat-sink was calculated using Eqs. 3 & 4.
We found Rchip-to-heat-sink was 9.986 ± 1.154 W/K. Heat transfer vs. ΔT is plotted in Appendix E on p. 7.
To determine the time constant for the chip to reach steady state temperature we used Eq. 5.
where Cpackaging is the capacitance of the ceramic (Appendix B, p. 5). Experimentally, the time constant was 4.62 ± 0.53 s, which was calculated using the experimental resistance value and the theoretical capacitance. This is close to the theoretical value of τ = 3.95 s.
Our theoretical calculation for the chip-to-ambient resistance was modeled as a sum of the resistance from the conduction in the chip (silicon) the contact resistance from the silicon to the aluminum, the resistance from the conduction in the base of the aluminum heat-sink, and the equivalent resistance of the convection from both the base top surface and the fins of the heat-sink. For the contact resistance, we used the top surface area of the chip, which was less than the heat-sink base area, and a contact resistance given in Appendix F on p. 7. For modeling the resistance of the heat-sink, we approximated the fins as cylinders because we were unable to find square geometry constants at the tested Reynolds numbers for use in calculating Nusselt number Nu using the Hilpert correlation [3]. Also, because our chip had fewer than 20 fins, we multiplied Nu by a correction factor C, as shown in Eq. 6. The electrical circuit diagram of the system can be seen in Appendix H on p. X (all physical constants and coefficients used are given in Appendix A on p. X). Reynolds number ReD was calculated using Eq. 7 below.
where uf,∞ is the maximum velocity between the fin cylinders. From Eq. 5 we were able to find conduction coefficients, the heat-sink total efficiency, and ultimately the heat-sink resistance. The resistance values are summarized in Appendix F on p. 7.
Using our data from Experiment 4, we used the divided ΔT by QH to solve for Rchip-to-ambient. In Fig. 1 we plot the Rchip-to-ambient vs. air velocity for both our theoretical calculations and measurements from Experiment 4 at chip voltages of 9.71, 14.55 and 19.41V. The experimental data follows the same trend as the theoretical data as well as the manufacturer's data for the resistance of the heat-sink alone [2]. For the range of tested velocities, the percent error of our experimental versus theoretical resistances never exceeded 12.5%. In our plot, uncertainty is due to error in measurements of current and voltage and to resolution and precision error in the anemometer readings.
Assuming fatal failure occurs at a chip temperature Tchip = 150 °C, we calculated maximum allowable chip heat exchange for our tested velocities using Eq. 6. The results are shown in Table 1. As expected, maximum allowable chip power QHmax increases with increasing air velocity.
(Eq. 6)
The alpha obtained from experiment 2 was more accurate than from experiment 1 because we used a proper 4-point probe setup. This decreased the parasitic resistance, therefore lowering the initial and measured resistance. More importantly, we obtained the data without damaging the chip. In experiment 1, we scratched the surface of the resistor of the chip we were measuring, sometimes so severely that the resistance would increase dramatically between different attempts at the same temperature. The large temperature range also contributed the larger discrepancies from the linear model we were attempting to validate. We found the best alpha value for the second experiment using the normalized slope of R vs. T as it produced the smallest error.
The theoretical time constant, τ = 3.95 s, was smaller than the experimental value, 4.62 ± 0.53 s, possibly because the ceramic volume used to calculate ceramic resistance was estimated as that beneath the chip. The experimental resistance was also higher than the theoretical one which could contribute to the larger experimental time constant. They were within 17% of each other, which was considered satisfactory. Our theoretical results imply a required time of ~ 20 s to reach 99% of steady state. We may not have waited this long during the experiment, which may have added error to our results.
We were able to develop a heat transfer model which could predict Rchip-to-ambient for a given air velocity with increasing accuracy as the velocity is increased. Our experimental and theoretical calculations for Rchip-to-ambient vs. V∞ are closely related quantitatively and in trend, showing the validity of our model. They also agree with the trend given by the manufacturer: as the air velocity is increased, so does the maximum allowable chip power. This is valid as increased velocities would increase heat dissipation from the heat sink. Also, it was not surprising that the experimental resistances were slightly higher than the theoretical calculations which could be manufacturing inconsistencies. It appears that the resistance of the total system was not dependent on the chip voltage, which makes sense physically.
The results of our experimental and theoretical calculations for the S1530 20W heat-sink have close agreement and we have calculated maximum heat transfers to prevent failure versus velocity (Table 2 on p. 4). For increased chip cooling, resistance can be lowered by increasing the fin length and/or spacing, increasing the profile area, or use of a higher conductivity fin material, such as copper or graphite [4]. Our studies show that there is a threshold length of 120 mm beyond which increasing fin length does not help (see Appendix L on p. 10). Enhanced convection from a faster or nearer fan or liquid cooling can also help. Other options include refrigeration/solid-state refrigeration if packaging space is not a limiting factor.

There has long been and interest in studying the mechanics of aortic rupture [1]. The biomechanical behavior of the human aorta has been interest of study primarily due to its susceptibility to atherosclerotic occlusive disease [2] and aneurysms [3, 4]. These are due in part to the weakening of the walls of the aorta. The stresses and strains in these walls are factors in the creation and development of cardiovascular diseases. Thus, it is important to know how to predict the stress and strain states of aortic walls to discover the progression of certain vascular pathologies. Since stress cannot be experimentally measured, constitutive models are used to calculate tissue stresses. It is important, therefore, to identify the appropriate constitutive models that will accurately describe the biomechanical response of the biological tissue.
To understand this complex problem, one must examine the biomechanical behavior of the human aorta. In the past, studies were done to record the biomechanical response of human aortic tissue to uniaxial loading conditions. However, recent studies have shown that the behavior of human aortic tissue is nonlinear elastic, thus data from uniaxial tensile testing is unsuitable for this application. For a nonlinear elastic material, the slope of the stress-strain curve changes with deformation, hence the instantaneous stiffness of the material changes with deformation. Most biological soft tissues become stiffer with increased deformation. For these reasons, there is a need for a better description of the biomechanical response of human aortic tissue under biaxial stress. Biaxial mechanical testing allows for the investigation of the nature of mechanical anisotropy [5].
Constitutive models serve a vital role in studying the role biomechanical behavior because they are a quantitative measure of a tissue function. The linear elastic models do not do a good job of characterizing aortic tissue because a) soft tissues undergo large deformation and b) the relationship between stress and strain for soft tissues is nonlinear. This means that the stiffness of a soft tissue will change with deformation, unlike a linear elastic model where the stiffness is constant as long as the material is in the elastic range. For soft tissues, like aortic tissue, there may be one or more strain energy functions that work for a given tissue. After relating the tissue structure to this function, one may derive a structure-function relationship, from which one can quantitatively analyze how alterations in tissue structure due to aging or disease affect its function [6]. In this paper, aortic tissue data from Dinesh Mohan's Failure Properties of Passive Human Aortic Tissue II was optimized to fit to the Mooney-Rivlin constitutive model and the Neo-Hookian constitutive model to see if either model was a good fit.
In Mohan's paper, the aortic tissues were modeled as nonlinear elastic materials and were tested biaxially as flat specimens. Mohan's circular samples were tested using a biaxial test apparatus (see Fig. 1). In these tests, the specimen was inflated using the hand operated valve and the deformation was monitored using a movie camera. All tests were run till complete rupture of the tissue. The data used in this paper were the tissue samples tested quasi-statically.
A strain energy function is a model describing a hyperelastic material. According to Hollister, unlike linear elastic materials, "there is no 'one' material strain energy function for a nonlinear elastic material" [6]. For soft tissues, there may be one or more strain energy functions that work for a given tissue. Two classic forms of the strain energy function are known as the Mooney-Rivlin model and the neo-Hookian model. These models are commonly applied to analyze the deformation of materials such as rubber or plastics and assume both incompressibility and isotropy. Carew concludes that for most practical purposes arteries should be assumed to be incompressible, homogenous, and isotropic [1,7]. My reasons for choosing the Mooney-Rivlin and the neo-Hookian model are based on two papers that claim that the aortic wall displays rubber-like qualities that suggest that the aortic wall material is essentially elastomeric [8, 9]. The neo-Hookian model is the simplest model to describe such rubber-like behavior. The Mooney-Rivlin model is more accurate because the free energy function depends on two invariants. Based on various plots by Macosko, I hypothesized that the Mooney-Rivlin would be the better fit [10].
Now that we have defined constitutive models, the next step is to fit these models to experimental data to define the model constants. Since constitutive models relate stress and strain, we need to know the approximate stress and strain state. From this stress and strain state we then fit the constants from the constitutive model. When the material behavior is nonlinear fitting constants for the constitutive model requires multiple tests to mathematically fit the constitutive model to the data. To fit constitutive data, the square of the difference between the experimental measurement of stress and that calculated by the constitutive model is minimized using a numerical algorithm [6]. The algorithm modifies constants within the chosen constitutive model to minimize the error. The result gives the constants of the constituent model that best fit the data.
Full derivations of the Cauchy stress states for the Mooney-Rivlin model and neo-Hookian model can be found in Appendix A and B respectively. I began the derivation with the strain energy functions for the Mooney-Rivlin model (Eq. 1) and neo-Hookian model (Eq. 2).
Note that the neo-Hookian model is an abridged version of the Mooney-Rivlin. The second constant is truncated from the neo-Hookian. Both derivations followed the same steps. From here, I derived the 2nd Piola-Kirchoff (PK) stress tensor, Sij, from the strain energy function, W, in terms of the right Cauchy deformation tensor, Cij. The 2nd PK is then used in the equation for the Cauchy stress equivalents. ij. For the Cauchy stress, I had to find the deformation gradient tensor, Fij by solving using the three principal stretch ratios ( 1, ,2, ,3). Since the specimen is thin, only S11, ,22, and ,33 are needed. Due to incompressibility, d33 is set to zero, this makes it possible to solve for the hydrostatic pressure, p. I substituted the 2nd PK equations and hydrostatic pressure into the 11 and a22 equations. After simplifying, I applied the incompressibility assumptions (Eq. 3).
This gave me further simplified equations in terms of the stretch ratios and ∂W⁄∂r. This worked out well, since both the Mooney-Rivlin and neo-Hookian models may be defined in terms of principal stretch ratios. After substituting the derivative of the strain energy function in terms of the extension ratio, into the Cauchy stress equations we obtain Equations 4 and 5 for the Mooney-Rivlin model, and Equations 6 and 7 for the neo-Hookian. Notice the similarities between the two sets of equations.
The final step is optimization of the sets of equations using the formula below (Eq. 8):
For the neo-Hookian model, I did not use a constraint for the fitting of the experimental data. However, for the Mooney-Rivlin model, the Baker-Ericksen inequality was used (Eq. 9).
A detailed derivation of the inequality can be found in Appendix A. After derivation of the model equations, the next step was writing the MATLAB code. I chose 0 as seed value, for the both the Mooney–Rivlin, which has two material parameters, and the neo-Hookian model, which has only one. The code written for the Mooney-Rivlin fitting and the neo-Hookian fitting can be found in Appendices C and D, respectively.
Below, is the aortic tissue data from Mohan's Failure Properties of Passive Human Aortic Tissue II fit to the proposed constitutive models. Figure 2 describes the tissue data fit to the Mooney-Rivlin model and Figure 3 describes the tissue data fit to the neo-Hookian model. The experimental data are depicted by the stars and the predictions of the models are shown as lines.
As hypothesized earlier, the Mooney-Rivlin is clearly the better fit of the two. The neo–Hookian model is insufficient for describing the nonlinear mechanical behavior of aortic tissue. When the neo-Hookian model was used to predict stress relaxation at extension ratios between 1.1 and 1.25, the ability of the model to accurately predict the stress response of the tissue was limited. The Mooney-Rivlin model was closer to the experimental data, but still overestimated the stress for several data points.
The overall fit of each model's predictions is evaluated from the calculated coefficients between experimental and theoretical data. The constants are not unique meaning two very different sets of constants can generate an excellent fit for the plot. The constants c1 and c2 equal-14.0292 and 28.4883 respectively in the Mooney-Rivlin strain energy function equation. The constant c1 equals 29.6073 in the neo-Hookian strain energy equation.
In Appendix E, the polynomial residuals have been plotted and the norm of the residuals has been calculated.
This paper evaluated the fit of passive human aortic tissue, based on experimental response, to the Mooney-Rivlin and neo-Hookian constitutive models. The biomechanical response of the soft tissue was modeled as a homogenous, isotropic, and incompressible nonlinear elastic material using the two different strain energy functions associated with the constitutive models. It was discovered that neither model was an excellent fit, though the Mooney-Rivlin was a much better fit than the neo-Hookian model. The constitutive models were designed to accurately fit elastomers, so it is understandable that biological tissue, which is not as homogeneous as an elastomer, will not fit perfectly.
Accurately modeling the biomechanical response of soft tissue remains a challenge due to unique properties such as nonlinearities in the material, large deformations, anisotropy, and viscoelasticity [11]. Vande Geest suggests that difficult to model human aortic tissue past the age of 30 [5]. The age of the specimen in Mohan's study was 60 years of age. This was one of the limitations encountered. Other studies have suggested that aortic tissue cannot be modeled as isotropic. Patel found determined from the response of canine aorta that the tissue is anisotropic [12]. Neither model can be reliably used for the mechanics of passive human aortic tissue. One suggestion for further study are the exponential-based models to describe the behavior of aortic tissue [13]. In some cases, they have proven to be more effective in describing tissue behavior than constitutive models. Other studies have been conducted with soft tissue using the Ogden model, Martins model, or Humphrey model. I would suggest using the former two with aortic tissue because of the number of constants. For optimization, the number of constants to fit influences the fit directly. The Ogden model has six coefficients for fitting, and the Martins model has four.
It is important to identify the appropriate constitutive model that will accurately describe the biomechanical behavior of the aortic tissue. Such information is useful because identifying relevant changes in the biomechanical response of the aortic tissue can lead to an early prediction of an aneurysm.

HVAC Training Centers USA trains technicians to properly install refrigeration and heating systems, many of which utilize the vapor compression cycle (VCC). Your training program tests technicians on their abilities to tune the operating characteristics of the systems to deliver the best coefficient of performance (COP) for cooling and heating from a number of choices using the VCC training carts, and you have had some complaints that this test is unfair due to the uncertainties of your testbed systems. Thus, you have solicited our company's help in investigating this claim. Specifically, you have asked us to find the COP of cooling and heating for a VCC cart that you provided us with under three different compressor frequencies (30Hz, 45Hz, and 60Hz). In addition, you requested that we document the thermodynamic cycle on a temperature-entropy diagram with uncertainties at each state (using SI units). Lastly, you have asked that we report any other considerations that are important in determining the unit's ability to heat or cool efficiently and recommend whether they should be included in your testing of the technicians. We have completed these tasks. The purpose of this report is to provide you with our findings, conclusions, recommendations, and supporting documentation.
We have found the COP values of cooling and heating for the compressor frequencies of 30Hz, 45Hz, and 59Hz. The COP values decrease with increasing compressor frequency (Table 1); hence, less work is needed for lower frequencies to pump a specific amount of heat into or out of the space to be heated or cooled than would be needed for higher frequencies. We have also provided temperature-entropy diagrams to show the thermodynamic cycle at each frequency (Fig. 3-5, p.4). We have found that the uncertainties of the system are small enough that each frequency has a distinct cycle and a unique COP value. Thus, we conclude that your test is fair and the complaints about the test have been unfounded. We also have also determined that the cooling and heating capacities are key considerations in determining the unit's ability to heat or cool efficiently, and suggest that you test your technicians on their ability to tune the unit to give an appropriate value of the cooling or heating capacity. The values of the cooling and heating capacities were calculated for each frequency, and were found to increase with increasing frequency (Table 1).
Your company provided us with a VCC cart (Hamden Engineering Corporation Refrigeration Trainer, Model H-CRT-1), as well as a computer controlled data acquisition system (Labview 8.2) for recording the thermodynamic data. The VCC cart had two choices for the evaporator and several choices for the throttling valve; we utilized evaporator 1 and the capillary for these components, respectively. Schematics of the VCC cart are shown in Fig. 1 and Fig. 2. The working fluid of the apparatus was R-134a.
The data of interest for our analysis are shown in Fig. 2, where T refers to temperature, P refers to pressure, and Q refers to volume flow rate. The subscript refers to the point at which the value is measured. All the data was measured directly with Labview. However, Labview recorded gauge pressures, and therefore, we had to add the room pressure to each recorded value in order to get absolute pressure. The data of interest, for each point in the vapor-compression cycle, can be seen in Fig. 2; this data was used to find both enthalpy and entropy values at each of the points 1 through 4.
To find the COP of the VCC system, we set the compressor frequency to the desired value and waited for the system to reach steady-state. Steady-state was achieved when the computer acquisition system showed all of the measurements of interest to be constant values (straight, horizontal lines), and also, when the fluid coming out of the condenser at point 3 (Fig. 1) was completely liquid (no bubbles observed in the sight glass). We then used the Labview 8.2 software to record the data. The data was recorded ten different times for each frequency to allow us to compute the uncertainties in the data. This procedure was performed at 30 Hz, 45 Hz, and 59 Hz. 59 Hz was used instead of the requested frequency of 60 Hz, because this was as high as the compressor frequency would go for the system that you provided us with.
In our analysis of the thermodynamic properties of the VCC cart, we made several assumptions about the system. We assumed that there was no additional heat transfer apart from the heat flux in and out shown on Fig. 1 (perfectly insulation), that there were no additional pressure drops (no leaks), and that there were three reversible steps, taking place from points 1 to 2, 2 to 3, and 4 to 1 (Fig. 1). Also, oil had been added to the refrigerant to lubricate the compressor; however, we assumed that the added oil did not change the thermodynamic properties of the refrigerant.
All experimental data was taken at a room temperature of 294 ± 1°K and a room pressure of 99.13 ± 0.05 kPa. Room temperature and pressure were measured three times each with a thermometer (resolution of 1° K) and a barometer (resolution of 0.01 kPa), respectively.
In addition, as R-134a in liquid form can cause blindness, we were especially careful to wear appropriate protective eye gear.
In this section we will give the coefficient of performance (COP) of the VCC system and document the thermodynamic cycle on a temperature-entropy diagram for compressor frequencies of 30Hz, 45Hz, and 59Hz. We will also discuss the heating and cooling capacities of the system and their importance in determining the system's ability to heat or cool efficiently. We will also discuss the uncertainties associated with the data.
Both the COP of cooling and the COP of heating were found to decrease with increasing compressor frequency; thus, pumping a specific quantity of heat out of or into the reservoir requires less work at a higher frequency than a lower frequency. The values for each compressor frequency (30Hz, 45Hz, and 59Hz) can be found in Table 2.
Table 2: Coefficient of Performance of Both Cooling and Heating Decreases with Increasing Compressor Frequency
The COP of cooling was calculated using Eq. 1, where all of the variables refer to properties of the refrigerant, R-134a. is the volume flow rate, ρ is the density at point 3, h1 is the enthalpy at point 1, h4 is the enthalpy at point 4, and is the power input to the compressor (Fig. 1, p. 2). and are the cooling and heating capacities of the unit, respectively. h1 was found from the thermodynamic tables of R-134a [2], using the temperature and absolute pressure at point 1 (Fig. 1, p. 2). h4 is known to be equal to h3 because enthalpy remains constant though the throttling valve [1], and h3 was found from the thermodynamic tables of R-134a [2], using the temperature and absolute pressure at point 3 (Fig. 1, p. 2).
The COP of heating was calculated in the same way as the COP of cooling; however, we now make use of Eq. 2 instead of Eq. 1. h2 is the enthalpy at point 2, and h3 is the enthalpy at point 3 (Fig. 1,
p. 2).
For the frequency of 30Hz, however, the COP of heating had to be computed in a different way, due to a malfunction of the thermocouple that measured T2. The thermocouple recorded the temperature of point 2 (at 30Hz) to be too low (the temperature was clearly incorrect because the fluid must be a super-heated vapor at this point, but the recorded temperature tells us that it is a saturated liquid). Therefore, we instead assumed that the entropy, s, remained constant from point 1 to 2 (Fig. 1, p. 2), as it would in an ideal cycle. We then found h2 using the thermodynamic tables of R-134a given this constant entropy, s, and pressure, P [2]. This h2 value was then used in Eq. 2 to give the COP of heating value found in Table 3, p. 2.
The uncertainties in the COP values are due primarily to the precision errors in , ρ, h2, h3, and .
The temperature-entropy diagrams for the compressor frequencies of 30Hz, 45Hz, and 59Hz were plotted, and can be seen, respectively, in Fig. 3 through Fig. 5. Each diagram, labeled with the 4 points of Fig. 1 (p.2), shows the expected trend for a vapor-compression cycle, where point 1 is a saturated vapor, point 2 is a super-heated vapor, point 3 is a saturated liquid, and point 4 is a saturated mixture [1].
To plot the thermodynamic cycle, we had to find the entropy values for points 1-4 (Fig. 1, p. 2). This was done by using the R-143a thermodynamic tables to find si (entropy at point i), using Ti and Pi at points 1-3 and using T4 and h4 to find s4 [2]. This was done for the compressor frequencies of 30Hz, 45Hz, and 59Hz (Fig. 3-5). However, for the frequency of 30Hz (as mentioned in the previous section) we found that point 2 was not a super-heated vapor as it should be for a VCC, but rather a saturated liquid; we attribute this discrepancy to a malfunctioning thermocouple that recorded the temperature to be too low. Instead of using this point, which is clearly inaccurate, we assumed that the entropy, s, remained constant from point 1 to 2, as it would in an ideal cycle. We then found the temperature using the thermodynamic tables of R-134a given this constant entropy, s, and pressure, P [2]. This new point is shown in Fig. 3 as point 2'.
In the temperature-entropy diagrams (Fig. 3-5), the uncertainty in the temperature arises primarily from precision error, and the uncertainty in the entropy is due primarily to the precision errors in the temperature and pressure.
The cycles of the VCC cart (Fig. 3-5) differ slightly from the ideal vapor-compression cycle. In an ideal vapor-compression cycle, pressure should remain constant from point 2 to 3 and from point 4 to 1, and the entropy should remain constant from point 1 to 2. Because these values are not held constant between said points, we can conclude that the processes of compression (1 to 2), heat rejection (2 to 3), and heat addition (3 to 4) are not reversible. This is because of energy losses due to friction and unwanted heat transfer; for example, the pipes were not perfectly insulated and inevitably exchanged heat with the ambient.
When determining the unit's ability to heat and cool efficiently, it is also important to consider the cooling and heating capacities of the VCC system. We have calculated the cooling capacity, , and the heating capacity, , for the three compressor frequencies using Eq. 1 and Eq. 2 (p. 3) and we can see that both the cooling capacity and the heating capacity increase as the compressor frequency increases(Table 3). This means that a higher frequency will be able to pump more heat into a room in a certain amount of time than a lower frequency will be able to.
The cooling and heating capacities are important to consider for a VCC system, because even if the operating characteristics of the system yield a large COP, the unit still won't be efficient unless the cooling or heating capacity is appropriate for the type and amount of space to be heated or cooled. If the cooling/heating capacity is too small, the system will not cool/heat the room or space adequately; however, if it is too large, the system will turn on and off too often causing the efficiency of the unit to decrease and energy bill to increase. Therefore, we suggest that you test your technicians in their ability to match the cooling/heating capacity with the necessary factors, for example, the size of room to be cooled or heated, the number of windows, and the number of people typically inside room.
Through our analysis of the VCC cart that you provided us with, we have concluded that the test you give your technicians is fair, and the complaints that you have received were unfounded. With all uncertainties accounted for, each frequency gives a unique thermodynamic cycle with a distinct COP. Our analysis shows that both the COP of cooling and the COP of heating decrease with increasing compressor frequency (see Table 1, p. 1), which means that less work is needed for lower frequencies to pump a specific amount of heat into or out of the space to be heated or cooled than would be needed for higher frequencies.
In addition, we have concluded that the heating and cooling capacities are key components in determining the unit's ability to heat or cool efficiently, because if the cooling/heating capacity is too small, the system will not cool/heat the room or space adequately, but if it is too large, the system will cycle on and off too often causing the efficiency of the unit to decrease and energy bill to increase. We have provided you with the values of the heating and cooling capacities for the three compressor frequencies of 30Hz, 45Hz, and 59Hz in Table 1 (p.1), and have found that both the heating and cooling capacity increase with increasing frequency. This means that a higher frequency will be able to put more heat into or take more heat out of a space than a lower frequency will in the same amount of time.
We recommend that you test your technicians not only their ability to tune the cart to give a good value of COP, but also on their ability to choose a good value of the cooling or heating capacity, based on what type of space is to be heated or cooled. This will give your technicians the knowledge to help their clients save on energy costs.

Piezoelectricity is a special property possessed by some materials that allows either an electrical signal to produce a material strain, or a material strain to produce an electrical signal; the two are reciprocal properties. The former property has been used to facilitate actuation of many devices. High frequency applications, such as ultra-sound medical devices, have seen a particularly important benefit from these materials due to their extraordinary signal response time. The latter property can be found in applications such as accelerometers, thermal sensors and dynamical signal sensors. However, this ability to convert a mechanical strain into an electrical signal can also be used to derive energy from vibrating systems for a potentially unlimited renewable power source. Because of this energy harvesting capability, several researchers have investigated aspects of this process. This includes determining the available energy from a system, mechanical modeling of the piezoelectric element, developing energy conversion circuits, and energy storage methods.
Traditional mechanically vibrated systems have been analyzed to determine how much energy can be harvested from them (Vujic 2002). However, significant interest has also been shown in determining the amount of energy that humans exert during daily life that could be parasitically harvested for use in wearable electronics. Starner (Starner 1996) has calculated that nearly 67 W of power is wasted through the process of walking. He also conjectures that .33 W of energy could be harvested by integrating piezoelectrics within the joints of clothing; here, the process of bending would cause strain, and thus, energy generation. Several investigators have conducted studies regarding the use of piezoelectrics within shoes to scavenge power. Shenk (Shenk 1999) has worked on developing a working prototype of a military boot equipped with a power harvesting bimorph composed of piezoelectric elements known as THUNDER; this boot was capable of producing approximately 80 mW at its peak and averaged 2 mW. Paradiso's (Paradiso 2001) work is closely tied to Shenk's and, using a PVDF piezoelectric element within a shoe, has shown the ability to generate a peak power of 20 mW with an average of 1 mW. This work has proven the ability of power harvesting systems to generate low amounts of power for electrical systems.
The use of piezoelectrics as sensors and actuators has provided the groundwork for the development of energy harvesting systems that utilize them. IEEE standards (1987) exist that provide details on the constitutive equations that relate the mechanical strain and stress to electrical displacement and field. Two important relations that incorporate these four properties are:
where S is strain, s is modulus of elasticity, g is a piezoelectric constant, and D is electrical displacement, E is electric field, T is stress, and g and β are piezoelectric constants. From this, (Michael J. Ramsay 2001) derived power equations for a piezoelectric element excited in its 33-direction, which means that the application of load coincides with the direction of poling, and in the 31-direciton, which means that the application of load is in a direction (the 1-direction) that is perpendicular to the direction of poling. These 33 and 31 power equations are shown in equations 3 and 4, respectively:
where, P is power, d is a piezoelectric constant, t is material thickness, b is material width, l is material length and f is the frequency of excitation. Mechanical models that describe energy harvesting systems can readily be developed based on these equations.
Energy conversion and storage within a medium is another important aspect of energy harvesting that has received detailed investigation from several researchers. Most power harvesting circuits use a rectifier that ensures that all electricity entering the circuitry is positive, thereby protecting the downstream components. Beyond this, detailed work has been completed that involves conditioning this power and utilizing it to transmit signals via RF transmitters after a threshold voltage has been generated (Paradiso 2001). Ottman and Lesieutre (Geffrey K. Ottman 2003) have developed a power harvesting circuit that is continuously optimized, through the use of an adaptive controller and a DC/DC converter, to provide the greatest amount of power possible to the storage medium. They claim that their harvesting circuit improves direct charging of a storage medium by nearly 400%. Researchers use either capacitors or chemical batteries as an energy storage medium. While capacitors can be effective in powering systems that only require intermittent power--- for instance, to transmit an information signal--- they lack the ability to store large amounts of power, and they have fast discharge rates, thus limiting their utility (H.A. Sodano 2004). Therefore, to power a greater variety of electronic devices, power storage in batteries is required and is being investigated by research groups (Henry A. Sodano 2004).
The basic science behind power harvesting has been developed and there are several applications where a renewable power source is required, or would drastically improve current technologies. For example, health monitoring systems for building structures could utilize power harvesting to transmit signals from embedded sensors to a central processor. Or, RF tags used to track the migration habits of endangered animals could be powered through energy harvesting means, thus eliminating the need to capture the animals for battery replacement, as is currently done (Sodano 2004). Beyond this, everyday systems also show the possibility of benefiting from power harvesting. Tires, on automobiles and bicycles, deform significantly during their rotation and operate at frequencies that make them prime candidates for energy harvesting in order to provide energy to low power systems. For example, safety lights for bicycles are already available, but they require batteries, and can be expensive, and bulky. By comparison, an integrated power harvesting system used to power safety lights could be integrated into the tire, thus reducing the bulkiness and weight associated with traditional batteries.
This paper describes a case study in which the ability to install a power harvesting system on a bicycle tire is proven. Theoretical calculations used to determine the output power of the bicycle are described along with a comparison to actual results. The electrical circuitry of this power harvesting system is described along with improvements to enhance its ability to convert and utilize the deformation energy of the tire.
In this section, a static model of the piezoelectric-element, its bonding layer, and the material of the tire will be established, and a method of predicting the output voltage of the piezoelectric-element will be discussed and modeled. The results of this model will later be used in a comparison with experimental results.
In order to calculate the voltage produced by the PVDF, the amount of strain encountered during a single wheel revolution, or the tire loading, must be known. This paper investigates the former scenario. It is assumed that the bicycle tire is completely flattened when in contact with the ground, and that it reverts to the natural curvature of the bicycle wheel when not in contact. It is also assumed that the neutral axis is at the centroid of the bending section, because the thickness of the tire, piezoelectric-element, and bonding layer is sufficiently small in comparison to the wheel curvature. It has been noted that if the radius of curvature is more than eight times the depth of the bending element, then the error encountered in making this assumption is less than 5% (Young 1989). In this case, the radius of the bicycle wheel is 570 times the thickness of the bending element, and standard beam theory can therefore be used to calculate the strain while maintaining model validity.
From (Brei 2004) the strain encountered from a piezoelectric sensor can be found from the following:
where is the distance from the piezoelectric-element to the neutral axis.
The second term on the right hand side of Equation 5 is simply the curvature of the bent shape of the piezoelectric-element, which in this case is the curvature of the bicycle wheel. Assuming that the wheel is a circle, in Cartesian coordinates, the vertical distance along the perimeter is related to the horizontal difference and radius by Equation 6:
where is the wheel radius.
In order to properly calculate the distance from the piezoelectric-element to the neutral axis, it is necessary to appreciate that there are essentially four layers bonded to one another: the tire substrate, the Kevlar reinforcing in the tire, the bonding layer, and the piezoelectric-element. Figure 1 shows these four layers, the neutral axis (or centroid), and the respective distances from the top edge of each element to the neutral axis (C1, C2, C3, and C4).
The distance from the top edge of all four layers to the neutral axis, C4, is also equal to . To find this distance, it is first noted that for each layer the distance from the individual central axis to the laminates neutral axis is as follows:
where
where ,E1, E2, E 3, and E4 are the Young's moduli for each layer, C4 can be solved, since everything on the right hand side of Equation 11 is known.
With the ability to calculate strain, the output voltage of the piezoelectric-element can now be calculated. From (Brei 2004) it has been shown that, assuming that there is no applied electric field, voltage is related to strain through Equation 13:
where C is capacitance, V is voltage, A is area, and e is a piezoelectric constant. The following relationships between the given constants are known:
where k2 is the electrical coupling factor, c is elastic stiffness and g is a piezoelectric constant.
Combining Equations 14 and 15 with Equation 13 the output voltage can be written in integral form:
The capacitive value,, from Equation 16 is:
where is a known constant for the permittivity of the PVDF, and , , and are the length, width, and thickness of the PVDF, respectively.
Integrating Equation 16 over a constant width while maintaining as constant, the voltage formulation becomes the same as for a cantilever beam:
In this case, the flattening of the bicycle tire can be viewed as two cantilever beams anchored at their abutting edges (Figure 2). This is true because of the inherent symmetry of the bending element.
Therefore, Equation 18 is evaluated over two sections of half the length of the flattened section of the tire. Equation 6 can now be differentiated and inserted into Equation 18. The resulting equation is the total voltage produced by the flattening of a section of the bicycle tire:
Table 1 shows the constants assumed in calculating the voltage produced by the PVDF.
In order to determine the voltage from Equation 19, it is necessary to find the length of the footprint (or the flat area in contact with the ground). Assuming that the weight of the bicycle rider is evenly distributed between the front and back wheels, the length of the footprint is as follows, assuming that the width (tread width) is known:
where F is the half the weight of the rider, P is the tire pressure, l is the length of the footprint, and b is the width. Assuming that the width and length of the PVDF are from Table 1, that the tire is inflated to 100 psi, and that the rider weight is 100 lbs, then the amount of voltage recovered by the energy harvesting unit is equal to 10.1 V.
With a working model developed, and a prediction for the output voltage in hand, the process of validating the model can now be discussed. Since the PVDF was prepared, mounted, and installed in the tire prior to model development, all of the values and conditions assumed in the model discussed in Section 2 were obtained either by direct measurement, outside sources, or by reasonable approximation. For example, all of the dimensions of the tire, Kevlar reinforcement, and PVDF were directly measured with digital calipers. The thickness of the bonding layer could not be measured, but it was assumed that it was approximately the same thickness as the PVDF since a very small amount of epoxy was applied over a relatively large area and great care was taken in making the layer as thin as possible. The material properties of each layer were found from outside sources (Graham 1992; Brei 2004).
A small piece of PVDF was prepared for this experiment by etching the electrode with acetone and then cutting the desired shape. This was done to eliminate the possibility of electrical arching. An IRC High Pressure Bicycle Tire was obtained for the experiment, and the bicycle wheel and inner-tube were removed. A small area was prepared on the inside Kevlar reinforcement of the tire, and the PVDF was then bonded to the Kevlar with 3M Scotch-Weld DP110 epoxy adhesive. It was determined from the 3M Company that this particular adhesive would work well in bonding the PVDF to the tires Kevlar inner lining.
Along with the PVDF bonded to the inner Kevlar lining, some foam spacers were inserted to protect the outside surface of the PVDF from marring by the inner-tube. This was done from experience as an initial trial was rendered inoperable after it was damaged by the inner-tube in direct contact with the PVDF. The bicycle inner-tube was then inserted into the tire, and the tire was remounted on the rim of the bicycle wheel. Finally, the tire was inflated to 100 psi, and left to set overnight.
In order to test the model developed in Section 2, the two leads from the piezoelectric-element within the bicycle wheel were attached to an oscilloscope as shown in Figure 3.
With the oscilloscope set to trigger-mode, the bicycle tire was loaded by applying a force by hand and shocking the area where the PVDF was located along the perimeter of the wheel. It was noted, that while peaks as high as 20 volts were noted when the wheel was heavily shocked, most of the peaks occurred in the range of 10 to volts. Figure 4 shows a typical peak resulting from our test method.
The testing of the bicycle wheel assembly showed that our model results of 10.1 Volts were not only on the same order of magnitude as predicted, but also fairly close to the theoretical voltage prediction. It is estimated that the tire was exposed to a shock force of roughly 50 pounds, but the necessary equipment to accurately produce this force on a repetitive basis was simply to expensive and difficult to obtain. However, from an order of magnitude standpoint, this model correlated with experimental data, and if this project were to be further pursued, the model could be used to optimize the amount of voltage produced by the PVDF patch.
The energy of a single impact cycle, including impact and recovery, was calculated by observing the voltage signal across a known resistor of 100K on an oscilloscope. .It was found that a single impact yielded two approximately equivalent but opposite peaks, one from initial impact, and one from recovery. This voltage would become entirely positive if it were passed through a rectifier circuit. These impacts were approximated as triangular waves. Energy was then calculated from the waveform by integrating the instantaneous power over time:
where represents triangular relationship between voltage and time (which is an approximation of the actual signal):
and resistance R=100 K
Analytically, the total energy from impact and recovery resolves to:
in this case the maximum voltage . and t = 8.5 ms, is the time duration of a single peak.
The total impact energy can then be calculated to be 9.9nJ. Then, assuming that 6 patches could be placed on a 187 diameter tire, a rider could produce 740 aJ over a 3 hr ride. Average power can be calculated by dividing the energy of an impact/recovery cycle by the total period of the cycle, here 35ms based on measured data. This yields an average power of 0.283 .W. The average current produced by deformation of the PVDF can be calculated from the average power and the sense resistance:
whereis the average power.
The average current for an impact cycle through a 100K resistor is then calculated to be 1.7 A. It should be noted that this average current is specific to the 100KI resistor, and it would change depending on different resistance values used. However, the power output will not change with difference resistor values.
Knowing that the PVDF patch is capable of delivering voltages on the order of 10 volts, the possibilities of harvesting and storing this electrical energy could next be considered. In this section, the work done to design a functioning product will be presented. First, a short discussion of the importance of properly sizing the PVDF will be given. Next, a voltage rectifier circuit will be presented followed by a discussion of the circuit's ability to charge a capacitor. Efforts to develop a circuit that could automatically discharge this capacitor will then be discussed. Lastly, several potential applications for the energy harvesting PVDF and circuit will be given.
During initial experimentation, it was found that a large strip of PVDF, deformed in a small area, would suffer from a significant capacitive effect -- the inactive PVDF stores charge generated by the active region, and therefore reduces the voltage present between the two electrodes. In response to these findings, both the modeling and experimental studies (section 2 and 3 of this report) were modified in order to reduce the size of the PVDF strip to dimensions more comparable to that of the tire's contact surface. As a result, voltages of around 10V were capable of being generated. In order to properly design an energy harvesting element, it is consequently crucial to size the PVDF to suit both the harvesting circuit, and the bicycle tire in which the piezoelectric-element is situated.
Since the output of the PVDF is an alternating signal, it was necessary to produce a voltage rectifier circuit that would make use of both the positive and negative pulses. Four diodes, as seen in Figure 5, comprise the rectifier and a capacitor is placed across the output leads.
By bouncing the bicycle tire on a hard floor, it was possible to charge a capacitor to a sufficient voltage to power an LED.
With a rectifying circuit built and successfully tested, various circuits, capable of automatically draining the capacitor through an LED once a given voltage was reached during the charging of the capacitor, were next investigated. This proved to be a more difficult task than anticipated, since the circuits sought had to be self-sufficient. For example, a promising circuit made use of a thyristor, which behaves like a transistor but remains "on" until there is zero current running through it after it is initially switched "on". In order for the thyristor to activate, its base lead was connected to the capacitor, since a thyristor will turn on when the base reaches a threshold voltage. Unfortunately, the base also draws a very small amount of current -- enough in this application to keep the capacitor from charging to the desired level.
Efforts in designing an autonomous circuit have been purely investigative, but a more thorough study, possibly involving an electronics expert, should be able to produce a working device. However, in this case such a study is beyond the scope of the project. Additionally, if a design did not require self-sufficiency, there are many externally powered electrical components such as comparators, which would be able to produce the needed switching function.
While this project and report are intended to primarily serve as a proof of concept, there still are several potential applications, should this work be used to create an actual working product. From this investigation, a capacitor was able to be charged by the repeated shocking of a bicycle tire. Once the capacitor was charged above 3 volts, an LED was placed across the capacitor leads and a flash of light was observed. Clearly this shows that an LED could be periodically flashed if a controlling circuit were built, and products relating to safety lighting could easily be developed and marketed.
It was thought that the output of the PVDF could be used to charge a small battery after passing through the rectifier circuit, but as seen in the energy calculations in section 3.4, the output is quite small. It is still possible, however to charge a very small battery, or to increase the overall energy output by adding more PVDF elements in the bicycle tire. There also low-powered electrical accessories that are powered by small batteries, such as cyclometers used to measure speed and trip distance. Most of these electrical systems are on only when the bicycle is in use, and if an electrical circuit were designed to trickle charge the small batteries powering the systems, the batteries would only need to be replaced every few years (assuming a NIMH battery with the capacity for 1,000 charges (Energizer)).
This paper has shown that it is indeed possible to harvest electrical energy with a PVDF in the specific application of a bicycle tire. The underlying physics of the application were discussed, and a model was developed to predict the output signal of the PVDF embedded in the bicycle tire (accounting for four different layers bonded together). A discussion of experimental results was then provided, and it was concluded that the model verifiably predicts output voltage to a reasonable degree of accuracy. It was then shown that it is possible to transfer electrical energy to a storage medium for later use. While measurements of this energy show that the output of the PVDF is too low to charge conventional batteries, there are small capacity batteries that can still be charged with this power input. For higher power applications, it is recommended that a different piezoelectric is used, since the findings of this report show that a PVDF would be inadequate. If certain applications require that a PVDF be used (i.e. large strains that might fracture a brittle piezoceramic) it is suggested that a laminated PVDF be tested in a similar manner as this report. Once the laminate is fully characterized, decisions regarding its role in an application can be made.

The operation of internal combustion engines at their current speed range is made possible by turbulence. If complete combustion of the fuel-air mixture depended solely on the laminar flame velocity of the fuel, a typical four-stroke engine running on iso-octane (a hydrocarbon that approximates gasoline) would have a maximum speed of approximately 400 rpm [1]. However, turbulence wrinkles the flame front and causes entrainment of the fuel-air mixture by the flame front, leading to flame fronts with larger surface areas. This leads to higher burning rates and the high power densities of internal combustion engines. Turbulence occurs as the fluid jet coming through the intake valve separates from the valve seat, producing shear layers with large velocity gradients [1]. It increases as the engine speed increases, allowing internal combustion engines to operate over a large range of loads and speeds.
Proper combustion in internal combustion engines may be ensured by controlling turbulence in the flow within engines. If turbulence causes the surface area of flame fronts to become too large, excessive heat conduction out of the reaction zone causes premature flame extinction. Also, if the flame kernel from the early stages of combustion dwells near the spark plug for too long, it may be extinguished too quickly due to excessive heat loss, resulting in incomplete combustion. However, if the flame kernel moves away from the region near the spark plug too quickly towards regions of high ignition energy or low temperature, such as the cylinder walls, it may be extinguished too. Thus, a mean fluid velocity between 3 m/s and 5 m/s is optimal [1]. In direct injection engines, turbulence also controls the degree of mixing of the fuel spray with the air in the cylinder, thus controlling the equivalence ratio stratification and flame development.
As turbulence is very sensitive to initial conditions, there can be great cycle-to-cycle variability in turbulence in engines, leading to incomplete combustion or even misfires, and variations in the engine power. Accounting for cycle-to-cycle variability leads to design compromises that reduce engine power at full load and fuel efficiency at part load [1]. Understanding turbulence allows for the minimization of the effects of cycle-to-cycle variation in turbulence. This can lead to higher engine power, better fuel economy, and reduced emissions.
Turbulence may be studied by examining the fluid velocity fields in internal combustion engines. Particle image velocimetry (PIV) is a technique that uses a laser light sheet to illuminate tracer particles in the fluid in a transparent quartz cylinder and captures the movement of these particles using high-speed cameras. These images are then used to construct instantaneous fluid velocity fields. The experiment discussed in this report used a high-speed PIV technique that employed 355 nm lasers and silicone oil tracer particles to capture instantaneous velocity data in a motored four-stroke, single-cylinder, four-valve gasoline stratified spark ignition direct injection engine during consecutive engine cycles at every other crank angle from 69 °BTDC to 25 °BTDC. The engine was run at a speed of 2000 rpm with an intake pressure of 95 kPa and an intake temperature of 45 °C. Previous high-speed PIV techniques used lasers in the green range of the spectrum (510 nm, 527 nm, or 528 nm). However, lasers emitting green light cannot be used to capture reliable velocity fields in a fired engine as soot luminosity would interfere with the laser light scattered by the tracer particles. Using 355 nm lasers effectively circumvents this problem [1].
Instantaneous velocity vector fields were obtained from the raw images of tracer particles using LaVision Davis 7.1, a commercial software package [1]. These velocity vector fields from consecutive cycles were organized according to crank angle. Gaussian filters of wavelengths varying from wavelengths close to the resolution of the velocity vector fields (1 mm) up to wavelengths close to the size of the vector fields were applied to them (33.1 mm). The resultant velocity vector fields illustrate the flow structure at different length scales in internal combustion engines. They were subtracted from each other to obtain band passes that had the same size in wave number space. For example, the velocity vectors resulting from the application of Gaussian filters of 1 mm wavelength (1 mm-1 wave number) and 16 mm wavelength (0.0625 mm-1 wave number) were subtracted from the velocity vectors resulting from the application of Gaussian filters of 1.00100 mm wavelength (0.999001 mm-1 wave number) and 16.3 mm wavelength (0.0613 mm-1 wave number), respectively, to obtain band passes, both with a size of 0.001 mm-1, illustrating the flow structure at wavelengths 1.0005 mm and 16.15 mm, respectively. The following figure is a velocity vector field illustrating the flow structure at a wavelength of 8.03226 mm at a crank angle of 37 °BTDC:
Note that the larger area at the top of the image with an absence of velocity vectors denotes space occupied by the spark plug.
Next, mass-specific kinetic energy was calculated for each set of band pass velocity vector fields and for the unfiltered velocity vector fields at every other crank angle using the following equation:
where,
The vector fields were divided into several smaller areas and the ensemble mean velocity and the rms of the velocity fluctuations about the ensemble mean were calculated for each of the smaller areas. Then, an ensemble average kinetic energy false-color image was constructed using the ensemble mean velocity and an ensemble turbulent kinetic energy false-color image was constructed using the rms of the velocity fluctuations about the mean. Examples of such images are shown in the figures below:
Figures 2 and 3 show a small rectangular area selected at the top right-hand corner of the ensemble average and ensemble turbulent kinetic energy false-color images. The spatial averages of the ensemble average and ensemble turbulent kinetic energies in this rectangular area are referred to as the average kinetic energy and the turbulent kinetic energy, respectively. If the spatial averaging was done over the entire ensemble average and ensemble turbulent kinetic energy false-color images, the larger amount of instantaneous velocity data available at crank angles further away from TDC would have had an effect upon the average and turbulent kinetic energies calculated. The average and turbulent kinetic energy values were plotted against crank angle and wave number to examine the variations in average and turbulent kinetic energies with time and length scale.
The following figures show the average kinetic energy and turbulent kinetic energy values plotted against crank angle and wave number.
Figure 4 shows that the average kinetic energy is highest for flow structures at higher length scales. This illustrates that as energy cascades from larger length scales to smaller length scales, some of it is dissipated [1]. However, the dip in the plots between approximately 55 °BTDC and 40 °BTDC is hard to explain, as the average kinetic energy of the fluid in an internal combustion engine depends directly on the piston speed which decreases in a sinusoidal fashion from about 90 °BTDC (depending on the piston eccentricity) to TDC.
Figure 6 again illustrates the energy cascade from larger to smaller length scales. It also shows the dip in average kinetic energy more clearly, with 27 °BTDC having the highest average kinetic energy and 47 °BTDC having the lowest average kinetic energy among the crank angles plotted.
Figures 5 and 7 lead to a most interesting conclusion: turbulent kinetic energy does not vary depending on crank angle. It is expected that turbulent kinetic energy would increase as the piston approaches TDC, compressing the fluid within the cylinder, and reach a peak, possibly, before decreasing as the dissipation rate increases. However, the turbulent kinetic energy was calculated using only the data available in a small rectangular portion of the velocity vector fields examined. This rectangular region may have been less representative of the larger velocity vector fields at crank angles further away from TDC. Also, the rectangular region under consideration was next to the spark plug, where a strong tumble flow generated by the initial intake valve events dominated the flow structure. Thus, the large initial turbulent kinetic energy associated with the tumble motion might overshadow any smaller changes in the turbulent kinetic energy that occur due to piston movement.
The analysis of the data from the experiment under discussion indicates that the average kinetic energy reaches a minimum between approximately 55 °BTDC and 40 °BTDC, and the turbulent kinetic energy does not vary with crank angle. Reanalysis of the experimental data by finding the spatial mean velocity and the rms of the velocity fluctuations about this spatial mean and using these values to calculate the ensemble average kinetic energy and the ensemble average of the turbulent kinetic energy may confirm these conclusions. Examining the average and kinetic energies associated with a different, possibly larger, rectangular portion of the velocity vector fields and comparing them to the values presented in this report might also provide more insight. Further experiments may be required to confirm and understand these results. Calculating dissipation rates from the experimental data under discussion may also provide valuable information.
In order to develop a more complete understanding of turbulence in internal combustion engines, the high-speed PIV technique should be combined with high-speed planar laser induced florescence (PLIF) of biacetyl to simultaneously image the flow structure and the equivalence ratio distribution in a spark ignition direct injection engine in order to investigate events occurring near ignition, such as the interaction of the plasma channel produced by the spark with the surrounding fluid flow. Data obtained from such experiments may also be used to obtain kinetic energy and dissipation rate spectra that enhance the current understanding of turbulence in engines and help validate CFD models used to design and develop internal combustion engines [1].

Grills and Grilles (GG) has recently had a number of grilles which cover fluorescent lights mysteriously fail. GG suspects the aluminum alloy used in the grilles is causing this failure, and has requested that our engineering team determine key material properties including the density, modulus, yield strength, ultimate tensile strength, elongation at fracture, and fracture toughness of samples provided to us by GG. We have successfully determined these material properties and compared them to a reference to determine if the alloy truly is 7075-T651 aluminum. The purpose of this report is to present our findings, conclusions, and supporting documentation.
Our team successfully determined the density, modulus, yield strength, ultimate tensile strength, and elongation at fracture of the samples GG gave us; by comparing them to reference values from Dowling [1], we have concluded the samples we received are not 7075-T651 aluminum. We attempted to calculate the fracture toughness of the samples, but none of the four tests performed satisfied conditions set forth by the ASTM E 399 [2] standard for fracture toughness testing. Calculated and reference values with their associated uncertainty for each material property are located in Table 1, below. A graphical representation of the stress versus strain behavior is available in Figure 1 on page 3, with modulus, yield strength, and ultimate tensile strength depicted. Even though we were unable to obtain the fracture toughness of the material, the stress intensity factors (KQ) we did calculate are shown in Table 1, below. Since these stress intensities are not representative of the fracture toughness of the material, they should not be used in engineering calculations.
To provide the requested material properties and determine if this 7075-T651 aluminum, we used the six test specimens provided by GG: a solid bar, a tensile specimen, and 4 pre-cracked specimens. Relevant dimensions of these specimens were measured with calipers; before taking any measurements, we ensured that the calipers (± 0.0005 in) were properly calibrated to zero when in the closed position. We then measured dimensions of interest: the length, width, and height of the solid bar, the diameter and length of the tensile specimen, and the thickness of each fracture specimen. The solid bar was also weighed on a digital scale, and its mass was recorded. The measurements of each length and the mass were repeated four times. We then performed a tensile test and four fracture tests. Data was collected during both of these using LabView 7.1 and plotted using Microsoft Excel 2003.
Tensile Test: The supplied tensile specimen was placed in the grips of the 4206 Instron tensile testing setup. A 45-90 strain gauge rosette was fixed to the specimen; the middle strain gauge was directly along the longitudinal axis of the specimen, and the other two were positioned 45º on either side of it. We then began loading the specimen with the Instron's crosshead set to move at 2.54 mm/min and continued to increase the load until the tensile specimen eventually failed after brief necking.
Fracture Test: There were four different thicknesses of fracture sample (B) provided: 0.1" (0.254 cm), 0.25" (0.635 cm), 0.3" (0.762 cm), and 0.4" (1.016 cm). Each specimen was provided with a single notch in the center, also known as a single edge notched beam (SENB), and a fatigue crack already initiated. We set up the fracture test according to the 399 standard [2] for plane-strain fracture toughness (K1c) testing; Figure 1, below, shows the standard's specification for fracture specimen setup. A displacement gauge was attached to the specimen to measure the width of the crack. An 8516 Instron machine was used to load the specimen. We increased the load on each fracture sample until the crack propagated through most of the part. Once the crack was 2-3 mm from the edge of the SENB, it was removed from the Instron and fracture was completed by applying force by hand.
The stress-strain behavior of the tensile specimen is summarized in Figure 2, on page 3. Towards the end of the tensile test, one of the three strain gauges in the rosette broke off of the specimen. Strain values past this point are unreliable, but force data is still valid.
The density of the test specimen was determined to be 2.8 ± 0.4 g/cm3; Dowling [1] reported 2.7 g/cm3, which does not agree with our value. The density of this material was determined by dividing mass of the provided solid bar by its volume.
The yield strength for the provided specimen was determined to be 546 ± 6 MPa; Dowling [1] reported 469 MPa, which does not agree with our value. Yield strength represents the stress value at which a material begins to plastically deform, typically measured as 0.2% permanent strain.
The ultimate tensile strength (UTS) of the given specimen was determined to be 590 ± 5 MPa; Dowling [1] reported 578 MPa, which does not agree with our value. UTS represents the maximum amount of stress that a material can withstand before failure occurs.
The elongation at fracture was determined to be 17 ± 1%; Dowling [1] reported 11%, which does not agree with our value. This was determined by dividing the displacement of the crosshead at fracture by the original length of the specimen, with crosshead displacement being 0.01440 ± 0.00003 m and original length being 0.084 ± 0.001 m.
We determined the elastic modulus of the test specimen to be 68 ± 2 GPa; Dowling [1] reported 71 GPa, which does not agree with our value. In the early stages of the tensile test, the linear elastic region was examined. We used Eq.1, below, to calculate nominal stress (σn) in terms of load (P) and original cross-sectional area (A0). The specimen had an original cross sectional area of 0.000129 ± 0.000001 m2. We found our calculated nominal stresses to be within ± 3% of their actual value. True stress was calculated from these nominal stresses. The true strain in the direction of tension was calculated using strain values reported by the strain gauge rosette. True stress was plotted as a function of true strain for the tensile test and the linear portion of it was analyzed. The elastic modulus was determined with the average slope of best-fit lines incorporating the uncertainty in our measurements.
While we were able to find KQ (stress intensity factor associated with critical load PQ) values for each individual fracture specimen, we could not find K1c (plane-strain fracture toughness) using the conditions imposed by the 399 standard [2] for K1c calculations. The values of KQ we found are 24 ± 8 MPa√m, 30 ± 2 MPa√m, 36 ± 3 MPa√m, and 36 ± 3 MPa√m for specimen thicknesses 0.1" (0.254 cm), 0.25" (0.635 cm), 0.3" (0.762 cm), and 0.4" (1.016 cm), respectively.
The 399 standard [2] is very specific about how a test for K1c should be performed. The fracture specimen needs to be set up and loaded as shown in Figure 1 on page 2. Load (P) versus crack displacement (a) data need to be analyzed to determine if a specimen fails in Type 1, Type 2, or Type 3 fracture. The critical parameter is the load to be used in KQ calculations (PQ), and it is determined differently for each type of fracture; details on how to determine the type of failure are available in the 399 standard [2]. Figure 4 on page 4 shows a sample PQ calculation for a 0.25" (0.635 cm) thick specimen.
The final parameter needed to calculate KQ is a geometric correction factor f(a/w); this parameter adjusts the KQ formula for a variety of different geometries. The formula associated with the geometry of our test specimens is shown as Eq.3, below.
After PQ is determined, KQ can be calculated using Eq.4, above. KQ increases with specimen width, as shown in Figure 3, above; if KQ is K1C, the expected trend is an increase in KQ with specimen width followed by a decrease with specimen width, and then a plateau whose value represents K1C. Calculated values of KQ need to satisfy the conditions listed in Eq.5, above, in order to be the plane-strain fracture toughness. These conditions are designed to check if the part yielded excessively before fracture. If excessive yielding occurs, KQ is not the same as K1c, and cannot be used in future fracture calculations. Our team determined none of our calculated KQ values to be K1c, and our calculated KQ values should not be used in fracture calculations.
Our team found values for density, elastic modulus, yield strength, ultimate tensile strength, and elongation at fracture of the samples GG provided, and since none of them agreed with reference values from Dowling [1] I concluded the specimens provided were not 7075-T651 aluminum. Our calculated material properties are displayed on Figure 2 on page 3. The elastic modulus was determined to be 68 ± 2 GPa, characterized by the slope of the linear-elastic region of the stress-strain curve. The yield strength is 546 ± 6 MPa and is shown where the curve diverges from the linear path, which indicates permanent deformation. The ultimate tensile strength of the specimen is 590 ± 5 MPa, and is the maximum stress attained in the experiment before the onset of necking. The elongation at fracture is 17 ± 1%. We were able to calculate KQ values for the four fracture specimens provided by GG, but they were determined to not be K1C. The standard specifies that the linear elastic fracture mechanics requirements (Eq.5 on page 4) be satisfied for KQ to be K1C, but they were not. I recommend that GG further investigate the material actually used to make the grilles for the fluorescent lights, and either remanufacture the grilles using 7075-T651 aluminum or analyze whether the material being different gives rise to a redesign of the grilles.

Our design group was asked to develop a conceptual structural model for either a mid-size or small vehicle. We have completed this task using a mid-size monocoque vehicle. The following report presents our target customer description, the structural interpretation of the customer's expectations, an in-depth analysis of some important structural requirements, and our recommendations for modification of our structure in subsequent design steps.
A retired elderly couple was the target customer of our mid-size vehicle. They have a secure income and are looking for a comfortable vehicle to travel between their primary home and winter home in Florida. Their target price range is approximately $30,000. Using this customer description, we decided that a mid-size luxury vehicle was the target concept. We generated some general vehicle qualities that may be important to our customer. Table 1 below shows our breakdown of these qualities, their importance with respect to our customer, and the structural portions of the vehicles that may affect the qualities.
We completed our rough design concepts based on packaging, first order analysis, and customer requirements. First, we introduce the general strategy behind our structure and how we achieved the desired characteristics. Then, we will provide general overlays of our structure onto the vehicle plan views and the sizing of major elements.
Our design sketch is shown in Figure 1 below. Please consider vehicle symmetry while viewing the sketch. We also summarized the structural strategy behind our design concept as shown in the figure as well.
Our design is based off a monocoque structure and attempts to satisfy the expectations of our target customer. The material choice for the components was steel because it is highly durable and fatigue resistant. This coincides with our customer requirements for the expectations of high durability for this vehicle, considering its $30,000 price tag. Thus, we concentrated on enhancing the robustness of traditional steel designs. The mass of our concept structure as shown in this report is estimated to be 448 kg. However, there are many minor structural components we did not consider and thus, this value should only be considered a rough estimation. In any case, we found this mass to be larger than we required and we discuss how to address this later.
We addressed the needs of comfortable ride by attempting to make the body extremely stiff with respect to any suspension that may be added. We included 4 under-floor cabin cross members which can serve as attachment points for the seats and other passenger compartment structures. The front 2 cabin cross members are much larger in comparison to the rear. They have relatively large section sizes to 1) support the longitudinal rails during front impact and 2) react side impact loads. The 2 rear cabin cross members are designed to react side impact loads. All the cross members add bending and torsional rigidity to stiffen the structure which makes it robust to noise and vibrations. This NVH robustness was considered an important expectation.
We also facilitated ingress/egress and step over height by lowering the height of the rocker and increasing its thickness. This lead to a relatively large rocker section, but it was a compromise we were willing to make to cater to our customer's needs. However, we feel that lowering the rocker may compromise side impact safety, as the rocker may be too low to contact the barrier. We also tried to make the roof rail and B-pillar as thin as possible to create an even larger ingress/egress space. Our goal was to seat the retired couple with as little bending over as possible -- just in case their bodies are as limber as they used to be when they were younger. We intended to design the cabin to be spacious by disallowing any structural intrusions into the passenger compartment and by slightly crowning the roof panel to allow for ample head room. The goal was to make the cabin feel more like a living room than the interior of a car, hence adding to the luxury aspect.
We considered cabin safety very seriously and designed for robust energy dissipation in case of front or side impact. The cabin cross members serve as added load paths for side impact crashes and thereby increase the safety of the vehicle in the event of a side impact. We included dual motor compartment crushable rails on each side of the vehicle to react frontal impacts. All 4 rails have crush initiators to facilitate crush during a frontal crash. The 2 longitudinal rails extend from the cabin's 2 front cross members. The 2 outer rails extend from the rocker section and help react loads with the upper structure. Since our rocker was very large, we decided to make use of it as an additional load path for crash loads because it was roughly the same size as our longitudinals. This design provides 4 load paths for a full frontal collision and at least 2 load paths for an offset collision. Our design also indirectly increases safety by providing the driver with an increased range of visibility made possible through a thin A-pillar and upper B-pillar.
For ease of viewing, please refer to the appendices listed in Table 2 for packaging overlay views and for the major structural element dimensions in conjunction with the following discussion. The overlays primarily show the beams and panels that we sized for this initial concept. Also, the drawings reflect actual scaled dimensions for all beams and panels.
We laid our underbody structure on the top plan view as seen in Appendix A. The scaled structure appears to fit within the plan view from a packaging perspective. However, we want to note that any routing under the floor pan may require holes in the cross members and this may pose a manufacturing problem. The possible sub-systems affected are exhaust, HVAC, and fuel systems. We want to make note of the continuous section size we utilized along the motor compartment rails, the longitudinal rails, and the cabin cross members. In Appendix C, notice that all 3 rails have the same cross section but different thicknesses. This design facilitates a smooth load path along the entire perimeter of each section, which is advantageous in crash and other loading situations. This is another way we designed durability and robustness into the structure.
We also laid our beam structure on the side plan view as seen in the first figure in Appendix B. Again, we observe that the structure does fit with regards to packaging. However, it seems there may be a packaging problem with the mid-rail extending from the rocker. It may interfere with the shock tower and/or wheel hub. Additionally, we point out that the rocker is located on the low side of the suggested rocker position of the plan view. This was the result of a direct attempt to lower step-over height for easy ingress/egress for our customer. The relatively thinner A and B-Pillars show that visibility can be increased within the package constraints.
The second figure in Appendix C shows the major cabin panels (roof, dash, seat back, and floor) and their locations in the package. These appear to fit within the package and are relatively thin compared to the rest of the structure. Their final shape is highly dependent on routings, holes, curves, and manufacturing capability but we approximated them as flat panels for our initial assessment.
Thus, our final design sketch and concept package seem to fulfill many of our customer requirements and fit into the package space. A detailed analysis of how we arrived at our design requirements, section sizes, and final mass follows.
Prior to creating a structure, we performed a mass analysis to approximately determine the total vehicle mass. First, we determined the plan view area of the target vehicle, 9.42 m2. Then, we used a historical graph to estimate the nominal total weight of our vehicle. This graph of Vehicle Mass to Plan-View Area can be found in Appendix D on page 19. We determined the nominal mass to be 1620kg. Next, we split the vehicle into major subsystems and used typical subsystem masses for mid-size vehicles to estimate each subsystem's contribution to the nominal mass. However, we tailored the vehicle's mass to our target customer. This was done using a spreadsheet which incorporated subsystem mass iterations. When we changed the mass of one subsystem, these iterations helped adjust the masses of the other subsystems using historical data to calculate the interaction between subsystems' masses. In Table 2 on the following page, we outline our initial mass estimates for the subsystems, show the reasons for changing the mass of a particular subsystem, and provide the new subsystem's mass after interaction effects are calculated.
After finding our concept's final mass estimate, we determined typical structural requirements for the vehicle. These included the vehicle's bending moment diagrams, bending strength, bending stiffness, twist ditch torque, torsional stiffness, front and side impact parameters, and roof crush. For many of these requirements we mention a test mass, which we estimated as 2035kg. We discuss the development of the requirements below.
We determined the vehicle bending moment diagrams from a free body diagram of the vehicle as a simply supported beam with its typical loads at the gross vehicle mass condition. This free body diagram is shown in Appendix E, on pages 20 and 21. We included the dynamic bending moment diagram, assumed to be twice that of the static diagram. In addition, we considered front and rear towing conditions. All these bending moment diagrams are shown in Figure 2 below.
We determined that our structure should be strong enough to withstand an 11,000N force in an H-point bending test without permanent deformation. We arrived at this value by considering the maximum bending moment from Figure 2. Modeling the vehicle as a simply supported beam, we determined that an 11,000N force applied equidistant from the front and rear suspensions would yield an equivalent maximum moment of approximately 7,100,000 N-mm when it is the only force acting on the beam.
We determined the required bending stiffness of the vehicle to be 7700 N/mm. We derived this from a first order estimation of bending frequency. Historically, the desirable range for primary vehicle modes is 22-25 Hz. We decided to design our structure to a 23 Hz primary bending mode. We used Equation 1 below to determine the necessary bending stiffness, k.
The other variables are as follows: fn is the bending frequency, l is the wheelbase, L is the overall length of the vehicle, and M is the rigidly mounted mass, which we estimated to be approximately 40% of the curb mass. Hence, we set these bending requirements as our targets.
We determined the twist ditch torque requirement to be 8,200,000 N-mm. This was determined using Equation 2 on the following page, where t is the track of our vehicle (1560mm) and WAxle is the maximum value of the front or rear suspension reactions. In our case the front suspension was the largest reaction force at 10,500N. The free body diagram of Appendix F on page 22 helped us find these reactions.
We determined the torsional stiffness requirement of the vehicle to be 14,000 N-m/°. We arrived at this value by examining the torsional stiffnesses of benchmarked vehicles. The nominal value for a typical mid-size sedan was approximately 12,000 N-m/°. However, we want our vehicle's structure to be stiffer so that it is more robust to noise and vibrations. Thus, we decided to pursue a higher torsional stiffness.
We determined the amount of available crush space to be 550mm in the case of a frontal impact. We used the plan view of the vehicle to get a rough estimate of this value. Please refer to Appendix G on page 23 for the calculation and the plan view.
Additionally, we required the average front barrier crush force to be 335,000N. Using judgment and target retired couple, we determined that the deceleration during a crash must be better than most typical vehicles, which range from 20g to 30g. The deceleration must also be low enough to compensate for the anatomy of an older couple whose bodies are not as robust to acceleration as they once were. Thus, we required a maximum crash deceleration of 23g during the mandated FMVSS 208 30mph frontal crash. Using Equation 3 below, we determined that the structural efficiency needed to attain a 23g deceleration is 73%.
Here, Δ is the available crush space, η is the crush efficiency, v is the velocity prior to crash, and amax is the maximum deceleration desired. We believe this is practical because historically, structures range from 65-80% efficient in 30mph frontal crashes. Finally, the relationship defining the crush efficiency is shown in Equation 4 below, where Favg is the average crush barrier force, and Fmax is the maximum crush barrier force.
For side barrier collisions, we require that crush load for the vehicle side is approximately 200,000N. We know historically and from first order analysis that a large side crush load will decelerate the barrier quicker, which will result in lesser acceleration being imparted to the occupant. Also, the available side crush available in our package is about 300mm. There is 120mm from the outer portion of the door to the inner portion, and there is 180mm from the inner door to the occupant. We used a spreadsheet that utilized a first order analysis of side impact to determine the effects of the crush space on the occupant and to determine whether a package change may be necessary. Please refer to Appendix E for a detailed analysis which utilizes the FMVSS 214 standard for side crash.
In short, we found that at the current dimensions of the side of the vehicle and with a 200000N side crush force, the impact would result in about 57g being imparted to the occupant. If we simply flip the door dimension to 180mm and instead have the distance to the occupant as 120mm, then the impact would impart 38g to the occupant. This is a reduction of 33% by simply reducing shoulder room by 6cm. Although interior room may be diminished, the survivability chances of the occupant are much higher. Thus, a package change should be considered.
We determined that the roof must not deflect more than 5 inches under a 30,000N static load. This was determined by FMVSS 216 which states that the static load applied during the roof crush test is 1.5 times the vehicle weight. During the test, the roof must not deform more than 5 inches. Thus, our roof crush load was determined to be 30,000N using the test mass of our vehicle.
This section aims to describe how we achieved the final sizes of the major structures shown previously. These include the side frame, the cabin shear resistant panels, motor compartment crushable rails, under-floor longitudinal rails, and cabin cross members. We will summarily describe the steps we took and the first-order methods we implemented to determine the dimensions for these major structures. We begin with the side frame.
We determined the side frame beam dimensions mainly from the bending stiffness requirement and also from our customer description. Historically, the bending stiffness requirement is one of the harder requirements to meet. First, we analyzed the plan views of the vehicle and roughly determined the maximum allowable dimension for each of the 8 identifiable side frame beams: the A-pillar, hinge pillar, lower B-pillar, upper B-pillar, lower C-pillar, upper C-pillar, roof rail, and rocker. Next, we obtained a simple first order FEA modeler to perform an H-point bending test analysis. The modeler assumes rectangular sections and our dimensions are reported as such. Using the modeler, we applied the 11,000N load from our bending strength requirement to the lower middle of the side frame and began our analysis. We estimated the bending stiffness as the ratio of the 11,000N load to the vertical deflection of the application point.
We began the analysis by assuming typical joint stiffness values. In the first run, we included all the beams at their largest perimeter dimensions to determine the maximum bending stiffness attainable from our side frame at worst case for packaging. Having surpassed the requirement of 7700N/mm with this first run, we began to reduce the dimensions of the beams. Our first priority was to ensure that our target customers would have ample room for ingress and egress. Thus, we attempted to reduce the section heights of the rocker, the upper and lower B-pillars, the hinge pillar, the A-pillar and the roof rail. This would enlarge the driver and passenger openings in the side frame to facilitate entry and exit. As a bonus, the thinner A and B-pillars would also help increase visibility. However, at the same time, we monitored the beams with the highest strain energy -- the rocker and roof rail. We tried to change them as well since they would affect the overall stiffness the most, but we still wanted to facilitate easy ingress/egress. We reduced the section sizes and altering thicknesses until we met our bending requirement. A screenshot of our final side frame from the FEA modeler is shown in Appendix H on page 24. Please see Appendix C on page 18 for dimensions of each individual beam and its relative sizing.
Our final concept side frame has a total bending stiffness of 7750 N/mm according to our FEA modeler. Its total weight is 83.4kg and the deflection at the loading point was 2.84mm. Thus, we can make the observation that the structure meets the bending stiffness requirement. Additionally, the maximum observed stress in the structure was 95MPa in the roof rail. Recalling the yield strength of typical automotive steel as 207 MPa, we note that there was no yielding in the structure. Also, the width-to-thickness ratio, or "b/t," for the roof is less than 60, and therefore, we can conclude that it will fail by yielding, not buckling. Thus, we can conclude that the structure met the bending strength requirement as well.
We performed a torsion strength and stiffness analysis on the entire cabin. The cabin included both side frames, the seat back, the dash panel, the floor, the roof, the windshield frame, and the backlite frame. Our initial assumptions were that the shear resistant panels of the cabin (floor, dash, roof, and seat back) were all 1mm thick, flat, steel panels.
We determined that the 1mm shear resistant panels buckled under the twist ditch torque and resizing was necessary. Applying the twist ditch torque to the dash panel, we performed an in-depth load path analysis on the cabin structure to get the shear loads on each edge. Please refer to Appendix I on page 25 for specific details. This allowed us to analyze each of the 4 flat panels in shear. We noted that at 1mm, the width-to-thickness ratio "b/t" was greater than 60 for each panel. Thus, they would fail by buckling rather than yield. Therefore, we determined the critical buckling stress (σcr,Shear) and load (Fcr,Shear) for each of the 4 panels. Assuming the panels were simply supported, the following Equations 5, 6, and 7 applied.
Here, E is the elastic modulus, t is the thickness, μ is Poisson's ratio, b is the short dimension of the panel, K is the boundary condition factor, and a is the long dimension of the panel. Thus, if the shear loads on any side of the panels exceed Fcr,Shear, then the panel will buckle.
As previously stated, we determined that all 4 of the 1mm panels failed by buckling. Therefore, we iterated through the previous 3 equations varying the thickness until Fcr,Shear was less than the shear load found through the load path analysis. Please refer to Appendix I on page 26 for specific calculated values. The final panel thicknesses were: 1.4mm for the seat back and dash panel, 1.5mm for the roof, and 1.75mm for the floor.
In addition, we observed that the maximum stress in the side frame under the twist ditch torque was 115 MPa in the upper B-pillar. This stress is less than yield strength of steel and since the b/t value for this pillar is less than 60, we can conclude that it will fail by yielding, not buckling. Thus, the side frame met twist ditch/torsion strength requirement.
We estimated the torsional stiffness of the cabin to be 9,000 N-m/° without the front and rear windshields installed. We determined this by considering the twist ditch torque and the entire cabin in torsion once again. We utilized a spreadsheet to find the torsion stiffness whose basis was a first order equation for cabin stiffness shown below as Equation 8.
Here, q is the shear flow on an edge, T is the twist ditch torque, A is the area, G is the shear modulus, and t is the thickness of the panel, and i is the number of panels. Our load path analysis and the cabin itself told us everything except the effective shear stiffness (Gt)eff.
For the shear resistant flat panels, we determined the (Gt)eff by using the shear modulus and the panel thickness. However, the (Gt)eff of the windshield frames and the side frame had to be determined separately. We found (Gt)eff of the windshield and backlite frames by analyzing the deflection of a flexible frame under a shear force. We assumed small angles and equal angular deflections for all joints. We utilized the relevant joint stiffness used in our side frame FEA modeler. Thus, equating strain energy to work done by the shearing force, we developed Equation 9, which we used to calculate the effective shear stiffness of the windshield and backlite frames.
Here, Kjoint is the joint stiffness, A is the flexible panel area, and i is the number of the joint. Thus, we determined from our model that (Gt)eff of the windshield frame was 380 N/mm and that of the backlight was 252 N/mm. Finally, we found the (Gt)eff of the side frame by using the FEA modeler mentioned earlier to determine the fore-aft deflection caused by the shear force on the side frame. We determined the (Gt)eff of the side frame to be 244 N/mm.
Additionally, we determined the torsion stiffness of the cabin with the windshield and backlite glass installed. Assuming the glass to be rigid and the frame to be very flexible, we used the typical (Gt)eff of the adhesive to determine that the effective stiffness of the windshield and backlite frames was about 4500N/mm. Thus, the total cabin stiffness became 11,700N. We note that in either case, the structure does not meet our 14,000 N-m/° torsion stiffness requirement. We will address this further in the Recommendations section on page 14.
We sized the 2 longitudinal rails using a limit analysis with plastic joints, the maximum expected barrier crush force, and an assumption of square, steel sections. To clarify, we only consider the rails which extend from the cabin cross members, not the secondary rails extending from the rocker. We used a first order limit analysis on the rails to determine their size. Below, Figure 3 shows the equations and a brief sketch of the analysis. We assumed that joints 1 and 2 had equivalent fully plastic moments, Mp. Also, we assumed small translational and rotational deflections. In the following equations, the angle θ was taken from our side package overlay as 55º, L1 was 300mm, and L2 was 200mm.
Typically, 50% of the crash force is absorbed through the lower-middle structure. Our structure included 2 longitudinal rails and therefore, we needed each rail to react at least 25% of the maximum expected barrier force. The max crush force expected is approximately 460,000N during a 23g crash at our test mass of 2035kg. Thus, each rail needed to react 115,000N. Each rail was determined to be a steel section that is 100mm by 100mm and 4mm thick. The b/t ratio for these sections is 25 which indicates that they will fail by yielding.
We determined the size of our 4 crushable rails from the plan view, the average front barrier crush force, and empirical equations for axial crush of steel, square sections. Using judgment, we decided to use square sections of 100mm because this dimension would flow smoothly from the longitudinal rails thereby creating a smooth and robust load path. Typically, 50% of the average crush force is directed through the lower middle structure and 20% is directed through the upper structure. Thus, we sized the 2 lower rails to crush at 25% of the 335,000N load, which is 93750N. We sized the 2 upper rails to crush as 10% of the load, 35,000N. The empirical relations for steel square sections, Equations 9 and 10, were provided by SAE.
We set Pmax = 93750N and 35,000N, respectively, to indicate crippling and the formation of the first fold at this force. For the lower rails, we determined that a square section should be 100mm per side and 1.5mm thick. For the upper rails, we determined that a square section should be 60mm per side and 0.92mm thick. The b/t value for both sets of rails is greater than 60 which constitutes failure by buckling. This is the desirable failure mode for these crushable members. We could further initiate crush of these members by adding large radius ribs on the sides that act as crowned panels, which buckle more easily under loading.
We want to note that the sizing and packaging of the upper crushable rails must be checked so that they do not interfere with the shock tower or any other subsystem. The next design team may consider removing them, but we urge them to find an alternate method for enhanced energy absorption, as the safety of the occupant is of high importance.
Next, we sized the 4 cabin cross members under the floor. To do this, we considered only the worst case loading condition for one of the cross members. This worst case is shown in Figure 4. The front 2 cross members will be loaded in a front collision or a side collision. So we sized these beams for both impacts and chose the more conservative as the final set of dimensions for each cross member. We sized the rear 2 cross members for side crash only. To size the front 2, we iterated through first order buckling and yield. We recall the longitudinal rails react 115,000N during front impact. However, there are 2 cross members that can share this load from each longitudinal rail. So thus, only 57,500N would be reacted by one cross member. Also, the side impact should have a strength of 200,000N per our requirement. During this analysis, we only consider 100mm square sections because we want to fit within the package, and more importantly, the sections would flow smoothly from the 100mm square longitudinal sections to create a smooth load path.
The maximum moment exerted on the beam during frontal impact is about 22,000,000N-mm. Thus, we use Equation 11 to calculate the bending stress in the beam and also Equation 12 to consider buckling.
For Equation 11, σ is the bending stress, M is the moment applied to the beam, y is the maximum distance from the neutral axis, and I is the moment of inertia. The parameters of Equation 12 have been described earlier. Iterations through first order beam analysis, lead us to dimensions of 100mm by 100mm and 18mm thick to react the frontal crash condition. With these dimensions, the largest stress in the beam is 194MPa -- almost the yield of steel at 207MPa. Obviously, the b/t ratio for these beams is small and they will fail by yield. This strength will help ensure the passenger compartment remains relatively un-deformed during a frontal crash.
Considering side impact, we utilized AISI CARS 2005: Geometrical Analysis of Sections program provided by AISI. We performed an axial capacity trend analysis on a 100mm by 100mm section. The results are in the following plot in Figure 5. We note that a thickness of 2.2mm can react approximately 200000N. Thus, the rear 2 cabin cross members should be 100mm by 100mm and 2.2mm thick.
We observe that the frontal crash condition is far more detrimental to the beam that side impact because it is transversely loaded. However, the main function of the front 2 cross members is to keep the longitudinal rail rigid as it plastically deforms to protect the cabin. Thus, the stress in the beam is much higher in than in the axially loaded case.
After sizing the major structural members, we need to acknowledge manufacturing considerations with respect to our sections. The generic sections shown in Appendix C on page 18 are very generic and do not consider manufacturing. For example, none of the thin sections shown in Appendix C have any flanges for welding. So for instance, the motor compartment crushable rails could take on a somewhat different form, as in Figure 5 on the next page. The flanges may add enough length or width that the member may interfere with the packaging and or the aesthetics of the structure. Also, the positioning of the flanges affects the strength of the section as well.
There are ample other examples like this. However, we can also increase strength and stiffness of any of these sections if they are manufactured properly. For example, we can increase the plastic moment of the longitudinal rail by carefully welding another section within it. This would allow it to react a higher crash load we than expected. Thus, we could introduce higher safety factors into our section designs by reinforcing our sections. In Appendix J on page 27, we readjust some of our sections to account for packaging, manufacturing considerations, strength, or aesthetics.
We estimated the final mass of our structure to be 448kg. After finding all the section sizes, we estimated the total mass of the sized structures and then we simply estimated the masses of the structures that we did not explicitly size. Hence, we could compare it to our preliminary mass analysis. This allowed us to make design recommendations based on the any remaining mass available and based on any lack of robustness in the structure. Thus, having found all the section sizes for the beams, we determined their lengths by analyzing our plan views. Below, Table 3 lists the estimated masses of all the structures in our concepts.
The estimated total mass of our structure is about 448kg. This is well above the 418.7kg we approximated for the structural mass during our preliminary mass analysis. Thus, we need to make some changes and improvements to more efficiently make use of the mass. Primarily, we need to focus on reducing the mass of the front cabin cross members which account for 37% of our current structures mass. With this in mind, we pass the following recommendations along to the detail design team.
The structure we analyzed was a very simple one and there are many areas for improvement. For example, the current structure is not robust enough in torsion according to our first order model. We recommend testing be performed to obtain a more accurate torsion model. We were unable to model the effects of our cross body torsion members using first order analysis. High torsional rigidly is a high priority to stiffen the body and also to make it robust to vibrations.
Also, we recommend looking into using doublers or bulkheads for the high stress or high cycle joints. This would not only enhance the rigidity of the structure by increasing joint efficiency, but also it was increase the durability of the high stress and high cycle joints. Also, adding ribs to sides of beams and joints subject to buckling would help inhibit buckling by reducing the effective width of the section.
We recommend adding crush initiators to the front crush members. This will help initiate crush to dissipate crash energy and reduce the maximum deceleration of the vehicle resulting in less injury to the occupants. Along the same lines, the packaging around our upper crush members must be verified to ensure proper clearance from the shock tower and feasibility of design. The packaging of the secondary mid-rail extending from the rocker must also be verified to make sure it clears the wheel well.
Also, our sections are very generic as rectangles and squares. The finer details of styling the sections should be carried out, and then, the strength and stiffness of the sections should be reevaluated to maintain structural rigidity and integrity. We also recommend reinforcing the larger sections such as the rocker and mid-rails. This can be done by welding smaller sections within them to increase the stiffness and strength.
We feel that the rear of our structure is not as structurally robust as the front. Therefore, we recommend the addition of cross members or other reinforcing structures to stiffen the rear of the body. Also, the addition of rear crush members for rear impact should be considered as well.
Finally, the mass of our structure exceeds the requirements set forth in our preliminary mass analysis. This is mainly because our front cross members must react large crash forces in their transverse directions. We recommending investigating other possible load paths to lessen the transverse load applied to those beams. Thus, their size and mass can be significantly reduced.

